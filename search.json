[
  {
    "objectID": "CoC.html",
    "href": "CoC.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "University of Idaho Carpentries is dedicated to providing a harassment-free experience for participants of the conference regardless of age, gender, sexual orientation, disability, physical appearance, race, or religion (or lack thereof).\nWe encourage the open exchange of ideas and expression and thus require an environment that recognizes the inherent worth of every person and group. An inclusive space free of harassment encourages interaction among diverse groups. We want to make certain our workshops and courses are welcoming, and encourages participants to be involved moving forward.\nAll participants (including organizers, attendees, instructors and volunteers) at UI Carpentries Workshops are required to agree to the following code of conduct. Reports of violation to this Code of Conduct should be addressed to the course/workshop lead instructor.\nThis Code of Conduct (CoC) applies to any participant in a University of Idaho Carpentries Workshop. Note that this code augments rather than replaces legal rights and obligations pertaining to any particular situation.\n\nExpected Behavior\nAll workshop/course participants are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior, and all applicable laws.\nWe’re committed to providing welcome environments where people behave according to professional standards. We expect everyone at any UI Carpentries-affiliated event to contribute to a welcoming, civil, safe, and tolerant environment.\nExamples of encouraged behavior that contributes to a positive environment include:\n\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for everyone at the event\nShowing empathy towards other participants\n\n\n\nUnacceptable Behavior\nHarassment will not be tolerated in any form, including but not limited to:\n\nIntimidation or harassment of any kind.\nOffensive comments related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held.\nUnwelcome comments regarding a person’s lifestyle choices and practices, including those related to food, health, parenting, drugs, and employment.\nDeliberate misgendering, “outing,” or use of “dead” or rejected names.\nGratuitous or off-topic blatant sexual images or behavior in spaces where they are not appropriate.\nNot respecting the privacy of other participants\n\n\n\nHarassment in online channels\nSome of our workshops are online event. Please use these guidelines when engaging with participants. The above Code of Conduct applies to an online event, with the addition of:\n\nAvoid using overtly sexual or offensive usernames or profile photos which might detract from a friendly, safe and welcoming environment for all.\nDo not publish text/screenshots of anything shared in private communication channels without explicit consent from the author. This includes screenshots of private messages to public channels, as well as conversations on public channels to anywhere outside of UI Carpentries Workshop.\nDo not direct message someone without their permission.\nDo not record sessions without the presenter’s permission.\nThe meeting host/organizer should be aware of privacy concerns for different tools. For tips on security, a good place to start is: Securing Your Zoom Meetings.\n\nThis CoC applies to all University of Idaho Carpentries online spaces.\n\n\nResponses to Code of Conduct Violations\nWe will follow all University of Idaho and Idaho State requirements regarding how to handle incidents of harassment.\n\n\nWhat To Do If You Witness or Are Subject To Unacceptable Behavior\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact the lead instructor immediately.\n\n\nAcknowledgements\nThis CoC is adapted from RConsortium CoC and the Carpentries CoC This policy is licensed under a Creative Commons Attribution 4.0 International license."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introductory R for Scientists",
    "section": "",
    "text": "Our Class Playlist\nThis workshop will take you from zero to hero over the course of 16 hours of instruction and practice. It will introduce the R programming language, the graphical user interface RStudio and how R can be used to manage and analyse your data. At the end of this workshop, you will be able to:\n\nimport & export data\nunderstand data types and object types\nfilter, reshape, merge and manipulate your data\nmathematically transform data\ndo repeat actions in R\nplot data\nnavigate R help files\n\n\n\nWho is This workshop for?\nThis workshop is intended for beginner R users. No previous experience in R or any other programming or statistical language is expected (although previous R users whose skills have lapsed are welcomed!)\n\n\nWhat this workshop will not cover\n\ngit, GitHub, or any version control\nusage of the terminal (e.g. bash)\nstatistical analysis\n\n\n\nRequirements\n\na computer with a reliable internet connection\nA camera and microphone for Zoom\nA Zoom account (the free version is sufficient)\n\n\n\nWhen\nJan 17 - February 9\nTuesday/Thursdays\n2 - 4 pm Pacific time\nAll sessions will take place over Zoom so students across different timezones can participate.\n\nOffice hours\nI will hold open drop-in hours on Zoom on Wednesdays and Fridays, 1-2 pm if you have questions. It will be the same Zoom link for regular class sessions.\n\n\n\nInstructors\n\nLead Instructor\nJulia Piaskowski | training website | GitHub | personal website\n\n\nTeaching Assistants\nJT VanLeuven | Research Website\nBreanna Sipley | GitHub | Twitter"
  },
  {
    "objectID": "install_R_instructions.html",
    "href": "install_R_instructions.html",
    "title": "Install R & RStudio",
    "section": "",
    "text": "You may already have R installed on your computer. However, if the installation is one year older or later, you should upgrade it. This the beauty and drawback of R (yay for new functionality, boo to the inconvenience). R is updated frequently, usually several times per year. Not every update is important, but over time, older versions of R will cause you problems because they will work poorly with installed packages. New packages will not work at all with older version of R and older packages will have problems, requiring to also install older package versions. This is a pain to manage; its easiest to keep R updated."
  },
  {
    "objectID": "install_R_instructions.html#install-r",
    "href": "install_R_instructions.html#install-r",
    "title": "Install R & RStudio",
    "section": "Install R",
    "text": "Install R\nFirst, navigate to the Cloud mirror of the R Project for Statistical computing, and download R](https://cran.rstudio.com/):\n\n\n\n\n\n\nWindows\nUse the link circled in red regardless if you have R installed or not. It’s just easier.\n\n\n\n\n\n\n\nMac\nDownload the installation bundle. Check that your operating system version is compatible (the text to the right of the download link will indicate this).\n\n\n\n\n\nOnce the installation file is downloaded, open it and follow the installation instructions, accepting the default installation settings."
  },
  {
    "objectID": "install_R_instructions.html#install-rstudio",
    "href": "install_R_instructions.html#install-rstudio",
    "title": "Install R & RStudio",
    "section": "Install RStudio",
    "text": "Install RStudio\nYou can download RStudio from the Posit website. Pick the version appropriate for your operation system and follow the installation instructions.\nYou do not need to follow “Step 1: install R” indicated on the Posit site if you already installed R following the directions above."
  },
  {
    "objectID": "install_R_instructions.html#test-your-installation",
    "href": "install_R_instructions.html#test-your-installation",
    "title": "Install R & RStudio",
    "section": "Test your Installation",
    "text": "Test your Installation\n\nOpen RStudio on your personal or work computer. It should look very similar to Posit Cloud.\nRun a command in the console to make sure all installed properly.\nInstall the Tidyverse packages: install.packages(\"tidyverse\") (this will take a few minutes)"
  },
  {
    "objectID": "learning-quarto.html",
    "href": "learning-quarto.html",
    "title": "Working with Quarto Documents",
    "section": "",
    "text": "Quarto is a file format for weaving together code (R, python, and others), output, and text into a single notebook. It is a nice tool for putting together reports or doing analysis for yourself. Quarto also has applications for building websites (this website is build with Quarto!), formatting books, and making slideshow presentations. These are advanced applications that over time, you may want to try out yourself.\nWhile Quarto offers many advanced features, using only the basic features will enable users of many abilities to communicate their results with others. You can choose to learn more, but Quarto is nevertheless useful using only its foundational tools: mixing text, code, and code outputs.\nIt follows some of the standard syntax of markdown, which is a highly simplified version of HTML (“hypertext markup language”).\nA .qmd document can simply exist as is (and is highly useful), or you can choose to output it to many enabled formats such as .html (the easiest to do), .pdf, .docx and more. Click on “Render” at the top of a .qmd file in RStudio to see a rendered version of your Quarto document."
  },
  {
    "objectID": "learning-quarto.html#basics-of-quarto",
    "href": "learning-quarto.html#basics-of-quarto",
    "title": "Working with Quarto Documents",
    "section": "Basics of quarto",
    "text": "Basics of quarto\n\nText Formatting\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n*italics* and **bold**\nitalics and bold\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n\n\n\nHeadings\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n# Header 1\nHeader 1\n\n\n## Header 2\nHeader 2\n\n\n### Header 3\nHeader 3\n\n\n#### Header 4\nHeader 4\n\n\n##### Header 5\nHeader 5\n\n\n###### Header 6\nHeader 6\n\n\n\n\n\nLists\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n*   item 2\n\n    Continued (indent 4 spaces)\n\nitem 2\nContinued (indent 4 spaces)\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\nitem 2\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n(@)  A list whose numbering\n\ncontinues after\n\n(@)  an interruption\n\nA list whose numbering\n\ncontinues after\n\nan interruption\n\n\n\nterm\n: definition\n\nterm\n\ndefinition\n\n\n\n\n\n\n\nSource Code\nUse ``` to delimit blocks of source code:\n```\ncode\n``` \nAdd a language to syntax highlight code blocks:\n```r\n1 + 1\n``` \nIf you are creating HTML output there is a wide variety of options available for code block output. See the article on code blocks for additional details.\n\n\nTables\n\nMarkdown Syntax\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\nOutput\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nTo Learn More\n\n\n\nThere are many more options for formatting Quarto documents and embedding information in a Quarto document. Visit Quarto’s markdown page to learn more."
  },
  {
    "objectID": "learning-quarto.html#what-else-can-quarto-be-used-for",
    "href": "learning-quarto.html#what-else-can-quarto-be-used-for",
    "title": "Working with Quarto Documents",
    "section": "What else can quarto be used for?",
    "text": "What else can quarto be used for?\nThere is a rich array of possibilities for Quarto documents, the majority of which we will not address in this class. Take a look at this gallery to get a better sense of what you can do with Quarto and decide for yourself if it’s worth the effort to learn better.\nI started learning how to use markdown for html documents, then made a few presentations with Quarto’s predecessor, Rmarkdown (I’m not sure this is worth the effort). I next started building website with Rmarkdown and Quarto, and have found this to be a great tool for sharing information via websites. If you never do this, that is completely okay! Not everyone neesd these tools, but it you do, Quarto can make implementation easier."
  },
  {
    "objectID": "lessons/Lesson00.html",
    "href": "lessons/Lesson00.html",
    "title": "Preparing for this Short Course/Workshop",
    "section": "",
    "text": "Welcome & salutations!\nI excited to teach this course. I have fully revamped this curriculum, doing my best to recreate “beginner’s mind”.\nWe have very limited time, so order to conserve class time and have us all ready for the first day of class, please read through this “Lesson Zero”, watch the video and follow the instructions below.\n\n\nJoin Posit Cloud\nYou will receive an invitation a link via email from us to join our online classroom on Posit Cloud, where you will need to sign up for an account using your email, or you can connect it to a Gmail or GitHub account (any of these choices will work fine for the class). If do you not have a Gmail or GitHub account, use your normal email instead. If you are taking this for course credit, please use your official UI email. Once you receive the invitation and have created an account, follow these instructions for accessing the classroom.\n\n\n\n\n\n\nImportant!!!\n\n\n\nIf you use any other email for your Posit account than the one associated with your UI account, please notify me ASAP so I can invite you to join the classroom.\n\n\n\n\nClass Structure\nFor all lessons, please follow along in your RStudio cloud session. In most instances, you will type and run the same code that I will demonstrate.\nI will record each day’s lessons and make it available through email and Canvas. Additionally, all code generated that day will be posted on this course website shortly after each class ends. It is important that you read through notes and watch the video if (1) you had to miss some or all of a class, or (2) there is material you do not understand.\nIt is very important that you use the time between class sessions to ensure you understand the material.\n\n\nClass absences\nIt’s okay to miss classes - we all have stuff going on. There is no need to tell me in advance. As mentioned above, if you miss class, please be sure to catch up on the course material you missed by reading the course notes, running the content and watching the video. If you are registered for course credit and will miss more than 3 classes, consider switching to the workshop mode, which is the same content, but no course credit.\n\n\nClass Notes Structure\nAs mentioned, all code run will be captured in class notes that will be posted. While you can read those notes and not attend class, many find it helpful to attend a live course and receive live instruction and feedback from an expert. Additionally, those of you formally registered for BCB 502 are required to attend at least 60% of the classes per the syllabus in order to pass.\nAt the beginning of each lesson, this box will be included:\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThis will be a list of what each lesson intends to teach.\nIf you do not think you have met those learning goals, please review the notes, rewatch the videos and if the material is still unclear, contact me.\n\n\n\nAt the end of most lessons, this box will be included:\n\n\n\n\n\n\nPutting it all together\n\n\n\nTips designed to weave together information from multiple lessons.\n\n\n\n\nHow to Suceed in Learning R\n\nAt the end of each class, review the learning goals and decide if you met those goals. These are designed to be the bare minimum of knowledge to competently use R. Later workshop/course content builds on this knowledge.\n\nReview what we have covered between classes - refresh your knowledge.\nIf there are practice problems, do them.\nExperiment in the R console using what you learned. Really, nothing can go wrong.\nIf class material is not clear, re-run the code from class and reread the notes; watch the videos. If it’s still not clear, contact me.\nCome to me with specific questions! I’m here to help.\n\n\n\nYour very first R lesson!\n\nR is case-sensitive! (data is different from Data and DATA). This means when typing commands, exercise great care and attention to detail so your code works.\nThere is no “undo” button in R. Once a command is run, you can’t undo it! (this is not as bad as it sounds)"
  },
  {
    "objectID": "lessons/Lesson01.html",
    "href": "lessons/Lesson01.html",
    "title": "Lesson 1: Math Operators",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nUnderstand sorts of math operators available in R and how to use them\nUnderstand logical operators in R\nBe aware of the order of operations\nBe aware of how whitespace is interpreted in R\nUnderstand how to use parentheses, brackets, braces and quotations in R\n\n\n\n\n\nR as a calculator\n\nAddition, subtraction, multiplication, division\n\n1 + 3\n\n[1] 4\n\n10 - 15\n\n[1] -5\n\n2*8\n\n[1] 16\n\n60/12\n\n[1] 5\n\n\nA hard return between lines of code is sufficient to separate the commands.\n\n\nExponentiation\n\n3^2\n\n[1] 9\n\n2^4\n\n[1] 16\n\n9^0\n\n[1] 1\n\n2^-2\n\n[1] 0.25\n\n\nR can also handle scientific notation. This number, 3e2 is equivalent to \\(3 * 10^2\\), or \\(3000\\).\n\n\nRoots (square, cube, ….)\n\n4^(1/2)\n\n[1] 2\n\n8^(1/3)\n\n[1] 2\n\n\n\n\nLogs\n\nlog(10)\n\n[1] 2.302585\n\n\n(base e)\nlog with base 10\n\nlog10(10)\n\n[1] 1\n\n\nlog with base 2\n\nlog2(4)\n\n[1] 2\n\n\nIf you have other bases:\n\nlog(10, base = 4)\n\n[1] 1.660964\n\n\n\n\nOperations with sign\n(positive and negative signs are called “unary operators”)\n\n3*-4\n\n[1] -12\n\n\nLike in standard math, only negatively signed numbers need to be specified.\n\n\nInteger division (the remainder is discarded)\n\n5 %/% 3\n\n[1] 1\n\n\n\n\nModulus operator (return the remainder after division)\n\n5 %% 3\n\n[1] 2\n\n\n….and so much more\n\n\n\nLogical Operators\nThese test for conditions (“is this true?”) and return either a TRUE or FALSE\n\n\n\nsyntax\nFunction\n\n\n\n\n==\nequal\n\n\n!=\ndoes not equal\n\n\n<\nless than\n\n\n>\ngreater than\n\n\n<=, >=\nless than and equal to, and greater than equivalent\n\n\n\nExamples\n\n1 == 1\n\n[1] TRUE\n\n1 == 2\n\n[1] FALSE\n\n1 != 2\n\n[1] TRUE\n\n1 < 1\n\n[1] FALSE\n\n1 > 1\n\n[1] FALSE\n\n1 <= 1\n\n[1] TRUE\n\n1 >= 1\n\n[1] TRUE\n\n\nWhen testing multiple conditions: use & (‘and’) if two things must be true and | (‘or’) if one of two things must be true:\n\n1 < 2 & 1 != 1 \n\n[1] FALSE\n\n1 < 2 | 1 != 1\n\n[1] TRUE\n\n\n\n\nOrder of operations.\nThe rules:\n\noperations go left to right\nexponents are first, followed by ‘unary operators’ (+/- signs)\nmultiplication and division before subtraction and/or addition\nlogical operators come after all mathematical transformations\nParentheses overall all other rules!\n\nWhat results from this?\n\n2^3+4+12*7/2 <= -6*9\n\nWhen in doubt about the order of operations use parentheses!\nHere is the official R guide to order of operations (warning: this is complicated and refers to functions beyond mathematical operators).\n\n\nSome notes on R syntax\n\nmost often, the amount of white space does not matter.\n\nThese are the same:\n\n4/3\n\n[1] 1.333333\n\n4/    3\n\n[1] 1.333333\n\n4    /  3\n\n[1] 1.333333\n\n\nThese are also the same:\n\nlog(10)\n\n[1] 2.302585\n\nlog( 10 )\n\n[1] 2.302585\n\nlog ( 10)\n\n[1] 2.302585\n\n\n\nR expects certain things to be paired or completed before it will send it to the interpreter\nAs mentioned, earlier a hard return is sufficient to send a command to the R interpreter.\nExceptions: binary operators (= those expecting 2 numbers): +, -, *, /, ^, ==, etc\nExceptions: unclosed parentheses (), brackets [] {}, or quotes ' ' \" \". R will wait for these to be completed. A single quote must always be complemented by a second single quote, and a double quote likewise must always have a second quote to complete it. Left parentheses, curly braces, or brackets much also be accompanying by their right-sided complement.\ngood examples\n\n\n1 + 2\n{ }\n( )\n[ ]\n\"  \"\n' '\n` `\n\nbad examples\n\n\n1 + \n'\n(  } ] \n\"\n' \"\n\nthere is no difference between double and single quotes on a practical level, but R will interpret them as different commands (so a single quote cannot close a double quote). This is useful when there is nested levels of quoting (rare), and yet, it happens now and then.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you become stuck with an unfinished command, you can use the escape key, ESC, to get out of it.\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nCheck the “History” tab in the upper right hand pane (this should be to the right of the “Environment” tab). What is there?\nIf you followed along and coded the above examples, you should see the command you ran previously (including any mistakes). This is your command history. There are several icons directly above your history - explore what those do (hoover before clicking any icon to make sure you are okay with action before performing it)."
  },
  {
    "objectID": "lessons/Lesson02.html",
    "href": "lessons/Lesson02.html",
    "title": "Lesson 2: Vectorizing Operations",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nunderstand how to assign variables and collections of numbers to an object name\nknown the rules for how to name objects\nunderstand reserved words in R and how to find them\nbe able to create a sequence of numbers in R using any starting value and any ending value\n\n\n\n\n\nVectorizing operations\nUsing R as a calculator between a few numbers is handy, but typically we are hoping to do so much more with it, such as performing a calculations across a long list of numbers.\nR is naturally vectorized, which means that you can easily perform a mathematical operation across a vector of numbers (no need to write loops!)\nSay we have a collection of numbers from 10 to 20 and we want to multiple them all by 12. We can create a sequence of numbers by wrapping them all in c() command (for “concatenate”) and separating each with a comma.\n\nc(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\nThen those numbers can be operated on by any math operator:\n\nc(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20) * 10 - 1\n\n [1]  99 109 119 129 139 149 159 169 179 189 199\n\n\nThere’s also a quicker way to specify a sequence of integers using the notation start:end:\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nIt also counts down:\n\n20:10\n\n [1] 20 19 18 17 16 15 14 13 12 11 10\n\n\nAnd works with negative integers:\n\n-5:5\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n\nThese can be operated on:\n\n(-5:5)^2\n\n [1] 25 16  9  4  1  0  1  4  9 16 25\n\n\n\n\nObject assignment\nIt is rather cumbersome to continually retype numbers, even while using a shortcut. There’s a general rule of “DRY” when coding, which means “Don’t repeat yourself”. We can avoid this by assigning these numbers to an R object.\nTraditionally, the left arrow is used for object assignment, <- (less than symbol + a dash), but the standard equals sign, = also works. These are equivalent:\n\nx <- 1\nx = 1\n\nWe can assign multiple numbers to an object\n\nx_vector <- 1:10\ny_vector <- c(2, 4, 6, 8, 10)\n\nThe left arrow assignment <- takes everything on the right side of the arrow and assigns it the object name on the left.\n\n\nObject naming\nIt is your choice (mostly) about what to name R objects. There are a few rules to follow:\n\nspaces are generally not allowed and a huge pain - avoid at all costs!\nDon’t start with a number or symbol! (this is technically possible, but a huge pain)\nchoose a name that is short, yet descriptive\nR is case sensitive, so test is different from Test and TEST. Be mindful of this! It trips many folks up.\n\nIt’s possible that you will thank yourself for using lowercase and avoiding special symbols (aside from . and _)\nif you start a function name with a “.” (e.g. .variable), you won’t see it listed in the global environment (which can be frustrating), this is not recommended for newer R users\nyou cannot use “reserved words” from the R language (terms set aside for very specific purposes in R). When typing these in an R console, they usually light up in a special colors.\n\nHere is some discussion on object naming in R.\n\n\nReserved words\n\n\n\n\n\n\n\nreserved word\nmeaning\n\n\n\n\nTRUE FALSE\nlogical\n\n\nNA\nmissing value\n\n\nNaN\nnot a number/undefined\n\n\nNULL\nno value/undefined\n\n\nInf -Inf\ninfinity\n\n\nfor in\nfor loops\n\n\nif else while break next repeat\ncontrol flow\n\n\nNA_integer_ NA_real_ NA_complex_ NA_character_\nmissing data by data type\n\n\n\nIt’s easy to forgot these. Run ?reserved in an R console or check here to remind yourself if need be.\nSome examples of reserved words in the wild:\n\nlog(0)\n\n[1] -Inf\n\n0/0\n\n[1] NaN\n\n2/0\n\n[1] Inf\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nCheck the environment pane. These are the object you created during the session. This is where you will see all objects created, unless you have choosen to render the objects invisible by starting their object names with a ., a period."
  },
  {
    "objectID": "lessons/Lesson03.html",
    "href": "lessons/Lesson03.html",
    "title": "Lesson 3: Introduction to RStudio",
    "section": "",
    "text": "Learning Recap\n\n\n\n\n\nAt the end of this lesson, you should understand:\n\nWhat the different tabs in each of the panes of RStudio do\nWhat is in each menu item in Rstudio and have a general sense of functionality available\nRStudio is more than a graphical user interface for R. It is an integrated development environment (IDE), that is a full service application for supporting software development. It can perform multitudes, so more than most people need. It is the supermarket of R functionality. Like a supermarket, there are parts of RStudio you will visit frequently and parts you will rarely if ever use. After 10+ years of using RStudio on a near daily basis, there are several parts of it that I continue to be unfamiliar with! Ths is okay - clearly, I have not needed those parts. You will come to find what sections youn will need most over time and practice.\nStill, it helps to have a guided tour. Let’s dive into this."
  },
  {
    "objectID": "lessons/Lesson03.html#the-panes",
    "href": "lessons/Lesson03.html#the-panes",
    "title": "Lesson 3: Introduction to RStudio",
    "section": "The Panes",
    "text": "The Panes\nHere is a simplified schematic:\n\n\n\n\n\nThese can be rearranged, but for this class, we will use the default arrangement.\n\nThe Console/Terminal/Background Jobs\n\n\n\nDefault location: left or bottom left\n\n\n\n\n\n\n\nTab\nFunction\n\n\n\n\nConsole\nwhere R commands are actually done\n\n\nTerminal\nuse a terminal language such as bash or the windows command prompt\n\n\nBackground jobs\nusual pacakage installation\n\n\n\nIn this workshop, we will only be using the Console.\n\n\nFiles/Plots/Packages/Help/Viewer/Presentation\n\n\n\n\n\nDefault location: bottom right\nProbably the most useful pane - we will be here frequently!\n\n\n\nTab\nFunction\n\n\n\n\nPlots\nview plots\n\n\nFiles\nexplore your file system\n\n\nPackages\ninstall, update and load packages\n\n\nHelp\nhelps files & examples\n\n\nViewer\nfor previewing websites\n\n\nPresentation\nfor previewing presentations\n\n\n\nWe will not be using the Viewer or Presentations tabs in this workshop.\nWhat are Packages?\nThese make the world go around in R. All of R consists of packages or libraries that have certain functionality associated with them. Some of are maintained by the R core team, others are maintained by outsiders. All packages are open source and most are a volunteer effort. When you open R, several packages are loaded automatically: base, datasets, graphics, grDevices, methods, stats, utils.\nWe will talk about package installation and usage later in this course/workshop.\n\n\nEnvironment/History/Connections/Build/Git/Tutorial\n\n\n\n\n\n\n\n\nTab\nFunction\n\n\n\n\nEnvironment\nobjects created and existing in your current R session\n\n\nHistory\nprevious R command run\n\n\nConnections\nto connect to an external database\n\n\nBuild\nfor building R packages and other large projects\n\n\nGit\nonly visible if you’ve initialized a git repository\n\n\nTutorial\ntutorials build by Posit (very helpful)\n\n\n\nhere\n\n\nOur Scripts Pane\n\n\n\n\n\ndefault location: upper left\nThese are all the files we create and edit: .R, .Rmd, .txt, …\nwhen we open files from the “Files” pane, this is where it shows up"
  },
  {
    "objectID": "lessons/Lesson03.html#the-upper-menu-items",
    "href": "lessons/Lesson03.html#the-upper-menu-items",
    "title": "Lesson 3: Introduction to RStudio",
    "section": "The Upper Menu Items",
    "text": "The Upper Menu Items\n\n\n\n\n\n\nFile\n\nopening and/or creating files\n\nopening and/or creating projects\n\nrecent files, recent project\n\n(standard file functionality)\n\n\n\nEdit\n\ncopy, paste, find\nvery handy “find in files” feature!\n\n\n\nCode\n\nincredible useful set of commands\nsome are very simple (e.g. “comment lines”), others are complex (e.g. “rename in scope”)\nover time, you will learn what these mean and perhaps make use of them (if you don’t, that is okay)\n\n\n\nView\n\nrearrange panes\nzoom in/out\noverall not that useful, except for the shortcuts\n\n\n\nPlots\n\nmeh\n\n\n\nSession\n\nvery handy for restarting your R session\nmanually set the working directory (we will do this in a few weeks)\n\n\n\nBuild\n\nadvanced tools for building packages, websites, et cetera. I’ve never visited this part of the supermarket.\n\n\n\nDebug\n\ntools for debugging code (removing scripting errors). We will not use this in the workshop! But you can learn more about it here.\n\n\n\nProfile\n\nfor code profiling (checking how long it takes your code to run). We will also not be using this in the workshop. This is part of the supermarket I rarely visit.\n\n\n\nTools\n\nsome handy utility function. I mostly use this menu item to set preferences via “Global Options”.\n\n\n\nHelp\n\nmore utility functions. You can check for RStudio updates here, access community help forum, and other forms of documentation in addition to standard help files.\n\n\n\nmore\nRstudio has a massive number of keyboard shortcuts. You can find them in the menu (Help –> Cheat Sheets) and summarized in this cheat sheet"
  },
  {
    "objectID": "lessons/Lesson04.html",
    "href": "lessons/Lesson04.html",
    "title": "Lesson 4: Introduction to R data types",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nUnderstand what object class means and how to determine and object’s class\nUnderstand the difference between the 5 main object classes: logical, integer, numeric, character and factors.\nknow how to coerce objects from one class to another\n\n\n\n\nR is a programming language and like all programming languages, it has special conventions for defining how information is classified on your computer and what types of actions can be performed on different data types.\nMuch of this is related to your computer hardware, how computer memory is allocated for R objects and processes and so forth. You don’t need to understand the guts of this to use R (but should you ever want to learn, this is fascinating material).\nThe most common object types and the rules that govern them are described in this lesson.\n\nData types\n\nNumeric\nPreviously, we created an object in R that was a collection or sequence of numbers.\n\nx1 <- 1:10\n\nThese numbers are technically integers (sometimes called “long integers”). We can also create “floating point numbers” (e.g. with precision past the decimal point):\n\nx2 <- c(1.25, 2.718, 10.000)\n\nThese are also called “double precision numbers” or “double” for short.\n\n\nCharacter\nThese can also be created for character variables:\n\nx3 <- \"apple\"\nx4 <- c(\"orange\", \"banana\")\n\nCheck the type for each R object\n\n class(x1)\n\n[1] \"integer\"\n\n class(x2)\n\n[1] \"numeric\"\n\n class(x3)\n\n[1] \"character\"\n\n class(x4)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can force a number to be a integer by adding an L to a number as long as it does not contain a decimal pont (e.g. c(0L, 1L, 2L))\n\n\nThere are two other special classes:\n\n\nLogical\n\nconsisting of TRUE and FALSE values\n\n\nx5 <- c(TRUE, FALSE, FALSE, TRUE)\nclass(x5)\n\n[1] \"logical\"\n\n\n\n\n\nObject type coercion\n\nR will automatically an assign an object type based on the items present within object. It will try to assign the simplest type possible. Here are the types from simplest to most complex:\n\n\\[logical < integer < numeric < character\\]\nWhat classes do you think results from each of these?\n\nx8 <- c(8, 9.2)\nx9 <- c(0, 0, 0, 0)\nx10 <- c(TRUE, FALSE, 1, 0)\nx11 <- c(1, 2, \"pear\", -6:2, TRUE)\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\nclass(x8)\n\n[1] \"numeric\"\n\nclass(x9)\n\n[1] \"numeric\"\n\nclass(x10)\n\n[1] \"numeric\"\n\nclass(x11)\n\n[1] \"character\"\n\n\n\n\n\nWhen you start importing data, you may notice variables did not come in as expected. This is due to the values in the original data file. For example, there may be a column that is only supposed to contain numeric values, yet it imported as character. The column in the file may contain something like this:\n\nc(1.3, 8, 23, \"0 (dropped sample)\", 100, 84)\n\n[1] \"1.3\"                \"8\"                  \"23\"                \n[4] \"0 (dropped sample)\" \"100\"                \"84\"                \n\n\nThis would import as character because of that one single value that is not numeric!\nYou can check if items are classified as specific types:\n\nis.numeric(x10)\n\n[1] TRUE\n\nis.logical(x10)\n\n[1] FALSE\n\nis.logical(x5)\n\n[1] TRUE\n\nis.character(x4)\n\n[1] TRUE\n\n\nObjects can be coerced with these functions:\n\nas.character(x8)\nas.logical(x10)\nas.numeric(x11)\n\n\n\nSpecial object type: The Factor\nThis is a very unusual data type that is specific to R and its history as a language for statistical analysis.\n\n\nFUN Fact\nR’s predecessor, “S”, was invented at Bell Labs for doing data analysis\n\nFactors look like a character variable:\n\nf1 <- factor(c(\"blue\", \"blue\", \"purple\", \"green\", \"green\", \"yellow\", \"green\"))\nf1\n\n[1] blue   blue   purple green  green  yellow green \nLevels: blue green purple yellow\n\n\nIt is a character variable, with pre-defined levels that are alphabetized. The text “Levels: …” are the predefined levels associated with that factor. Let’s compare this to a character variable by manually converting it to character.\n\nas.character(f1)\n\n[1] \"blue\"   \"blue\"   \"purple\" \"green\"  \"green\"  \"yellow\" \"green\" \n\n\nIn the character type, all the observations are in quotes and there is no “Level” information.\nLike other data types, you can manually coerce a fabric as thus:\n\nas.factor(x4)\n\n[1] orange banana\nLevels: banana orange\n\n\nUnder the hood, deep in the R internals, these are integers. The first factor level is designated 1, the second level is designated 2 and so forth. This order is set alphanumerically, but it can be manipulated by hand (run ?factor in the console for more information on how to do this).\n\nas.integer(f1)\n\n[1] 1 1 3 2 2 4 2\n\n\nFactors are used in statistical analysis and can be manipulated in several ways. To a large extent, you can ignore factors. However, you will see them referred to in R functions occasionally. It’s good to know they exist and the very basics of how they work.\n\n\n\n\n\n\nPutting it all together\n\n\n\nLook at the object created in the lesson in the Global Environment pane. For each object, the object class and the first few values will be listed."
  },
  {
    "objectID": "lessons/Lesson05.html",
    "href": "lessons/Lesson05.html",
    "title": "Lesson 5: Data Structures",
    "section": "",
    "text": "The longest and most important lesson of them all! These are the foundation of everything you are likely to do R as a scientists. Understanding these will take time and practice, so you may find yourself returning to this page to remind yourself of these data structures."
  },
  {
    "objectID": "lessons/Lesson05.html#introduction-to-common-data-structures",
    "href": "lessons/Lesson05.html#introduction-to-common-data-structures",
    "title": "Lesson 5: Data Structures",
    "section": "Introduction to Common Data Structures",
    "text": "Introduction to Common Data Structures\nPreviously, we looked at data types. Now we need to consider how those types are arranged into complex structures (that is, objects) we can access and manipulate.\nThere are several data structures commonly used in R:\n\nvector\ndata.frame\nmatrix\nlist\n\n\nThe vector\nA collection of items all coerced to be the same data type that we learned about in the previous lesson. These are sometimes called “atomic vectors” in the R documentation.\n\nv1 <- 1:10\nv2 <- c(\"apples\", \"pears\", \"oranges\")\nv3 <- c(1, 5, 7, 85)\n\nA vector can also consist of only one value or no value.\n\nv4 <- \"violets\"\nv5 <- TRUE\nv6 <- NA\n\nIt has the attribute length and each item in a vector can also be named.\n\nlength(v1); length(v2); length(v3)\n\n[1] 10\n\n\n[1] 3\n\n\n[1] 4\n\n\n\nnames(v3) <- c(\"A\", \"B\", \"C\", \"D\")\nv3\n\n A  B  C  D \n 1  5  7 85 \n\n\n\nAccessing items\nItems in a vector can be accessed by referencing the numeric position in the vector, starting at 1 and ending at the vector length. If a vector has length of one, it not necessary to index that.\nx[1] will access the first item in the vector, while x[5] will access the 5th element. Multiple item can be indexed: x[c(1,5)]. If an index position, it repeated, that item will be returned as often as it is called:\n\nv1[1]\n\n[1] 1\n\nv1[5]\n\n[1] 5\n\nv1[c(1,5)]\n\n[1] 1 5\n\nv1[c(1,1)]\n\n[1] 1 1\n\n\nAny collection of numbers can be used to index items in a vector:\n\nv1[c(1, 1:5)]\n\n[1] 1 1 2 3 4 5\n\n\nWhat happens if a negative number is used?\n\nv1[-1]\n\n[1]  2  3  4  5  6  7  8  9 10\n\n\nEverything but that index position is returned.\nWhat if you index a position that does not exist?\n\nv1[0]\n\ninteger(0)\n\nv1[20]\n\n[1] NA\n\n\nItems in a vector can also be accessed by their name:\n\nv3[\"A\"]\n\nA \n1 \n\n\nWhat happens if there are replicate names in a vector and you try to index (extract a value) for that name?\n\nnames(v3) <- c(\"A\", \"B\", \"C\", \"A\")\nv3\n\n A  B  C  A \n 1  5  7 85 \n\nv3[\"A\"]\n\nA \n1 \n\n\nOnly the first instance of a name is returned.\n\n\n\nThe data frame\nA collection of vectors all of the name length. Each vector is a single data type, but different columns can be different data types. This is similar to a typical workbook you might open in Excel or another spreadsheet program. These can be only one column wide, but they often consist of more than that.\n\nd1 <- data.frame(var1 = 1:5,\n                 var2 = c(\"a\", \"b\", \"a\", \"b\", \"c\"),\n                 var3 = c(\"alpha\", \"beta\", \"gamma\", \"zeta\", \"psi\"))\nd1\n\n  var1 var2  var3\n1    1    a alpha\n2    2    b  beta\n3    3    a gamma\n4    4    b  zeta\n5    5    c   psi\n\n\nNotes that is a single value is supplied for a column, it will be repeated for the entire column.\nA data frame has attributes for:\n\nnrow number of rows\nncol number of columns\ncolnames column names\nrownames row names (if none are provided, R will generate integer row names starting at 1)\n\n\n\n\n\n\n\nNote\n\n\n\nWhile duplicate column names in a data frame are allowed, they are not advised, and may throw an error during data import, depending on the import function used.\n\n\nCheck the number of rows and columns:\n\nnrow(d1)\n\n[1] 5\n\nncol(d1); length(d1)\n\n[1] 3\n\n\n[1] 3\n\ndim(d1) # tells us row and column lengths in one command\n\n[1] 5 3\n\n\nLook at the rownames and colnames atrributes:\n\nrownames(d1)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\ncolnames(d1)\n\n[1] \"var1\" \"var2\" \"var3\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe rownames attribute can be set, but if it is not, it is automatically created within R from 1 to the total number of rows. Row names are a tricky attribute than many packages in R do not support. A function may toss out your row names without any warning!\nIn general, I do not recommend setting the row names attribute in data frames to anything other than the default values unless a package function specifically requires it.\n\n\nWhat does length(d1) return? How about names(d1)?\nWe can look at the overall structure of a data.frame with View():\n\nView(d1)\n\nIf a particularly large file is loaded into R, using View() may be very slow (if you have a large number of rows) and provide an incomplete view (if you have a large number of columns). In that case, you can use str() to look at a data frame’s structure:\n\nstr(d1)\n\n'data.frame':   5 obs. of  3 variables:\n $ var1: int  1 2 3 4 5\n $ var2: chr  \"a\" \"b\" \"a\" \"b\" ...\n $ var3: chr  \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n\n\nThe data frame is the most common data structure scientists use in R\n\nAccessing items\nLike vectors, data frames can be indexed by position, except now we have two dimensions to consider. You can extract individual elements in a data frame by references the row and column position, my_dataframe[row, column].\n\nExtract the items located in the first 2 row2 and last 2 columns:\n\nVisual of what we want:\n\n\n\n\n\n(This graphic is an overlay of green over blue, creating a dark teal color. The green represents rows indexed, the blue is columns indexed and the teal is the intersection between those two. If a color is not visible, that is because it is under the teal overlay.)\n\nd1[1:2, 2:3]\n\n  var2  var3\n1    a alpha\n2    b  beta\n\n\n\nExtract the first two rows and all of the columns:\n\n\n\n\n\n\n\nd1[1:2, ]\n\n  var1 var2  var3\n1    1    a alpha\n2    2    b  beta\n\n\nWhen the column position is left empty, all columns are returned\n\nExtract the entire first column and all rows:\n\n\n\n\n\n\n\nd1[ ,1]\n\n[1] 1 2 3 4 5\n\n\nWhen the row position is left empty, all rows are returned\n\nExtract the values located in the first 2 rows and first two columns:\n\n\n\n\n\n\n\nd1[1:2, 1:2]\n\n  var1 var2\n1    1    a\n2    2    b\n\n\n\nReturn everything except the third columns\n\n\n\n\n\n\n\nd1[ ,-3]\n\n  var1 var2\n1    1    a\n2    2    b\n3    3    a\n4    4    b\n5    5    c\n\n\n\nReturn everything except the first 2 rows:\n\n\n\n\n\n\n\nd1[-(1:2),  ]\n\n  var1 var2  var3\n3    3    a gamma\n4    4    b  zeta\n5    5    c   psi\n\n\n\n\n\n\n\n\nThings to note\n\n\n\nIndexing accepts numeric/integer vectors, so you can use a sequence (3:10), or concatenated positions (c(1, 2, 5, 10)), or a combination of both (c(1:10, 13)).\nWhen indexing positions in a vector or data frame (or anything else), the amount of white space does not affect the outcome. These are equivalent: d[1,2], d[1, 2], d[ 1, 2]\n\n\n\n\nColumn Referencing\nData in R data frames can also be referred to by their column names using the notation dataframe$column_name:\n\nd1$var1\n\n[1] 1 2 3 4 5\n\n\nThe data are returned as a vector (with the typical attributes of a vector: length and names).\nThis can also be used to create a new column in the data frame:\n\nd1$var4 <- 0:-4\n\nIn this example, a new column called “var4” was created, consisting of sequence numbers from zero to -4.\n\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3    a gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\n\n\n\nValue replacement\nThere are likely to be moments when you want to replace values in a data frame or vector with something else. You can do that with indexing and variable assignment.\nLet’s image that we want to assign the third value in the second column as NA. First, we index the that position, then we assign a value to it (NA in this case):\n\nd1[3, 2] <- NA\n\n\n\n\nThe matrix\nA very mile-high view of the matrix is given here because you while may encounter this, it is a less commonly used data structure in R.\nLike a data frame, a matrix is a collection of vectors all the same length, except all vectors must be the same data type (e.g. numeric, character, etc).\nAn R matrix is not strictly identical to the mathematical concept of a matrix, but if you make an R matrix consisting only of numbers, it can be used like a mathematical matrix. Furthermore, there several mathematical operations that are intended to only work on matrices such as matrix pre-multiplication %*% or extraction of a diagonal from a square matrix, diag().\nA matrix lacks some of the attributes and functionality that are possible for data frames. Columns names can be given, but they cannot be used to index columns (i.e. my_matrix$col will throw an error).\nMatrices are not commonly seen in user-facing functions in R, but within R internals, they are widely used. You may occasionally come across a package requiring a matrix or perhaps you work in a math-intensive discipline where matrix operations are part of your regular work.\n\n\n\n\n\n\nFYI: how to make a matrix\n\n\n\n\n\nA matrix can be created by providing a vector of numbers and telling it to populate a table of given dimensions:\n\nx = 1:100\nm1 <- matrix(data = x, nrow = 5, ncol = 20, byrow = TRUE)\n\n\n\n\n\n\nThe list\nThis is the least structured and hence most flexible data structure that exists in R. A list is like a closet that happens to be filled with other objects, or your kitchen sink, or the trunk of your car. It’s a collection of objects of varying sizes, types, and so on. A vector, scalar and data frame can all be combined into a list. A list can contain other lists inside of it (although this list nesting can be cumbersome to deal with).\n\nL1 <- list(v1, v2, v3, d1, m1)\nstr(L1)\n\nList of 5\n $ : int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ : chr [1:3] \"apples\" \"pears\" \"oranges\"\n $ : Named num [1:4] 1 5 7 85\n  ..- attr(*, \"names\")= chr [1:4] \"A\" \"B\" \"C\" \"A\"\n $ :'data.frame':   5 obs. of  4 variables:\n  ..$ var1: int [1:5] 1 2 3 4 5\n  ..$ var2: chr [1:5] \"a\" \"b\" NA \"b\" ...\n  ..$ var3: chr [1:5] \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n  ..$ var4: int [1:5] 0 -1 -2 -3 -4\n $ : int [1:5, 1:20] 1 21 41 61 81 2 22 42 62 82 ...\n\n\nEach list item can have a name. Or not.\n\nL1 <- list(\"number\" = v1, \"flower\" = v3, v4, \"df\" = d1, m1)\nnames(L1)\n\n[1] \"number\" \"flower\" \"\"       \"df\"     \"\"      \n\nstr(L1)\n\nList of 5\n $ number: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ flower: Named num [1:4] 1 5 7 85\n  ..- attr(*, \"names\")= chr [1:4] \"A\" \"B\" \"C\" \"A\"\n $       : chr \"violets\"\n $ df    :'data.frame': 5 obs. of  4 variables:\n  ..$ var1: int [1:5] 1 2 3 4 5\n  ..$ var2: chr [1:5] \"a\" \"b\" NA \"b\" ...\n  ..$ var3: chr [1:5] \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n  ..$ var4: int [1:5] 0 -1 -2 -3 -4\n $       : int [1:5, 1:20] 1 21 41 61 81 2 22 42 62 82 ...\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you end up with too many objects in your global environment, you can always delete them with the rm() function:\nrm(myvar)\nrm(var1, var2, var3)\nIf one object ends up with the wrong name, you can copy the object to a new name and delete the old version:\nnew <- old\nrm(old)\n\n\n\nAccessing items\nAs mentioned earlier, lists are relatively unstructured and follow fewer rules. You can access list items by their numeric position, list[[1]], or their name (if it exists), list$name.\n\nL1[[1]]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nL1$df\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3 <NA> gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\n\nOnce a list item is accessed, the normal indexing rules apply. The 4th item in the list called “L1” is a data frame.\n\nL1[[4]]\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3 <NA> gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\nL1[[4]]$var1\n\n[1] 1 2 3 4 5\n\nL1[[4]][1:2,]\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1"
  },
  {
    "objectID": "lessons/Lesson05.html#checking-the-class-of-a-data-structure",
    "href": "lessons/Lesson05.html#checking-the-class-of-a-data-structure",
    "title": "Lesson 5: Data Structures",
    "section": "Checking the class of a data structure",
    "text": "Checking the class of a data structure\nUse the class() command.\n\nclass(v1)\n\n[1] \"integer\"\n\nclass(d1)\n\n[1] \"data.frame\"\n\nclass(L1)\n\n[1] \"list\"\n\n\nYou can also explicitly ask R if an object is a specific data structure:\n\nis.data.frame(d1)\n\n[1] TRUE\n\nis.matrix(d1)\n\n[1] FALSE\n\nis.list(L1)\n\n[1] TRUE\n\nis.data.frame(L1)\n\n[1] FALSE\n\n\nCoercion from is also possible. If you find yourself working with matrices, you can convert a data.frame to a matrix. Or a function may return a matrix that you need converted back to a data frame:\n\nas.data.frame()\nas.matrix()\nas.list()"
  },
  {
    "objectID": "lessons/Lesson05.html#final-notes",
    "href": "lessons/Lesson05.html#final-notes",
    "title": "Lesson 5: Data Structures",
    "section": "Final Notes",
    "text": "Final Notes\nThere are several more object types, but these are by far the ones you are most likely to encounter and use.\n\nMore resources:\n\nFor a deeper look into vectors, read this chapter from R 4 Data Science\nTo learn more about subsetting, read this chapter from Advanced R (they are not kidding; this book is advanced.)\n\nFor a very comprehensive guide to R object types, check out the official R language manual. Warning: this manual is extremely technical! If you choose to check it out, be patient with yourself. It may take several readings to fully understand the content.\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen information is extracted from a vector, data.frame, matrix or list using these tools, the returned information can always be assigned to a new object:\n\nnew <- d1[1:2, -3]\n\nSometimes, we need that information assigned to a new object so we can it use later. Other times, printing the extracted information to the console is sufficient for meeting researcher needs."
  },
  {
    "objectID": "lessons/Lesson06.html",
    "href": "lessons/Lesson06.html",
    "title": "Special Lesson 6: R Functions & R Help",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nUnderstand how to call functions using named and positional arguments\nBe able to access help files for an R function and know how to use the information provided in a help file\n\n\n\n\n\nThe Mechanics of R Functions\nWe have thus far used a few R functions without explicitly stating how to call them properly.\nThe majority of functions in R follow this format:\n\nfunction_name(arg1, arg2, arg3)\n\nWhere “arg” refers to a function argument (that is, a piece of information the function can use).\nA function has a name, and can take several arguments within the parentheses. These argument values can be provided by providing each argument in the expected order:\n\nfunction_name(value1, value2, value3)\n\nNote that each positional argument is not being explicitly referenced. However, we can specify each argument when calling a function:\n\nfunction_name(arg1 = value1, arg2 = value2, arg3 = value3)\n\nWhen specifying the argument explicitly, we don’t have to follow the order of arguments:\n\nfunction_name(arg1 = value1, arg3 = value3, arg2 = value3)\n\nThis approach of using named arguments is very helpful when there is a very long list of potential argument and you only plan to specify a small portion of them.\nWe can also combined positional argument and named arguments:\n\nfunction_name(value1, arg3 = value3)\n\nIn this case, arg2 has been completed omitted. When an argument is not specified, that implies the default arguments for that function will be used instead. In order to find out the default argument values for a function, we need to consult the R help files.\n\n\nUsing R Help\nYou can search for a function directly using the search windows in the upper right of the “Help” pane.\nYou can also search using this notation: ?function_name.\nLet’s check out the help file for sample(), a function designed to randomly sample items and return that random sample to us.\n\n?sample\n\nHere is a screenshot of the window that hopefully popped up in your RStudio help pane:\n\nknitr::include_graphics(here::here(\"images\", \"help_sample_ex.png\"))\n\n\n\n\nAll help files follow this format\n\nDescription what the function does\nUsage how the function is called; this is where default argument may be listed\nArgument the named arguments available in the function (often the most useful part of the help file)\nDetails an optional section providing various computational details\nValue what is returned after the function is run\nReferences any technical, scientific or peer-reviewed lit references supporting the computational procedures implemented in the function\nSee Also similar functions (usually not very useful)\nExamples actual examples of the function in the wild! These are hit-or-miss on their overall utility, but when I’m desperate to understand how to properly call a function, this has helped me.\n\nAt the very bottom is the package the function came from and a link to an index of all functions associated with that package. This can come in handy when you want to browse all functions available in a package.\nLooking at the sample() help file, here is what is it telling us:\n\nThe first argument is a vector of choices for the function to sample randomly\nThe next argument is the number to sample. By default, it will return a sample the same length at the input vector of choices\nThe third argument indicates that if a vector should be sampled with replacement (that is, can items be repeatedly sampled). The default is FALSE (meaning no).\nWe can also specify the probability of sampling any item in the input vector. If we don’t provide this information, then all item is assumed to have equal probabilities of being sampled.\nIt will return a vector of the item sampled\n\n\nx <- 1:100\nx\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\nsample(x, 10, replace = TRUE)\n\n [1] 60 27 28 66 86 77 50 68  7 73\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is normal to struggle with R code. Newer users of R struggle more than seasoned users, but we all end up experiencing an apparently intractable problem, one that we cannot solve despite our best efforts. The first response may be to Google that problem (which may yield helpful information), but there are also more efficient search strategies you can employ to solve your R coding problem. Here is a blog post addressing that very topic: how to find help when we are stuck.\n\n\n\n\nBack to functions\nFunctions can return exactly one object (or none at all). If it does return an object, that can be assigned to a new object:\n\nnew <- function_name(value1, arg3 = value3)\n\nIf the output from a function is not assigned, it will be sent to the console instead (we’ve done this plenty during this workshop). Sometimes, this is fine! Maybe it is a small amount of output we are running to check data integrity. Or maybe it’s a giant data frame we deeply regret printing in the console.\n\n\nBase R and Contributed Libraries\nThis is the last section with a major focus on ‘base R’, that is the set of functions that come automatically loaded when you install and open R.\nTake a look at this long-ish cheat sheet (4 pages long!) of the many useful commands in base R. Skim through this and see if there is anything useful for you. It is meant to periodically skimmed, not studied in great detail (you’ll put yourself to sleep if you try to read it beginning to end).\nAdditionally, here is the ultimate guide to working with the R language. This is a long, highly technical document, but it is also incredibly detailed and informative. Reading this is like reading an encyclopedia - only read a a small section at a time. I do not recommend reading this beginning to end.\n\nLibraries\n\nknitr::include_graphics(here::here(\"images\", \"sokka_library.gif\"))\n\n\n\n\nBut also, the community keeps R humming and current by writing packages that extend R’s functionality. This is both awesome (the latest greatest tool is now enabled!) and bad (quality of implementation is not guaranteed and these packages are often not maintained over the long haul).\nThese packages are often made available on CRAN, the comprehensive R archive network, as well Bioconductor or via GitHub, GitLab, independent websites.\nYou can access packages on CRAN by first installing them with install.packages(\"package_name\") and then loading the package into an R session, library(package_name). Here’s an example using readr and *readxl**, packages we will use for data importation.\n\ninstall.packages(c(\"readr\", \"readxl\"))\nlibrary(readr)\nlibrary(readxl)\n\nNote that multiple packages can be listed in the install.packages() command, but not library(). Also, packages only need to be installed once, not repeatedly (unless a package needs to be a updated to the latest version). However, packages must be loaded in every R session or their functionality (including the help files) is not available.\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen you search for something in the Help pane, several types of help files will result: vignettes and function documentation. Function documentation is what we have just reviewed (detailed information on how to use a function). Vignettes are examples of how to use a collection of function in a package. They provide more context and a programmatic flow for using a package or accomplishing a particular goal. They are package tutorials. Vignettes are not provided for every function or every package; they are an extra feature that package authors choose to create for users.\nThere is an enormous number of R packages available! There are a few options for finding packages relevant to your work: * CRAN Task Views * Bioconductor Workflows"
  },
  {
    "objectID": "lessons/Lesson07.html",
    "href": "lessons/Lesson07.html",
    "title": "Lesson 7: Importing Data into R",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nknow how to set your working directory\nknow how to specify a file path\nBe able to import CSV and Excel files into R\nunderstand the main arguments for importing .xlsx, .xls and .csv files"
  },
  {
    "objectID": "lessons/Lesson07.html#working-directory-and-file-paths",
    "href": "lessons/Lesson07.html#working-directory-and-file-paths",
    "title": "Lesson 7: Importing Data into R",
    "section": "Working directory and file paths",
    "text": "Working directory and file paths\nWhile you can simulate data or load existing data sets associated with packages for your research, most of you will need to load pre-existing data sets from you computer, or a cloud server, some other external device.\nThe first thing you need to understand is the working directory and file paths. When an R session is initiated, it ascertains what the root working directory is based on the default settings for your R installation and any other.\nYou can check this with getwd(). You can set the file path relative to the current working directory or set an absolute path (that is, independent of your current directory). You can read more about absolute and relative paths here.\nWhen opening an R project (an .Rproj file), the working directory is automatically set to the directory where the .Rproj is located. Otherise, you can set the working directory using setwd() or under “Session” in the RStudio Ribbon.\n\nQuarto files and the {Here} package\nWhen working with an R notebook like a Quarto document or an Rmarkdown document, the working directory within code chunks is automatically set to where the quarto document is located on your file system. This is the case regardless of whether you set the working directory or where the .Rproj file is located.\nTo import a data set located in another directory from where the quarto document is located, you can use bash strategies for navigating up and down directory structures (e.g. “../data/somefile.csv”). Another solution is to use the here.\nThe function here() in the here package will reconstruct a path based on the system you are using (Windows, Mac, Linux, etc). Each directory must be specified and the final item specified is the file to import.\n\nlibrary(here)\n\nhere() starts at /home/runner/work/r-for-ag-scientists/r-for-ag-scientists\n\nhere(\"directory1\", \"subdirectory\", \"my_file.txt\")\n\n[1] \"/home/runner/work/r-for-ag-scientists/r-for-ag-scientists/directory1/subdirectory/my_file.txt\"\n\n\nIf you don’t want to load an entire package, but use the function from it, you can use the notation package_name::function(). The code below uses that when calling the here() function: here::here()."
  },
  {
    "objectID": "lessons/Lesson07.html#how-to-import",
    "href": "lessons/Lesson07.html#how-to-import",
    "title": "Lesson 7: Importing Data into R",
    "section": "How to Import",
    "text": "How to Import\nThere are several ways to import data into R.\n\nUse the “Import Dataset” tool in the Environment pane.\n\n\nknitr::include_graphics(here::here(\"images\", \"import_dataset_enviro.png\"))\n\n\n\n\n\nUse the Files pane in RStudio\n\n\nknitr::include_graphics(here::here(\"images\", \"import_dataset_file.png\"))\n\n\n\n\nBoth of them open a new window that looks like this:\n\nknitr::include_graphics(here::here(\"images\", \"import_dataset_window.png\"))\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhile these point-and-click interfaces are very convenient, they don’t automatically leave a trail of breadcrumbs to help you repeat the process in the future. But, they do generate R code that we can capture and reuse. They are handy shortcuts that I have found especially helpful when trying to import file formats I work with rarely.\n\n\n\nManual command line import\n\nUltimately, this is how anything is imported into R. As mentioned, first two options listed above are actually tools for generating code that will import a data set through the command-line!\nThere’s 4 common approaches for importing data into R:\n\nread.csv()\nread_csv()\nread_excel()\nread_delim()\n\n\nread.csv()\nA very commonly used function for reading in “comma separated values” (CSV) files. I personally like this format because it is not proprietary and is compatible across many operating systems. It also limits all sorts of extraneous formatting that itself is a barrier to reproducible research (e.g. highlighting is discarded once a CSV file is closed).\nExample usage:\n\nmycsv1 <- read.csv(here::here(\"data\", \"trial_metadata.csv\"))\n\nResult:\n\nstr(mycsv1)\n\n'data.frame':   28 obs. of  30 variables:\n $ trial             : chr  \"SWIdahoCereals_HWW_PAR_2020\" \"SWIdahoCereals_SWW_PAR_2020\" \"SWIdahoCereals_H_W_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2018\" ...\n $ program           : chr  \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ pi                : chr  \"OWalsh\" \"OWalsh\" \"OWalsh\" \"OWalsh\" ...\n $ nursery           : chr  \"HWW\" \"SWW\" \"H_W\" \"SWW\" ...\n $ year              : int  2020 2020 2018 2018 2018 2018 2016 2016 2016 2017 ...\n $ location          : chr  \"Parma\" \"Parma\" \"Parma\" \"Parma\" ...\n $ grower_cooperator : chr  \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" ...\n $ irrigation        : chr  \"irrigated\" \"irrigated\" \"irrigated\" \"irrigated\" ...\n $ latitude          : num  43.8 43.8 43.8 43.8 43.8 ...\n $ longitude         : num  -117 -117 -117 -117 -117 ...\n $ planting_date     : chr  \"2019-10-07\" \"2019-10-07\" \"2017-10-25\" \"2017-10-25\" ...\n $ harvest_date      : chr  \"2020-07-21\" \"2020-07-21\" \"2018-07-17\" \"2018-07-17\" ...\n $ plot_length       : int  17 17 17 17 17 17 17 17 17 17 ...\n $ plot_width        : int  5 5 5 5 5 5 5 5 5 5 ...\n $ agronomic_notes   : logi  NA NA NA NA NA NA ...\n $ chemical_trts     : logi  NA NA NA NA NA NA ...\n $ free_lime_pct     : logi  NA NA NA NA NA NA ...\n $ k_ppm             : logi  NA NA NA NA NA NA ...\n $ n_lbs_acre        : logi  NA NA NA NA NA NA ...\n $ npks_lb_acre      : logi  NA NA NA NA NA NA ...\n $ p_ppm             : logi  NA NA NA NA NA NA ...\n $ ph                : logi  NA NA NA NA NA NA ...\n $ previous_crop     : logi  NA NA NA NA NA NA ...\n $ row_spacing_in    : logi  NA NA NA NA NA NA ...\n $ s_ppm             : logi  NA NA NA NA NA NA ...\n $ seed_rate_per_acre: logi  NA NA NA NA NA NA ...\n $ seed_trt          : logi  NA NA NA NA NA NA ...\n $ soil.type         : logi  NA NA NA NA NA NA ...\n $ soil_om           : logi  NA NA NA NA NA NA ...\n $ exp_design        : chr  \"RCBD\" \"RCBD\" \"RCBD\" \"RCBD\" ...\n\n\nDetails:\nread.csv() is actually a “wrapper” for another function, read.table(). It has taken read.table() and set the default arguments to work with CSV files. read.table() is a more generalized form providing more flexibility.\nThe default arguments include:\n\ncolnames = TRUE: the first row of data is assumed to be the column names * nothing in the data set will be used for row names unless we explicitly indicate so\nsep = \",\": each data point is separated from another by a comma * a newline indicator is used to separate rows of data\nna.strings = c(\"NA\", \"\"): cells with a either no data (““) or an”NA” will be treated as missing.\nif a column of data consists of non-numeric characters, that column vector will be treated as character and not a factor\n\n\n\nread_csv()\nThis function is part of readr. It has very similar functionality to read.csv(), but it parses the data a wee bit different.\nExample Usage:\nFirst, load the package readr that contains the function read_csv().\n\nlibrary(readr)\nmycsv2 <- read_csv(here::here(\"data\", \"trial_metadata.csv\"))\n\nRows: 28 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (8): trial, program, pi, nursery, location, grower_cooperator, irrigat...\ndbl   (5): year, latitude, longitude, plot_length, plot_width\nlgl  (15): agronomic_notes, chemical_trts, free_lime_pct, k_ppm, n_lbs_acre,...\ndate  (2): planting_date, harvest_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nResult:\n\nstr(mycsv2)\n\nspc_tbl_ [28 × 30] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trial             : chr [1:28] \"SWIdahoCereals_HWW_PAR_2020\" \"SWIdahoCereals_SWW_PAR_2020\" \"SWIdahoCereals_H_W_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2018\" ...\n $ program           : chr [1:28] \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ pi                : chr [1:28] \"OWalsh\" \"OWalsh\" \"OWalsh\" \"OWalsh\" ...\n $ nursery           : chr [1:28] \"HWW\" \"SWW\" \"H_W\" \"SWW\" ...\n $ year              : num [1:28] 2020 2020 2018 2018 2018 ...\n $ location          : chr [1:28] \"Parma\" \"Parma\" \"Parma\" \"Parma\" ...\n $ grower_cooperator : chr [1:28] \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" ...\n $ irrigation        : chr [1:28] \"irrigated\" \"irrigated\" \"irrigated\" \"irrigated\" ...\n $ latitude          : num [1:28] 43.8 43.8 43.8 43.8 43.8 ...\n $ longitude         : num [1:28] -117 -117 -117 -117 -117 ...\n $ planting_date     : Date[1:28], format: \"2019-10-07\" \"2019-10-07\" ...\n $ harvest_date      : Date[1:28], format: \"2020-07-21\" \"2020-07-21\" ...\n $ plot_length       : num [1:28] 17 17 17 17 17 17 17 17 17 17 ...\n $ plot_width        : num [1:28] 5 5 5 5 5 5 5 5 5 5 ...\n $ agronomic_notes   : logi [1:28] NA NA NA NA NA NA ...\n $ chemical_trts     : logi [1:28] NA NA NA NA NA NA ...\n $ free_lime_pct     : logi [1:28] NA NA NA NA NA NA ...\n $ k_ppm             : logi [1:28] NA NA NA NA NA NA ...\n $ n_lbs_acre        : logi [1:28] NA NA NA NA NA NA ...\n $ npks_lb_acre      : logi [1:28] NA NA NA NA NA NA ...\n $ p_ppm             : logi [1:28] NA NA NA NA NA NA ...\n $ ph                : logi [1:28] NA NA NA NA NA NA ...\n $ previous_crop     : logi [1:28] NA NA NA NA NA NA ...\n $ row_spacing_in    : logi [1:28] NA NA NA NA NA NA ...\n $ s_ppm             : logi [1:28] NA NA NA NA NA NA ...\n $ seed_rate_per_acre: logi [1:28] NA NA NA NA NA NA ...\n $ seed_trt          : logi [1:28] NA NA NA NA NA NA ...\n $ soil type         : logi [1:28] NA NA NA NA NA NA ...\n $ soil_om           : logi [1:28] NA NA NA NA NA NA ...\n $ exp_design        : chr [1:28] \"RCBD\" \"RCBD\" \"RCBD\" \"RCBD\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   trial = col_character(),\n  ..   program = col_character(),\n  ..   pi = col_character(),\n  ..   nursery = col_character(),\n  ..   year = col_double(),\n  ..   location = col_character(),\n  ..   grower_cooperator = col_character(),\n  ..   irrigation = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double(),\n  ..   planting_date = col_date(format = \"\"),\n  ..   harvest_date = col_date(format = \"\"),\n  ..   plot_length = col_double(),\n  ..   plot_width = col_double(),\n  ..   agronomic_notes = col_logical(),\n  ..   chemical_trts = col_logical(),\n  ..   free_lime_pct = col_logical(),\n  ..   k_ppm = col_logical(),\n  ..   n_lbs_acre = col_logical(),\n  ..   npks_lb_acre = col_logical(),\n  ..   p_ppm = col_logical(),\n  ..   ph = col_logical(),\n  ..   previous_crop = col_logical(),\n  ..   row_spacing_in = col_logical(),\n  ..   s_ppm = col_logical(),\n  ..   seed_rate_per_acre = col_logical(),\n  ..   seed_trt = col_logical(),\n  ..   `soil type` = col_logical(),\n  ..   soil_om = col_logical(),\n  ..   exp_design = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nDetails:\nThis function takes similar arguments to read.csv(), although the output is more extensive.\n\nLike in read.csv(), the default separator is “,”, missing datea are coded as empty string \"\" or NA and the first line is assumed to be the column header\nit does not bother with a row names attribute\nthe argument trim_ws will remove leading and trailing whitespace for data entries. So the column header ” soil pH” will become “soil pH”.\nColumn are preserved more clearly than read.csv() (including spaces and special characters). I’m honestly not fond of this behavior and usually clean up weird column names with janitor::clean_names().\n\nThe output is largely similar, although read_csv() actually parses dates, unlike read.csv().\n\n\nread_excel()\nThis function will read in MS Excel files (reliably)! It is truly amazing. For many many years, it was cumbersome and/or impossible to read Excel files direclty into R.\nExample Usage:\nLoad the package that contains the function read_excel(), readxl.\n\nlibrary(readxl)\nmyxl <- read_excel(here::here(\"data\", \"field_trial_2009.xlsx\"), \n                   sheet = \"site_02\", \n                   trim_ws = TRUE, \n                   na = c(\"\", \"NA\"))\n\nResults:\n\nstr(myxl)\n\ntibble [80 × 30] (S3: tbl_df/tbl/data.frame)\n $ plot    : num [1:80] 1 2 3 4 5 6 7 8 9 10 ...\n $ bloc    : num [1:80] 1 1 1 1 1 1 1 1 1 1 ...\n $ rep     : num [1:80] 1 1 1 1 1 1 1 1 1 1 ...\n $ Ptrt    : chr [1:80] \"high\" \"high\" \"high\" \"high\" ...\n $ inoc    : chr [1:80] \"myco\" \"myco\" \"myco\" \"myco\" ...\n $ Cv      : chr [1:80] \"OTIS\" \"ALPOWA\" \"BlancaG\" \"WALWORTH\" ...\n $ order   : num [1:80] 1 2 3 4 5 17 18 16 20 19 ...\n $ height  : num [1:80] 49 48.7 40.3 45.7 59 ...\n $ spikes  : num [1:80] NA 240 192 360 216 340 220 228 208 256 ...\n $ tstwt   : num [1:80] 61.9 61.2 61.3 60.6 61.7 60.2 61.2 61.2 62.1 62.1 ...\n $ HI      : num [1:80] 0.385 0.375 0.444 0.385 0.481 0.387 0.5 0.5 0.474 0.409 ...\n $ YieldKg : num [1:80] 1144 1274 1026 1026 922 ...\n $ YieldBu : num [1:80] 16.5 18.5 14.9 15.1 13.3 ...\n $ tkw     : num [1:80] 35.1 32.2 37.6 30.8 40.1 ...\n $ myco    : num [1:80] 37.5 30 35.7 15.4 14.3 ...\n $ PT1     : num [1:80] 4391 4500 4546 3436 4121 ...\n $ PT2     : num [1:80] 1040 726 605 702 1036 ...\n $ PT3     : num [1:80] 375 85.5 315.6 247.4 161.9 ...\n $ Pseeds  : num [1:80] 3182 2523 3156 3389 2473 ...\n $ cruc    : num [1:80] 6 10 4 5 2 3 9 7 39 66 ...\n $ Cu      : num [1:80] 6.11 4.72 5.99 5.69 4.48 ...\n $ Fe      : num [1:80] 46.4 27.2 46.8 36.5 34.2 ...\n $ Mn      : num [1:80] 28 21.5 28.2 28.4 23.8 ...\n $ Zn      : num [1:80] 16.2 14.2 18.3 22.1 15.1 ...\n $ Protein : num [1:80] 14.3 12.7 14.7 16.3 12 ...\n $ SDS     : num [1:80] 9.9 9.9 13.1 12.5 9.6 13.7 13.4 9.3 9.6 10.2 ...\n $ PT1_2   : num [1:80] 4371 4455 4442 3481 4146 ...\n $ PT2_2   : num [1:80] 968 659 544 635 965 ...\n $ PT3_2   : num [1:80] 387 104 328 262 179 ...\n $ Pseeds_2: num [1:80] 3103 2482 3083 3296 2434 ...\n\n\nDetails\n\nBy default, read_excel() will import the first sheet unless it named by position (e.g. 1, 2, 3) or name (like in the previous example).\nThe default argument for missing values is only an empty string \"\"\nIt returns results very similar to read_csv().\nThere is also an argument, range for setting a custom range of cells to read in.\n\n\n\nread_delim()\nFor reading in text files! It’s pretty simple. Text files are not used terribly frequently, but I see them now and then with really huge files, such as genotyping data.\n\nmytxt <- read.delim(here::here(\"data\", \"genotypic_data.txt\"))\n\nDetails\nThis function is a more extensive version of read.csv(). It has a longer list of argument and slight different default values for those arguments that read.csv. Run ?write.delim in the console for more details.\n\n\n\n\n\n\nNote\n\n\n\nIt’s useful to understand how R has read a data set into an R session. R has opened a connection to the file that you have specified, read file information into the R session using system memory (your computer’s RAM), and then closed the connection.\nThis is a one-way process from your file to R\nOnce a file is loaded and the connection closed, there is no longer any link between the object loaded into memory in R and its origin file (located on on your computer, a cloud server, etc). Any changes made to the object in R will not change the file on your computer unless you explicitly run scripts to overwrite that file. This is good thing; it gives you freedom to experiment with and manipulate an object without worrying about messing up the original file.\nWe will discuss later how to export R objects to your file system when you want to capture changes made to an object.\n\n\n\n\nTroubleshooting Import errors\nThings frequently go wrong when importing data. This can sometimes be corrected by changing the import arguments, but often it indicates problems with the incoming data.\nSome possible errors and how to fix them:\n\nSome variables which should be numeric are characters instead. At least one item contains an unexpected character that renders that observation - and the rest of the vector - as a character. This might be two decimal points, a comma, or a “O” instead of “0”. If possible, manually inspect the data and correct the error.\nMissing data are not coded as missing. Import functions have default values for what is interpreted as missing. Check the documentation and adjust the arguments as needed to capture what code a data sets is using to indicate missing data.\n\nThe best choice is to properly arrange your data set prior to import. Broman & Woo (2018) provides some straightforward recommendations on how to manage data in spreadsheets.\n\n\nImporting Other Data types\nThe instructions provided above are for importing tabular data that is generally not “big data”.\nBig data is a subjective term that is system-dependent (and is rapidly changing as PC computing power and memory increases). Some personal computers can easily handle a 50 Mb file, while others cannot. If you are waiting more than 5 seconds for your data to import, then consider other options. A deep discussion about how to handle large data sets are beyond the scope of this workshop, but at the very minimum, consider the package data.table and its high-performance functions for reading and writing data, fread() and fwrite(). If your data sets are too big to load directly into R, consider arrow.\nYou may also be working with data types that are not strictly tabular, at least in the form they are stored on a computer. Here are some common non-tabular data types and packages to handle import of those.\n\nspatial data: sf, sp, raster\nSAS data sets: haven, haven::read_sas()\nSPSS data sets: haven, haven::read_sav()\ntabular files on Google drive: googledrive\nimage files: magick\n\n…and so much more.\n\n\n\n\n\n\nPutting it all together\n\n\n\nNote how easy it is to import data from the ‘Files’ pane; navigate to the file and click on it! It’s important that that the code generated is saved so (1) you can reuse the code; and (2) so you can link the data set loaded to a set of R commands you ran should you ever need to rerun them (which is highly likely)."
  },
  {
    "objectID": "lessons/Lesson08.html",
    "href": "lessons/Lesson08.html",
    "title": "Lesson 8: Exporting Data",
    "section": "",
    "text": "This lesson is focused on exporting tabular data. It is a very short lesson because exporting data is quite similar to importing data. Like in data import, exporting data involves opening a connection between R and file system, writing the data to file and closing the connection.\nFirst, we need to load some data to write to file. R packages often come with data sets that can loaded with the data() command."
  },
  {
    "objectID": "lessons/Lesson08.html#exporting-to-csv-files",
    "href": "lessons/Lesson08.html#exporting-to-csv-files",
    "title": "Lesson 8: Exporting Data",
    "section": "Exporting to CSV files",
    "text": "Exporting to CSV files\n\nwrite.csv()\nFirst, check the documentation: ?write.csv\n\nwrite.csv(mtcars, here::here(\"outputs\", \"mtcars_1.csv\"), row.names = FALSE)\n\nSetting the row.names argument to FALSE ensures that a column of numbers without a header is not included in the file (which is likely to cause import errors in the future).\n\n\nwrite.table()\nThis function looks very similar to write.csv() because it is technically the same function. write.csv() is wrapper for write.table() using a specific set of default arguments for CSV files (e.g. sep = \",\"). In this case, we cannot rely on those default and must specify\n\nwrite.table(mtcars, here::here(\"outputs\", \"mtcars_2.csv\"), \n          row.names = FALSE, sep = \",\", quote = FALSE)\n\n\n\nwrite_csv()\nThis function is very similar to read.csv(), but it does not have a row names argument because it does not output rownames.\n\nlibrary(readr)\n\nwrite_csv(mtcars, here::here(\"outputs\", \"mtcars_3.csv\"))\n\nwrite_csv() is wrapper for write_delim()."
  },
  {
    "objectID": "lessons/Lesson08.html#exporting-to-text-file",
    "href": "lessons/Lesson08.html#exporting-to-text-file",
    "title": "Lesson 8: Exporting Data",
    "section": "Exporting to text file",
    "text": "Exporting to text file\nThis also uses write.table() or write.table():\n\nwrite.table(mtcars, here::here(\"outputs\", \"mtcars.txt\"), sep = \"\\t\",\n            quote = \"none\")\n\nwrite_delim(mtcars, here::here(\"outputs\", \"mtcars.txt\"), delim = \"\\t\",\n            quote = \"none\")"
  },
  {
    "objectID": "lessons/Lesson08.html#exporting-to-excel-file",
    "href": "lessons/Lesson08.html#exporting-to-excel-file",
    "title": "Lesson 8: Exporting Data",
    "section": "Exporting to Excel file",
    "text": "Exporting to Excel file\nUse the writexl package:\n\nlibrary(writexl)\n\nwrite_xlsx(mtcars, here::here(\"outputs\", \"mtcars.xlsx\"))\n\nThe help file is informative: ?write_xlsx"
  },
  {
    "objectID": "lessons/Lesson08.html#other-options",
    "href": "lessons/Lesson08.html#other-options",
    "title": "Lesson 8: Exporting Data",
    "section": "Other options",
    "text": "Other options\n\nsave()\nThis is special option to save objects in your environment to file. These can only be used by R, but are convenient if you plan to return to these object:\nSave one object:\n\nsave(mtcars, file = here::here(\"outputs\", \"mydata.RData\"))\n\nSave multiple objects:\n\ndata(\"sleep\")\nsave(mtcars, sleep, file = here::here(\"outputs\", \"more.RData\"))\n\nThese can be loaded back into an R session as thus:\n\nload(here::here(\"outputs\", \"mydata.RData\"))\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are working with a specialized file type that has dedicated libraries for importing them into R and manipulating those objects, those dedicated libraries likely have export functions for that file type. For spatial object, the package sf can import, alter, and export shapefiles.\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nExporting data is a good thing to do during the data wrangling process. Once you have arranged in your data set into an ideal state, save it so you an easily reload it later.\nIt is very important that you check your output file (especially as a newer R programmer!) to make sure everything is as you expect. We have all accidentally output “myfile” instead of “myfile.csv”, and this can be highly inconvenient! You can do by manually opening the file or by importing back into R; either should tell you if the file export went as expected or not."
  },
  {
    "objectID": "lessons/Lesson09.html",
    "href": "lessons/Lesson09.html",
    "title": "Lesson 9: Introduction to Data Wrangling",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to select columns in R using select()\nbe able to filter a data set using filter()\nbe aware of how to conditionally create new variables using case_when()\nknow to create new variables using mutate()\nbe able to rename variables using rename()\nbe able to sort a data set using arrange()\nbe table to use separate() to split up single variables into multiple variables\n\n\n\n\nFirst, load libraries:\nNext, import data:\n\nvariety_trials <- read.csv(here::here(\"data\", \"trial_data.csv\"))\nweather <- read.csv(here::here(\"data\", \"weather_data.csv\"))\n\n\n\n\n\n\n\nWhat is going on with here::here()?\n\n\n\n\n\nThe here() function is from the here package. This package simplifies working directory issues by setting it to where the nearest .Rproj files exists. When using a .qmd file, it looks for the .Rproj file that is the same directory as that file and moves up the directory tree.\n\n\n\n\nTidyverse notes\nThis lesson relies on group of packages called the “Tidyverse”, in particular dplyr and tidyr.\nThese packages follow a special set of rules called “non-standard evaluation” (sometimes abbreviated “NSE”). Tidyverse non-standard evaluation uses quotes far less often than “base R” (base R are package that are installed automatically when R is updated). It also uses indexing $ less frequently. You can name a variable directly instead of using dataset$var.\nMany functions in the Tidyverse follow this structure:\nfunction(dataset, action)\nWhere “dataset” is the data framed being input and “action” is whatever action is being taken.\n\n\nSelection columns\nThe function select is used to specify column you want to keep (all rows are returned). Columns can be specified by name or position (i.e. the first two columns in the data set would be 1:2).\nSelect by name:\n\nselect1 <- select(variety_trials, variety, yield, grain_protein)\nhead(select1)\n\n     variety     yield grain_protein\n1   LCS Iron  78.27131        14.250\n2   LCS Iron 124.19389        14.592\n3   LCS Iron  85.20458        15.105\n4   LCS Iron 140.56490        14.364\n5 10SB0087-B  94.18977        13.053\n6 10SB0087-B 121.59047        13.794\n\n\nYou can also select on what columns you do not want:\n\nselect2 <- select(variety_trials, -trial)\nselect3 <- select(variety_trials, -c(trial, plot))\n\nhead(select2); head(select3)\n\n  rep entry    variety     yield grain_protein test_weight flag row range plot\n1   1     1   LCS Iron  78.27131        14.250          NA <NA>  NA    NA   NA\n2   2     1   LCS Iron 124.19389        14.592          NA <NA>  NA    NA   NA\n3   3     1   LCS Iron  85.20458        15.105          NA <NA>  NA    NA   NA\n4   4     1   LCS Iron 140.56490        14.364          NA <NA>  NA    NA   NA\n5   1     2 10SB0087-B  94.18977        13.053          NA <NA>  NA    NA   NA\n6   2     2 10SB0087-B 121.59047        13.794          NA <NA>  NA    NA   NA\n\n\n  rep entry    variety     yield grain_protein test_weight flag row range\n1   1     1   LCS Iron  78.27131        14.250          NA <NA>  NA    NA\n2   2     1   LCS Iron 124.19389        14.592          NA <NA>  NA    NA\n3   3     1   LCS Iron  85.20458        15.105          NA <NA>  NA    NA\n4   4     1   LCS Iron 140.56490        14.364          NA <NA>  NA    NA\n5   1     2 10SB0087-B  94.18977        13.053          NA <NA>  NA    NA\n6   2     2 10SB0087-B 121.59047        13.794          NA <NA>  NA    NA\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe variables specified in select() will appear in the new data frame in exactly the order they were listed in the function call.\n\n\nSometimes, you might want to select many columns that share something common about their name:\n\nselect4 <- select(variety_trials, starts_with(\"r\"))\nhead(select4)\n\n  rep row range\n1   1  NA    NA\n2   2  NA    NA\n3   3  NA    NA\n4   4  NA    NA\n5   1  NA    NA\n6   2  NA    NA\n\n\nThis particular example is not all that useful, but you might have a large data set, with several dozen variables that all start with “snp” followed by some alpha-numeric code (e.g. “snp4738”). This function will enable you to select these column more efficiently than naming every single one.\nThere are more options for pattern matching on column names:\n\n?tidyselect::starts_with #another option for searching help from the R console\n\n\n\n\n\n\n\n\nFiltering rows\nThe function filter is used to specify rows you want to keep (all columns are returned). This command uses logical operators for deciding what to keep.\n\nfilter1 <- filter(variety_trials, variety == \"Stephens\") # match one name\nfilter2 <- filter(variety_trials, variety %in% c(\"Stephens\", \"Bobtail\")) # match multiple names\nfilter3 <- filter(variety_trials, yield > 50 & grain_protein <= 14) # filter on multiple conditions\n\ndim(filter1); dim(filter2); dim(filter3)\n\n[1]  4 11\n\n\n[1] 16 11\n\n\n[1] 1017   11\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is also possible to select by numeric position:\n\nselect(variety_trials, c(1:3, 4))\n\nWhile selecting by numeric position works, it is an unreliable choice because it depends on column order or row order being exactly as you expect it. This may work the first time you write + run code, but it is likely to fail over time as you sort, augment or change data sets.\n\n\n\n\nCreating new variables\nYou can quite create new variables with a mutate() function call:\nmutate(dataset, var_name = variable)\nExamples:\n\nnew_var <- rbinom(n = nrow(variety_trials), size = 1, prob = 0.5)\n\nmutate1 <- mutate(variety_trials, \n                    dataset = \"example\",\n                    row_position = 1:n(),\n                    range_new = range,\n                    random_yield = yield + rnorm(n = n()),\n                    binom_var = new_var, \n                    yield_protein = yield + grain_protein)\n\ntable(new_var)\n\nnew_var\n  0   1 \n944 938 \n\nhead(mutate1)\n\n                        trial rep entry    variety     yield grain_protein\n1 SWIdahoCereals_HRS_PAR_2016   1     1   LCS Iron  78.27131        14.250\n2 SWIdahoCereals_HRS_PAR_2016   2     1   LCS Iron 124.19389        14.592\n3 SWIdahoCereals_HRS_PAR_2016   3     1   LCS Iron  85.20458        15.105\n4 SWIdahoCereals_HRS_PAR_2016   4     1   LCS Iron 140.56490        14.364\n5 SWIdahoCereals_HRS_PAR_2016   1     2 10SB0087-B  94.18977        13.053\n6 SWIdahoCereals_HRS_PAR_2016   2     2 10SB0087-B 121.59047        13.794\n  test_weight flag row range plot dataset row_position range_new random_yield\n1          NA <NA>  NA    NA   NA example            1        NA     78.16129\n2          NA <NA>  NA    NA   NA example            2        NA    124.46183\n3          NA <NA>  NA    NA   NA example            3        NA     87.37132\n4          NA <NA>  NA    NA   NA example            4        NA    139.13330\n5          NA <NA>  NA    NA   NA example            5        NA     94.22276\n6          NA <NA>  NA    NA   NA example            6        NA    121.79668\n  binom_var yield_protein\n1         0      92.52131\n2         0     138.78589\n3         1     100.30958\n4         0     154.92890\n5         0     107.24277\n6         0     135.38447\n\n\nThis created 6 new variables:\n\ndataset which is a character with the value “example” for all rows\nrow_position providing the row number, starting at 1 and ending at n(), a function that returns the total nubmer of rows in the data frame\nrange_new which is a copy of the variable “range”\nrandom_yield which is the sum of the value for yield plus a random deviation from the function rnorm. This operation is vectorized, using the ‘yield’ measurement for each row and generating a new random deviate for each row.\nbinom_var the binomial outcomes variable created in the new_var .... statement.\nyield_protein the addition of two variables in the data set (this is also vectorized, calculating this for each row)\n\nThese example cover the majority of what you are likely to experience: creating a constant, calculating new variables from existing variables, pulling in an external variables, and so forth.\nThis is equivalent to what was taught earlier using “$” notation:\n\nmutate1 <- variety_trials # first, copy the data frame\nmutate1$dateset <- \"example\"\nmutate1$row_position <- 1:nrow(mutate1)\nmutate1$range_new <- mutate1$range_new # note that NSE cannot be used\nmutate1$random_yield <- mutate1$yield + rnorm(nrow(mutate1))\nmutate1$binom_var = new_var\nmutate1$yield_protein <- mutate1$yield + mutate1$grain_protein\n\nThis can be a bit longer and cumbersome compared to mutate statements, but it does work.\n\ncase_when(), a special addition to mutate statements\nOccasionally, you will need a define a variable conditionally, based on information from other variables. Here is an example for weather data. Here, a special minimum value is created where all data for “tmin_F” less than 50°F are set at 50:\n\nweather <- mutate(weather, new_min = case_when(\n  tmin_F <= 50 ~ 50,\n  TRUE ~ tmin_F))\n\nEverything to the left of the tilde ~ is a logical expression to evaluate. Everything to the right of the tilde is the value to put if the logical expression evaluates to TRUE.\nThis can easily become more complex with the addition of other logical expressions and categorical levels to create.\nIf you have a categorical variable that needs further refinement (e.g. collapsing of multiple levels into one), check out the package forcats, which provides many functions for manipulating categorical (factor or character) variables.\n\n\n\nRenaming Variables\nCompared to mutate(), the function for renaming variables, rename(), is a breeze!\nrename(dataset, new_name = \"old_name\")\nThis is similar to variable assignment:\nnew_name <- old_name\nExcept that quotes are always used when specifying the old variable name.\nExample:\n\nrename1 <- rename(variety_trials, cultivar = \"variety\")\nhead(rename1, 3)\n\n                        trial rep entry cultivar     yield grain_protein\n1 SWIdahoCereals_HRS_PAR_2016   1     1 LCS Iron  78.27131        14.250\n2 SWIdahoCereals_HRS_PAR_2016   2     1 LCS Iron 124.19389        14.592\n3 SWIdahoCereals_HRS_PAR_2016   3     1 LCS Iron  85.20458        15.105\n  test_weight flag row range plot\n1          NA <NA>  NA    NA   NA\n2          NA <NA>  NA    NA   NA\n3          NA <NA>  NA    NA   NA\n\n\nAlso, you can use rename notation in select statements:\n\nrename2 <- select(variety_trials, cultivar = \"variety\", yield, protein = \"grain_protein\")\n\nThis function selected the columns “variety”, “yield” and “grain_protein”, while renaming “variety to”cultivar” and “grain_protein” to “protein” - a handy shortcut.\n\n\nSplit up variables\nYou may encounter variables with information about multiple things. In agriculture, I see variables with values such as “Moscow_2021”, “Moscow_2022”, “StJohn_2021”, “StJohn_2022”. This variables is indicating multiple things - location and year in this exmample. This is a useful variable by itself, but a researcher might want to separate out location and year for other analytical purposes. The tidyr function separate() can do that.\nThe first column of “variety_trials” contains considerable information, all separated by an underscore:\n\nvariety_trials$trial[1]\n\n[1] \"SWIdahoCereals_HRS_PAR_2016\"\n\n\nThe first term is the program conducting the trial, the second is the crop grown, the third term is a location code, and the last term is the year. Let’s separate those terms into separate columns/variables.\nBefore running a separate() command, always check the variable to make sure it is structured as you expect.\nUse distinct() to determine the unique observations for the column “trial” in the the object “variety_trials”.\n\ndistinct(variety_trials, trial)\n\n                         trial\n1  SWIdahoCereals_HRS_PAR_2016\n2  SWIdahoCereals_HWS_PAR_2016\n3  SWIdahoCereals_SWS_PAR_2016\n4  SWIdahoCereals_H_W_PAR_2017\n5  SWIdahoCereals_HRS_PAR_2017\n6  SWIdahoCereals_HWS_PAR_2017\n7  SWIdahoCereals_SWS_PAR_2017\n8  SWIdahoCereals_SWW_PAR_2017\n9  SWIdahoCereals_H_S_PAR_2018\n10 SWIdahoCereals_H_W_PAR_2018\n11 SWIdahoCereals_SWS_PAR_2018\n12 SWIdahoCereals_SWW_PAR_2018\n13 SWIdahoCereals_H_S_WEI_2018\n14 SWIdahoCereals_H_W_WEI_2018\n15 SWIdahoCereals_SWS_WEI_2018\n16 SWIdahoCereals_SWW_WEI_2018\n17 SWIdahoCereals_HRS_PAR_2019\n18 SWIdahoCereals_HRW_PAR_2019\n19 SWIdahoCereals_HWS_PAR_2019\n20 SWIdahoCereals_HWW_PAR_2019\n21 SWIdahoCereals_SWS_PAR_2019\n22 SWIdahoCereals_SWW_PAR_2019\n23 SWIdahoCereals_HRS_PAR_2020\n24 SWIdahoCereals_HRW_PAR_2020\n25 SWIdahoCereals_HWS_PAR_2020\n26 SWIdahoCereals_HWW_PAR_2020\n27 SWIdahoCereals_SWS_PAR_2020\n28 SWIdahoCereals_SWW_PAR_2020\n\n\nThe variable variety_trials$trial uses an underscore to separate its components. However, one of the terms we mean to keep as one component does have an underscore inside of it, which will interpreted incorrectly as a term separator. The function gsub() can be used to fix this.\n\nvariety_trials$trial <- gsub(pattern = \"_H_\", replacement = \"_H-\", x = variety_trials$trial)\n\nNow, separate() will split the variable into 4 components:\n\nvariety_trials <- separate(variety_trials, trial, \n                           into = c(\"program\", \"crop\", \"location\", \"year\"),\n                           sep = \"_\", \n                           remove = FALSE)\n\nThe argument remove = FALSE indicates that we want to keep the input variable (“trial”). By default, it would be removed.\nThe opposite function is tidyr::unite() which will paste these variable together, separate by any character string you specify. unite() also can ignore missing data when pasting information together, avoiding this unfortunate result: “some.var_NA_NA_another.var”. You would get “some.var_another.var” instead.\n\n\nSorting a data set\nPrior to dplyr, sorting in R was a nightmare. Excel makes this so easy! Why was R torturing us??? But, dplyr has made this much easier:\narrange(dataset, variable1, variable2, ....)\nYou can sort on as many variables as you like! It will sort on the first variables listed and within that, the second variable listed, and so on.\nExample;\n\narrange1 <- arrange(variety_trials, variety, yield)\n\n\nOutput file\nLet’s output this object to file so we can use it later.\n\nwrite.csv(variety_trials, here::here(\"outputs\", \"variety_trials_clean.csv\"), row.names = FALSE)\n\n\n\n\nThe pipe\nThe pipe operator %>% or its newer replacement |> are magic, or at least, they make our (data wrangling) lives so much easier.\nThe pipe operator works as thus:\noperation_1 %>% operation_2\nOne operation can be performed (e.g. a select() command), and that resulting data frame is passed on to the next operation (e.g. filter()).\nExample: filter then sort\n\npipe1 <- filter(variety_trials, yield < 75) %>% arrange(variety)\n\nThe data set is not named in the second operation because it is assumed to be dataset provided in the first operation. Whatever is being output directly left of the pipe operator is in the input data set.\nWe can take this even further by making the first operation our addition of the data set to the pipes:\n\npipe2 <- variety_trials %>% filter(yield < 75) %>% arrange(variety)\n\nThe pipe has made data wrangling so much easier! Before the pipe, each of these operations can be specified separately with its own object. So when you were done, you had roughly 50 objects in your environment, 48 of which were not needed anymore.\nIt also saved us from the “parentheses cascade” where one function is nested inside another function, which is nested within another, and so forth. It can be difficult to ascertain what parentheses belong to what operation, which often leads to coding errors. In a set of nestd functions, the inner functions are first executed and the outer functions are executed last. no longer had any sense of which set of parentheses belong to which operation.\n\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhat going on this notation?\ntibble::rownames_to_column()\nThis is a normal function call (the function being rownames_to_column()), and it is specifying that the package where this function resides is tibble (a tibble is the Tidyverse alternative to the data frame).\nYou want to use this notation in 2 circumstance:\n\nYou don’t want to load the entire package with a library() call, especially if you only need one function from it\nThe name of the function you want to call from a package conflicts with function names from another package. A very common example is filter() - this is a dplyr function, but it is also a base R function. Sometimes, you may receive a very puzzling error when using filter() that essentially is indicating that the wrong package was used. Using notation like dplyr::filter() clarified to R that you want to use the dplyr version of filter(). By default, the most recent package loaded overrides other function name conflicts, but sometiimes, it’s helpful to be unambiguous in your R function calls."
  },
  {
    "objectID": "lessons/Lesson10.html",
    "href": "lessons/Lesson10.html",
    "title": "Lesson 10: Aggregating & Summarising Data",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to aggregate data and perform actions on those aggregated data using group_by() + summarise()\nunderstand when to use rowwise() for operations\n\n\n\n\nYou may find yourself wanting to calculate summary statistics across a grouping variable. To do this, a data set needs to be split up by that variable, a summary statistic calculated, and the resulting data recombined, or ‘split-apply-combine’. There’s some nice tools to do this in the dplyr package.\n\nPrep Work\nFirst, load libraries & import data:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nvariety_trials <- read.csv(here::here(\"data\", \"trial_data.csv\")) %>% \n  mutate(trial = gsub(\"_H_\", \"_H-\", trial)) %>% \n  tidyr::separate(trial, c(\"program\", \"crop\", \"location\", \"year\"),\n                  sep = \"_\", remove = FALSE)\n\n\n\nBasic grouping & aggregation\nThe group_by will group data and then any statistic can be calculated or summary action can be done on that grouped data using summarise().\nThe basic formula:\n\nmydata %>% group_by(variable) %>% summarise(new_var = ...)\n\nThis data set has several categorical variables that can be used for grouping:\n\nstr(variety_trials)\n\n'data.frame':   1882 obs. of  15 variables:\n $ trial        : chr  \"SWIdahoCereals_HRS_PAR_2016\" \"SWIdahoCereals_HRS_PAR_2016\" \"SWIdahoCereals_HRS_PAR_2016\" \"SWIdahoCereals_HRS_PAR_2016\" ...\n $ program      : chr  \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ crop         : chr  \"HRS\" \"HRS\" \"HRS\" \"HRS\" ...\n $ location     : chr  \"PAR\" \"PAR\" \"PAR\" \"PAR\" ...\n $ year         : chr  \"2016\" \"2016\" \"2016\" \"2016\" ...\n $ rep          : int  1 2 3 4 1 2 3 4 1 2 ...\n $ entry        : int  1 1 1 1 2 2 2 2 3 3 ...\n $ variety      : chr  \"LCS Iron\" \"LCS Iron\" \"LCS Iron\" \"LCS Iron\" ...\n $ yield        : num  78.3 124.2 85.2 140.6 94.2 ...\n $ grain_protein: num  14.2 14.6 15.1 14.4 13.1 ...\n $ test_weight  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ flag         : chr  NA NA NA NA ...\n $ row          : logi  NA NA NA NA NA NA ...\n $ range        : logi  NA NA NA NA NA NA ...\n $ plot         : logi  NA NA NA NA NA NA ...\n\n\nThe function tally() counts observations:\n\nvariety_trials %>% group_by(trial) %>% tally()\n\n# A tibble: 28 × 2\n   trial                           n\n   <chr>                       <int>\n 1 SWIdahoCereals_H-S_PAR_2018    88\n 2 SWIdahoCereals_H-S_WEI_2018    96\n 3 SWIdahoCereals_H-W_PAR_2017   120\n 4 SWIdahoCereals_H-W_PAR_2018    80\n 5 SWIdahoCereals_H-W_WEI_2018    48\n 6 SWIdahoCereals_HRS_PAR_2016    60\n 7 SWIdahoCereals_HRS_PAR_2017    32\n 8 SWIdahoCereals_HRS_PAR_2019    60\n 9 SWIdahoCereals_HRS_PAR_2020    48\n10 SWIdahoCereals_HRW_PAR_2019    44\n# … with 18 more rows\n\n\nLet’s group by crop and pull out the mean yield and standard deviation.\n\nyield_crop <- variety_trials %>% group_by(crop) %>% \n  summarise(yield_mean = mean(yield, na.rm = TRUE),\n            yield_sd = sd(yield, na.rm = TRUE),\n            yield_min = min(yield, na.rm = TRUE),\n            yield_max = max(yield, na.rm = TRUE),\n            total = n())\n\nyield_crop\n\n# A tibble: 8 × 6\n  crop  yield_mean yield_sd yield_min yield_max total\n  <chr>      <dbl>    <dbl>     <dbl>     <dbl> <int>\n1 H-S         57.6     34.3    16.6        119.   184\n2 H-W         84.4     42.2     4.17       199.   248\n3 HRS        111.      38.5    56.0        498.   200\n4 HRW        136.      45.0    66.2        197.   100\n5 HWS        116.      32.0    56.6        253.   132\n6 HWW        115.      38.5    68.7        192.    76\n7 SWS        104.      42.4    12.1        219.   316\n8 SWW         94.0     43.9     0.705      201.   626\n\n\n\n\n\n\n\n\nNote\n\n\n\nsummarise() only returns a single value back for each group. If you want more than that (e.g. to run a linear model on each group), there are other tools for that. This is intended to be addressed in Lesson 16, repeating actions.\n\n\n\n\nGrouping across multiple variables\nLet’s examine how many crops and years there are using the table() command:\n\ntable(variety_trials$crop, variety_trials$year)\n\n     \n      2016 2017 2018 2019 2020\n  H-S    0    0  184    0    0\n  H-W    0  120  128    0    0\n  HRS   60   32    0   60   48\n  HRW    0    0    0   44   56\n  HWS   44   32    0   24   32\n  HWW    0    0    0   44   32\n  SWS   40   40  132   56   48\n  SWW    0  160  206  108  152\n\n\nThis tells us how many rows of data occur for each variable combination. This information can help inform us how to group information.\nYou can group by as many conditions as you want:\n\nvariety_trials %>% group_by(crop, year) %>% \n  summarise(protein_na = sum(is.na(grain_protein))) %>% arrange(desc(protein_na))\n\n`summarise()` has grouped output by 'crop'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 24 × 3\n# Groups:   crop [8]\n   crop  year  protein_na\n   <chr> <chr>      <int>\n 1 SWW   2017         160\n 2 H-W   2018         128\n 3 H-W   2017         120\n 4 H-S   2018          96\n 5 SWW   2018          90\n 6 SWS   2018          64\n 7 SWS   2017          40\n 8 HRS   2017          32\n 9 HWS   2017          32\n10 HRW   2019           4\n# … with 14 more rows\n\n\n\n\n\n\n\n\nFYI\n\n\n\nYou can group by a numeric variable. If you do that, dplyr will look for common values to group observations. This can be successful when there are repeat ‘integers’ (e.g. year, replicate), but if all values are unique (which is often the case with floating point numbers), then the number of groups is the number of observations.\n\n\n\n\nSummarising across multiple variables\nUse across() to conduct the same summary action(s) across multiple columns.\n\nvariety_trials %>% group_by(trial) %>% \n  summarise(across(c(yield, grain_protein), ~ mean(.x, na.rm = T)))\n\n# A tibble: 28 × 3\n   trial                       yield grain_protein\n   <chr>                       <dbl>         <dbl>\n 1 SWIdahoCereals_H-S_PAR_2018  91.0         10.9 \n 2 SWIdahoCereals_H-S_WEI_2018  27.0        NaN   \n 3 SWIdahoCereals_H-W_PAR_2017 121.         NaN   \n 4 SWIdahoCereals_H-W_PAR_2018  63.1        NaN   \n 5 SWIdahoCereals_H-W_WEI_2018  28.4        NaN   \n 6 SWIdahoCereals_HRS_PAR_2016 111.          14.3 \n 7 SWIdahoCereals_HRS_PAR_2017 150.         NaN   \n 8 SWIdahoCereals_HRS_PAR_2019 106.          11.7 \n 9 SWIdahoCereals_HRS_PAR_2020  90.6         12.7 \n10 SWIdahoCereals_HRW_PAR_2019  88.2          8.20\n# … with 18 more rows\n\n\n\n\nRow-wise summaries\nMany operations in R are already vectorized across rows, but when they are not, you can use rowwise() to implement that.\nField disease scoring may benefit from this system. Often, several measurements are made on a single experimental unit (usually a plot), and those measurements are averaged together to create a final disease incidence score. Here is how to do that with rowwise().\nFirst, simulate a set of disease scores between 0 and 100 (indicating percent infection).\n\n# step 1: generate a set of possible scores: 0, 10, 20,...100\nscore_range <- c(0:10 * 10L)\n# sample those possible scores to generate 50 data points\nscores <- sample(score_range, 50, replace = TRUE)\n# arrange those 50 data points into a datafrmae of 5 columns, each column reflecting 10 observations\ndisease_df <- data.frame(plot = letters[1:10],\n                         score1 = scores[1:10],\n                         score5 = scores[11:20],\n                         score3 = scores[21:30],\n                         score4 = scores[31:40],\n                         score2 = scores[41:50])\ndisease_df\n\n   plot score1 score5 score3 score4 score2\n1     a     90      0     60     10     70\n2     b     10     20    100     20     50\n3     c     10     90     30     40     40\n4     d     30    100    100     30     80\n5     e     10     30     30     50     20\n6     f      0      0    100     90    100\n7     g     80     50     30    100     50\n8     h     90     70     50    100     50\n9     i     10     70     70     80     10\n10    j    100     30      0     20     40\n\n\nData sets exist like this. A person might have a set of 10 experimental plots to evaluate for some trait. The trait assay protocol may require that multiple observations be gathered per plot (from a statistical standpoint, this is a technical replicate, not a true replicate) and then reduced to a single number per plot using a simple mean. Row-wise functions can accomplish this.\n\ndisease_df_sum <- disease_df %>% rowwise() %>% \n  mutate(score_final = mean(score1:score2),\n        max_score = max(score1:score2))\ndisease_df_sum\n\n# A tibble: 10 × 8\n# Rowwise: \n   plot  score1 score5 score3 score4 score2 score_final max_score\n   <chr>  <int>  <int>  <int>  <int>  <int>       <dbl>     <int>\n 1 a         90      0     60     10     70          80        90\n 2 b         10     20    100     20     50          30        50\n 3 c         10     90     30     40     40          25        40\n 4 d         30    100    100     30     80          55        80\n 5 e         10     30     30     50     20          15        20\n 6 f          0      0    100     90    100          50       100\n 7 g         80     50     30    100     50          65        80\n 8 h         90     70     50    100     50          70        90\n 9 i         10     70     70     80     10          10        10\n10 j        100     30      0     20     40          70       100\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nIt is possible use mutate() or summary() commands on a grouped data frame. A summary() call will return one value per group + summary function (e.g. mean). A mutate() call will return one value per row + summary function. All the previous examples in this lesson used summary(). Here is one example using mutate():\n\nvariety_trials %>% \n  select(trial, rep, variety, crop, yield) %>% group_by(crop) %>%\n  mutate(relative_yield = yield/mean(yield, na.rm=TRUE)) %>% \n  arrange(desc(yield)) %>% head(15)\n\n# A tibble: 15 × 6\n# Groups:   crop [6]\n   trial                         rep variety        crop  yield relative_yield\n   <chr>                       <int> <chr>          <chr> <dbl>          <dbl>\n 1 SWIdahoCereals_HRS_PAR_2017     1 WB9411         HRS    498.           4.50\n 2 SWIdahoCereals_HRS_PAR_2017     3 12SB0197       HRS    297.           2.68\n 3 SWIdahoCereals_HWS_PAR_2017     3 Dayn           HWS    253.           2.18\n 4 SWIdahoCereals_SWS_PAR_2017     1 UI Stone       SWS    219.           2.12\n 5 SWIdahoCereals_SWS_PAR_2017     4 UI Stone       SWS    217.           2.09\n 6 SWIdahoCereals_SWS_PAR_2017     4 WA8277         SWS    204.           1.97\n 7 SWIdahoCereals_SWW_PAR_2017     1 Bobtail        SWW    201.           2.14\n 8 SWIdahoCereals_H-W_PAR_2017     3 WA8269         H-W    199.           2.36\n 9 SWIdahoCereals_HWS_PAR_2017     1 LCS Star       HWS    198.           1.71\n10 SWIdahoCereals_HRW_PAR_2020     2 LCS Jet        HRW    197.           1.45\n11 SWIdahoCereals_HRW_PAR_2020     3 LCS Rocket     HRW    196.           1.44\n12 SWIdahoCereals_SWW_PAR_2017     2 Agripro Legion SWW    194.           2.06\n13 SWIdahoCereals_H-W_PAR_2017     4 NSA10-2196     H-W    193.           2.29\n14 SWIdahoCereals_HWS_PAR_2017     4 LCS Star       HWS    193.           1.66\n15 SWIdahoCereals_HRW_PAR_2020     2 Scorpio        HRW    193.           1.42\n\n\nIn this case, the mean value used for calculating ‘relative_yield’ is the group mean."
  },
  {
    "objectID": "lessons/Lesson11.html",
    "href": "lessons/Lesson11.html",
    "title": "Lesson 11: Reshaping Data Sets",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to convert a long data set to wide\nbe able to convert a wide data set to long\nbe aware of function used during pivot_wide() to compress multiple observations for a variable combination being pivoted.\n\n\n\n\n\nWhat is pivoting?\nThere are circumstances when a wide data set are needed and circumstances when a long data set are needed, for analysis, plotting, data wrangling, etc.\nDoing this manually in a spreadsheet program is extremely cumbersome and very susceptible to errors! You are much better off doing this in R (or another programming language).\nThese wide-to-long and long-to-wide conversions are also called ‘pivoting’.\n\n\n\n\n\nWhen pivoting from long to wide format, we should consider what will be used as the identifying information, what information will be used for column headers and what information will be used to fill the cells/populate the table.\nWhen pivoting from wide to long, the considerations are similar: what will be the name of the new column header and what information (i.e. what columns) will be used to populate the data in the vertical direction, while which columns will be used for record identification.\nPivoting from wide to long can be done with the tidyr functions pivot_wide() and the reverse function if pivot_longer().\nLet’s run some examples with trial data set.\nLoad the trial data and libraries:\n\nlibrary(readr); library(dplyr); library(tidyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nvariety_trials <- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\n#weather <- read_csv(here::here(\"data\", \"weather_data.csv\"))\n\n\n\nPivot long to wide\nThe first thing we should do is look at the documentation for pivot_wider.\n\n?pivot_wider\n\nThe main arguments to consider (not including the input data) is:\nid_cols what are the identifying columns that we will keep in the data set to identify and separate records. This can be multiple columns.\nnames_from is the variable that will be used to make the new column header. This is the column that we are seeking to change from long to wide. This should be a categorical variable or one that can be coerced to one. Usually it contains repeating values.\nvalues_from is the variable that will be used to fill the cells under the column header.\nThere is long list of other arguments, but these are the most important.\n\nPivot single variable\nThe loaded data set includes many different field trials. Let’s look at the information for one trial and pivot the data across replicates for a single variable, using entry as an ID variable.\nFirst, find out the different levels for “trial”:\n\nunique(variety_trials$trial)\n\n [1] \"SWIdahoCereals_HRS_PAR_2016\" \"SWIdahoCereals_HWS_PAR_2016\"\n [3] \"SWIdahoCereals_SWS_PAR_2016\" \"SWIdahoCereals_H_W_PAR_2017\"\n [5] \"SWIdahoCereals_HRS_PAR_2017\" \"SWIdahoCereals_HWS_PAR_2017\"\n [7] \"SWIdahoCereals_SWS_PAR_2017\" \"SWIdahoCereals_SWW_PAR_2017\"\n [9] \"SWIdahoCereals_H_S_PAR_2018\" \"SWIdahoCereals_H_W_PAR_2018\"\n[11] \"SWIdahoCereals_SWS_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2018\"\n[13] \"SWIdahoCereals_H_S_WEI_2018\" \"SWIdahoCereals_H_W_WEI_2018\"\n[15] \"SWIdahoCereals_SWS_WEI_2018\" \"SWIdahoCereals_SWW_WEI_2018\"\n[17] \"SWIdahoCereals_HRS_PAR_2019\" \"SWIdahoCereals_HRW_PAR_2019\"\n[19] \"SWIdahoCereals_HWS_PAR_2019\" \"SWIdahoCereals_HWW_PAR_2019\"\n[21] \"SWIdahoCereals_SWS_PAR_2019\" \"SWIdahoCereals_SWW_PAR_2019\"\n[23] \"SWIdahoCereals_HRS_PAR_2020\" \"SWIdahoCereals_HRW_PAR_2020\"\n[25] \"SWIdahoCereals_HWS_PAR_2020\" \"SWIdahoCereals_HWW_PAR_2020\"\n[27] \"SWIdahoCereals_SWS_PAR_2020\" \"SWIdahoCereals_SWW_PAR_2020\"\n\n\nThis example will use the last trial listed (SWIdahoCereals_SWW_PAR_2020), but any of these options will work. Let’s filter the data and check that there is one observation per rep and entry.\n\nparma2020 <- variety_trials %>% filter(trial == \"SWIdahoCereals_SWW_PAR_2020\") \ntable(parma2020$entry, parma2020$rep)\n\n    \n     1 2 3 4\n  1  1 1 1 1\n  2  1 1 1 1\n  3  1 1 1 1\n  4  1 1 1 1\n  5  1 1 1 1\n  6  1 1 1 1\n  7  1 1 1 1\n  8  1 1 1 1\n  9  1 1 1 1\n  10 1 1 1 1\n  11 1 1 1 1\n  12 1 1 1 1\n  13 1 1 1 1\n  14 1 1 1 1\n  15 1 1 1 1\n  16 1 1 1 1\n  17 1 1 1 1\n  18 1 1 1 1\n  19 1 1 1 1\n  20 1 1 1 1\n  21 1 1 1 1\n  22 1 1 1 1\n  23 1 1 1 1\n  24 1 1 1 1\n  25 1 1 1 1\n  26 1 1 1 1\n  27 1 1 1 1\n  28 1 1 1 1\n  29 1 1 1 1\n  30 1 1 1 1\n  31 1 1 1 1\n  32 1 1 1 1\n  33 1 1 1 1\n  34 1 1 1 1\n  35 1 1 1 1\n  36 1 1 1 1\n  37 1 1 1 1\n  38 1 1 1 1\n\n\nThe table produces all “1” indicating 1 observation per variable combination, which is what we want.\n\nparma2020_wide <- parma2020 %>% \n  pivot_wider(id_cols = entry,\n              names_from = rep,\n              values_from = yield)\n\nhead(parma2020_wide)\n\n# A tibble: 6 × 5\n  entry   `1`   `2`   `3`   `4`\n  <int> <dbl> <dbl> <dbl> <dbl>\n1     1  165.  119.  161.  141.\n2     2  151.  141.  155.  155.\n3     3  150.  143.  155.  141.\n4     4  149.  149.  155.  158.\n5     5  182.  143.  131.  157.\n6     6  127.  135.  145.  125.\n\n\nIf you try to index that column with parma2020_wide$1, an error is thrown:\n\nparma2020_wide$1\n\nError: <text>:1:16: unexpected numeric constant\n1: parma2020_wide$1\n                   ^\n\n\nWe can give it better column names (not starting with a number) using the names_prefix argument.\n\nparma2020_wide <- parma2020 %>% \n  pivot_wider(id_cols = entry,\n              names_from = rep,\n              values_from = yield,\n              names_prefix = \"rep_\")\n\nhead(parma2020_wide)\n\n# A tibble: 6 × 5\n  entry rep_1 rep_2 rep_3 rep_4\n  <int> <dbl> <dbl> <dbl> <dbl>\n1     1  165.  119.  161.  141.\n2     2  151.  141.  155.  155.\n3     3  150.  143.  155.  141.\n4     4  149.  149.  155.  158.\n5     5  182.  143.  131.  157.\n6     6  127.  135.  145.  125.\n\n\n\n\nPivot multiple variables\nPerhaps we want to pivot 2 variables.\n\nparma2020_wide_2vars <- parma2020 %>%\n  pivot_wider(id_cols = entry,\n              names_from = rep,\n              values_from = c(yield, grain_protein))\n\nhead(parma2020_wide_2vars)\n\n# A tibble: 6 × 9\n  entry yield_1 yield_2 yield_3 yield_4 grain_protein_1 grain_…¹ grain…² grain…³\n  <int>   <dbl>   <dbl>   <dbl>   <dbl>           <dbl>    <dbl>   <dbl>   <dbl>\n1     1    165.    119.    161.    141.             9.9      8.4    11.2    11  \n2     2    151.    141.    155.    155.             8.5     10.2    10.1    10  \n3     3    150.    143.    155.    141.             8.5     10.4     8.8     9.3\n4     4    149.    149.    155.    158.             9.4      9      10       9.6\n5     5    182.    143.    131.    157.             8.4      9.5    10       8  \n6     6    127.    135.    145.    125.             8.8     10.4     9.5     9  \n# … with abbreviated variable names ¹​grain_protein_2, ²​grain_protein_3,\n#   ³​grain_protein_4\n\n\n\n\nPivot with multiple observations per identifier\nSometimes, there may be multiple observations per identifier and new column header. *tidyr will attempt to resolve this automatically, sometimes by inserting a list inside a data frame to capture the additional information. This is messy and hard to access. Sometimes this is an unintentional; you expected only one observation and learn through tidyr warning messages that there is an more observations than expected.\nHowever, you can also introduce a function in a pivot_wider such as mean or sum to summarise these replicate observations.\nHere is an example using “variety”, which is has replicate values.\n\nparma2020_wide_var <- parma2020 %>%\n  pivot_wider(id_cols = variety,\n              names_from = rep, \n              values_from = yield,\n              values_fn = mean)\n\nhead(parma2020_wide_var)\n\n# A tibble: 6 × 5\n  variety       `1`   `2`   `3`   `4`\n  <chr>       <dbl> <dbl> <dbl> <dbl>\n1 11PN044#48   165.  119.  161.  141.\n2 LCS Artdeco  151.  141.  155.  155.\n3 LCS Drive    150.  143.  155.  141.\n4 LCS Hulk     149.  149.  155.  158.\n5 IDO1708      182.  143.  131.  157.\n6 Jasper       127.  135.  145.  125.\n\n\n\n\n\nWide to Long\nLet’s put all the traits in one column (and filter out the missing data).\nMain arguments in pivot_longer() (besides the data set):\ncols the columns to stack/pivot\nnames_to name of the new categorial variable that is composed of the names of the columns being pivoted\nvalues_to name of new value column (will be named “value” by default if not specified)\n\nparma2020_long <- parma2020 %>% \n  pivot_longer(cols = c(yield, grain_protein, test_weight),\n               names_to = \"trait\")\n\nhead(parma2020_long)\n\n# A tibble: 6 × 10\n  trial                    rep entry variety flag  row   range plot  trait value\n  <chr>                  <int> <int> <chr>   <chr> <lgl> <lgl> <lgl> <chr> <dbl>\n1 SWIdahoCereals_SWW_PA…     1     1 11PN04… <NA>  NA    NA    NA    yield 165. \n2 SWIdahoCereals_SWW_PA…     1     1 11PN04… <NA>  NA    NA    NA    grai…   9.9\n3 SWIdahoCereals_SWW_PA…     1     1 11PN04… <NA>  NA    NA    NA    test…  61.5\n4 SWIdahoCereals_SWW_PA…     2     1 11PN04… <NA>  NA    NA    NA    yield 119. \n5 SWIdahoCereals_SWW_PA…     2     1 11PN04… <NA>  NA    NA    NA    grai…   8.4\n6 SWIdahoCereals_SWW_PA…     2     1 11PN04… <NA>  NA    NA    NA    test…  60.5\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen to use these function depends on the desired output. If you want to do a multi-year analysis of field trial data, stacking the years in the long format makes sense. If you want to compute correlations across two variables, the wide format makes sense for those variables.\nAs part of the tidyverse, anything pivoting can be preceded by or can be followed by any other data wrangling step such as filtering, data aggregation and so on.\nYou can use any of the tidy select methods for indicating which values to pivot. This is particularly useful when there is a very large number of columns to pivot that share similarities in their name."
  },
  {
    "objectID": "lessons/final_Lesson.html",
    "href": "lessons/final_Lesson.html",
    "title": "Moving on",
    "section": "",
    "text": "If you made this far, congratulations! Learning any programming language takes a big effort.\nThis is only the beginning. You will probably need more R knowledge, both generalized and specialized, to accomplish your research goals. Here are a few resources to develop stronger data science skills in R.\n\nData Science in a Box is a online course by Mine Çetinkaya-Rundel with videos for further development of R skills.\nR 4 Data Science by Hadley Wickham and Garret Grolemund is a comprehensive book providing guidance on leveraging R for data science aims\nWhat They Forgot to Teach you about R (and workshop version) describes some meta processes for ensuring a repeatable workflow.\n\nThere are many other resources to help develop skills in genetics, bioinformatics, geospatial analysis, Bayesian statistics, ….you name it. Look for the resources that will help you develop skills in R. One very reliable place to start are CRAN Task Views which provide a list of packages and other relevant R resources specific for a given topic such as environmetrics (ecology), spatial tools and agriculture.\nAnother good source for keeping up with major developments in R, contributed R packages and other R resources is R Weekly which puts out a weekly blog post (also available in a weekly podcast and an RSS feed)."
  },
  {
    "objectID": "posit_instructions.html",
    "href": "posit_instructions.html",
    "title": "Instructions for Accessing the Posit Classroom Project",
    "section": "",
    "text": "Follow the link provided in the mail to join the classroom.\nOnce you have created a login for Posit Cloud, you can join the classroom. Once you follow the link and log in to Posit, you should see this screen:\n\n\n\n\n\nClick “Yes”.\nOnce you join, navigate to the classroom on the left sidebar:\n\n\n\n\n\nWhen you open “R Classroom”, you should see this:\n\n\n\n\n\nClick on “Intro to R Class”, and the project will load. This may take a few minutes.\n\n\n\n\n\nOnce it is finished loading, this is what you should see:\n\n\n\n\n\nThis has created a temporary copy of the project (hence the blinking red label that says “TEMPORARY COPY”). Click on “Save a Permanent Copy” to copy the project. This also may take a few minutes to complete. When you’re done, if you return to the R Classroom, you should see something similar to this. It will list your name instead of “Julia Test” and there may be other students with the same project copied.\n\n\n\n\n\nOnly the instructors and you can access your project. Course instructors will not access student Posit classroom projects unless a student requests we look at it to help troubleshoot an R coding issue.\nThis project is where you should save all of your R scripts. You can access this project at anytime, including when the class is not meeting from now until Feb 10th, 2022. When the course is done, the classroom will be deleted, so be certain to download your project in case you want to revisit it. The course instructors will send a reminder email to do this if you forget."
  },
  {
    "objectID": "practice/practice-A.html",
    "href": "practice/practice-A.html",
    "title": "Practice A",
    "section": "",
    "text": "(for lessons on R for mathematics and vectorized operations)\n\nMake this calculation using R math operators\n\n\\[ \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\] Where: \\(\\pi\\) = 3.14, \\(e\\) = 2.718, \\(\\mu\\) = 50, \\(\\sigma\\) = 5, \\(x\\) = 20\n\nRepeat this calculation where \\(x\\) = {10, 30, 40, 50, 60}\n\nThe Solution"
  },
  {
    "objectID": "practice/practice-B.html",
    "href": "practice/practice-B.html",
    "title": "Practice B",
    "section": "",
    "text": "(for introduction to R types and objects lesson)\n\nYou have this collection of items:\n\n\nx <- c(-2:3, TRUE, FALSE, 1L, 0L, \"zero\"). \n\nWhat data type is this?\n\nConvert this object to these types:\n\n\nlogical\nnumeric\ncharacter Inspect the results. What happened?\n\nSolution"
  },
  {
    "objectID": "practice/practice-C.html",
    "href": "practice/practice-C.html",
    "title": "Practice C",
    "section": "",
    "text": "(for the lesson on data structures)\n\nVectors\n\nYou have this object in your R session: x = 7. What is the difference between x[1] and x?\nMake a vector of letters “a” to “m” (all lowercase) and letters “N” to “Z” (all uppercase).\nMake a vector of numbers 1 to 10 and 2 to 50.\n\n\n\nData Frames\n\nMake a data frame consisting of 6 rows and 4 columns, where one is a character variable, another is numeric, another is logical and the another is a factor. Verify that each column type is what you intended it to be.\nYou have this data frame:\n\n\ndf <- data.frame(one = 1:10,\n                 two = rnorm(10))\ndf$three <- df$two + rnorm(10)\ndf$four <- sample(c(\"A\", \"B\"), 10, replace = TRUE)\n\n\nAdd another column called ‘five’ that is a character variable consisting of levels that are fruits of your choice.\nAdd another column called ‘six’ that is ‘five’ coerced into a factor.\nMake a new data frame with the columns in this order: “five”, “one”, “four”, “two”, “three”.\n\n\n\nLists\n\nYou have this list: mylist = list(x1 = \"snow\", x2 = 45:65, x3 = rep(letters[1:3], each = 3), x4 = matrix(1:100, nrow = 10)). Return this list without x3.\nPut all your vectors and the data frame from the previous problems in this exercise set into a list. For the first list item that has a vector, change the forth item of that vector to missing.\nFor the list created in the previous problem, delete the second item.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nthe functions letters() and LETTERS() provide a shortcut for problem #3.\ntry using NULL for the last problem (under the “Lists” heading).\n\n\n\n\nSolution"
  },
  {
    "objectID": "practice/practice-D.html",
    "href": "practice/practice-D.html",
    "title": "Practice D",
    "section": "",
    "text": "(for the data import lesson)\n\nImport one of your data sets using two of the functions taught:\n\n(save your data in different format to enable this)\n\nread.csv()\nread_csv()\nread_excel()\nread.delim()\n\n\nExamine the data imported using View(imported_data). Did everything import as expected? Are your variables coded as they should be? Are numeric variables numeric? Are missing data detected as thus?"
  },
  {
    "objectID": "practice/practice-E.html",
    "href": "practice/practice-E.html",
    "title": "Practice E",
    "section": "",
    "text": "(for data export lesson)\n\nRepeat the import practice problems. Export those files under a new file name. Make sure you use a new file name or a different output directory so you do not write over the original files.\nExamine the output files to make sure they look as expected? Where any row names accidentally introduced? Were missing cells converted to “NA”? Did any data become unexpectedly quoted?"
  },
  {
    "objectID": "practice/practice-F.html",
    "href": "practice/practice-F.html",
    "title": "Practice F",
    "section": "",
    "text": "(for the data wrangling lesson)\nIf you have your own data, import it and consider what sort of data wrangling you might need to do on the data set to ready it for analysis - does something need to be filtered or calculated? This is a good moment to apply skills learned. \n\nImport “trial_metadata.csv” with the readr function read_csv(). Create a new variable that combined information in the ‘location’ and ‘irrigation’ columns.\nFilter the imported data set for when the location is “Parma” and sort the data set based on planting date. Assign the results to a new object.\nSelect 4 columns from the data set and rename one of them. Assign these results to a new object.\nImport “weather_data.csv”, select the first five columns and reduce that data set to unique rows (look into using distinct() for extracting the unique observations).\nNEW: Import “trial_data.csv”. Split the “trials” column into 4 variables using separate() as we did in class (or see the lesson notes). Filter the data set to the 2 most recent years and the varieties WA8268, WB4418, WB4311, WB4623CLP, WB4792, and WB7589.\n\nHere is the prep work to do prior to separate():\n\ntrial_data <- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\ntrial_data$trial <- gsub(pattern = \"_H_\", \n                         replacement = \"_H-\", \n                         x = trial_data$trial)\n\n\nOutput the result from any of the previous problems to file.\n\nSolution"
  },
  {
    "objectID": "practice/practice-G.html",
    "href": "practice/practice-G.html",
    "title": "Practice G",
    "section": "",
    "text": "(for the data aggregation lesson)\n\nAs usual, consider how these data aggregation functions can support your own work.\n\nFor some of these exercises, you may need to use other dplyr functions.\n\nImport “weather_data.csv”. Group the data by station and year and count the number of missing data points for ‘tmax’, ‘tmin’ and ‘tavg’.\nImport “weather_data.csv”, group the data by ‘station’ and ‘julian_day’ and calculate the average minimum and maximum temperatures for the groups from ‘tmin’ and ‘tmax’. If you already imported the data set from the previous problem, you don’t need to import it again if you did not change the data set.\nImport “weather_data.csv”, calculate the difference between the ‘tmin’ and ‘tmax’ for each day. Group the data by year and return the smallest and largest differences for each year. Consider how to handle missing data. If you already imported the data set from the previous problem, you don’t need to import it again if you did not change the data set.\n\nSolution"
  },
  {
    "objectID": "practice/practice-H.html",
    "href": "practice/practice-H.html",
    "title": "Practice H",
    "section": "",
    "text": "(for the data reshaping lesson)\n\nAs always, consider how these reshaping functions can support your own research and data analysis.\n\n\nImport “genotypic_data.txt” and remove columns 2 through 5 (‘CHROM’, ‘POS(cM)’, ‘Major_allele’, ‘Minor_allele’). What is left is genetic marker names and the marker scores for the individual lines (each column is an genetically distinct wheat line). Using pivot_longer(), reshape this object to long so there is one column for the marker name, one column for the wheat name, and the one column for the marker score. How many rows long is this object? Can you image trying to do this by hand??\nImport “weather_data.csv”. Filter to any single year and reshape the data from long to wide so that the levels in “station’ form the new column headers, ‘julian_day’ is the identifying column and the cells are filled with data from ‘tmax_F’.\nHere is a crazy extra exercise that utilizes transpose instead of pivoting. It’s not strictly related to reshaping. Only try this if you are in the mood for a challenge.\n\nThis problem is indicative of a data wrangling you can experience out in the wild. You are given a data set in one format, but a package requires your data be in another format.\nThe file “genotypic_data.txt” is a transposed version of “genotypic_data_rotated.csv”. Import “genotypic_data.txt” into R and use R commands to recreate “genotypic_data_rotated.csv”.\nThe column “individual” no longer has periods in the listed names, but the original file had periods in those names since they were column headers. Write code to remove those periods from the column “individual” in your transformed column (hint: look at the documentation for gsub()).\nSolution"
  },
  {
    "objectID": "practice/practice-I.html",
    "href": "practice/practice-I.html",
    "title": "Practice I",
    "section": "",
    "text": "(for the data merging lesson)\n\nImport “genotypic_data_rotated.txt”, “trial_data.csv”, and “trial_metadata.csv”).\nDo a full join between “trial_data” and “trial_metadata”.\nDo an inner join between “genotypic_data_rotated.txt” and “trial_data.csv”).\nDo a semi-join of “genotypic_data_rotated” with “trial_data” and do the reverse. How does this compare with the inner join from the previous problem?\nDo an anti-join between genotypic_data_rotated and trial_data.\nJoin together all common observations (by variety name) between the 3 files.\n\nSolution"
  },
  {
    "objectID": "practice/practice-J.html",
    "href": "practice/practice-J.html",
    "title": "Practice J",
    "section": "",
    "text": "(for the exploratory plotting lesson)\nSolution"
  },
  {
    "objectID": "practice/practice-K.html",
    "href": "practice/practice-K.html",
    "title": "Practice K",
    "section": "",
    "text": "(for the ggplot2 lesson)\nThe Solution"
  },
  {
    "objectID": "practice/practice-L.html",
    "href": "practice/practice-L.html",
    "title": "Practice Problem L",
    "section": "",
    "text": "(for the lesson on repeating operations)\n\nYou have a data set of 1000 random numbers between 1 and 100:\n\n\nx <- sample(1:100, 1000, replace = TRUE)\n\nWrite ifelse statements than converts:\n\nnumbers less than 50 to zero\n\nnumbers greater than or equal to 90 to 100\n\nand keeps the rest of the numbers as is\n\n\nneed an apply() problem\nYou have a data set of 500 random numbers between 1 and 100 that are divided into 5 categories.\n\n\ndf <- data.frame(int = sample(1:10, 500, replace = TRUE),\n                 category = sample(letters[1:5], 500, replace = TRUE))\nhead(df)\n\nCalculate the mode of each category using lapply(). The mode is the most commonly occurring value. If you’re unsure how to do this, consider the function table() combined with sort(). FYI, The R function mode() does not compute a mathematical mode (it gives object class information).\n\nRewrite this using purrr functions to loop over all countries for when y = “cereal_yield”:\n\n[THIS LOOKS LIKE IT NEEDS A DATA SET]\n\nmy_lm_fun <- function(df, y, cty) {\n  #browser()\n  form <- formula(paste(y, \"~ year\", sep = \"\"))\n  m1 = lm(form, data = df,\n          subset = df$country == cty)\n  a1 = anova(m1)\n  r2 = summary(m1)$r.squared\n  return(r2)\n}\n\nIt should start:\n\nmy_final_estimates <- fertil %>% \n\nThe Solution"
  },
  {
    "objectID": "practice/solution-A.html",
    "href": "practice/solution-A.html",
    "title": "Solutions to Practice A",
    "section": "",
    "text": "\\[ \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\]\n\\(\\pi\\) = 3.14 \\(e\\) = 2.718 \\(\\mu\\) = 50 \\(\\sigma\\) = 5 \\(x\\) = 20\n\nFor this problem, there are several possible solutions:\n\n\nManual the whole way down:\n\n\n1/(5*(2*3.14)^0.5)*2.718^(-0.5*((20-50)/5)^2)\n\n[1] 1.217755e-09\n\n\n\nEmploying a few shortcuts\n\n\n1/(5*sqrt(2*pi))*exp(-0.5*((20-50)/5)^2)\n\n[1] 1.215177e-09\n\n\n\nR function that estimates the standard normal density (the equation above is the probability density function for the normal distribution)\n\n\ndnorm(x = 20, mean = 50, sd = 5)\n\n[1] 1.215177e-09\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s not expected you would be aware of the second and third solutions given what has been taught thus far, but it’s helpful to be aware that many shortcuts exist in R to make coding easier.\n\n\n\nUsing the manual approach:\n\n\nx = c(10, 20, 30, 40, 50)\n1/(5*(2*3.14)^0.5)*2.718^(-0.5*((x-50)/5)^2)\n\n[1] 1.014069e-15 1.217755e-09 2.679505e-05 1.080317e-02 7.980869e-02"
  },
  {
    "objectID": "practice/solution-B.html",
    "href": "practice/solution-B.html",
    "title": "Solutions to Practice B",
    "section": "",
    "text": "The variable x is a character variable:\n\n\nx <- c(-2:3, TRUE, FALSE, 1L, 0L, \"zero\")\nclass(x)\n\n[1] \"character\"\n\n\n\nWhen converted:\n\n\nas.logical(x)\n\n [1]    NA    NA    NA    NA    NA    NA  TRUE FALSE    NA    NA    NA\n\nas.character(x)\n\n [1] \"-2\"    \"-1\"    \"0\"     \"1\"     \"2\"     \"3\"     \"TRUE\"  \"FALSE\" \"1\"    \n[10] \"0\"     \"zero\" \n\nas.numeric(x)\n\nWarning: NAs introduced by coercion\n\n\n [1] -2 -1  0  1  2  3 NA NA  1  0 NA\n\n\nItems which did not the expected object type could not be converted (or “coerced”), so they were set to NA."
  },
  {
    "objectID": "practice/solution-C.html",
    "href": "practice/solution-C.html",
    "title": "Solutions to Practice C",
    "section": "",
    "text": "Vectors\n\nThere is no difference. If there is only item in a vector, it does not need to be indexed by position.\nThe way to do this shown in class:\n\n\nv1 = c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\")\nv1\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nThis is rather cumbersome. An easier way is to use the preset vectors letters and LETTERS which are the english alphabet in lowercase and uppercase, respectively. The index position 1 of each corresponds to the first letter of the alphabet, “a” or “A”.\n\nv1 <- c(letters[1:13], LETTERS[14:26])\nv1\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\n\n\n\n\n\n\nFYI\n\n\n\nIf something seems tedious and slow in R, there is probably a shortcut.\n\n\n\nThe vector:\n\n\nv2 <- c(1:10, 2:50)\n\n\n\nData Frames\n\nA possible data frame:\n\n\nd1 <- data.frame(var1 = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE),\n                 var2 = 1:6,\n                 var3 = \"orange\",\n                 var4 = as.factor(c(\"red\", \"blue\", \"blue\", \"purple\", \"green\", \"green\")))\n\nstr(d1)\n\n'data.frame':   6 obs. of  4 variables:\n $ var1: logi  TRUE TRUE TRUE FALSE FALSE FALSE\n $ var2: int  1 2 3 4 5 6\n $ var3: chr  \"orange\" \"orange\" \"orange\" \"orange\" ...\n $ var4: Factor w/ 4 levels \"blue\",\"green\",..: 4 1 1 3 2 2\n\n\nThe function str() is for checking the structure of an object. For a data frame, it will iterate over every column and give us the data type and some sample values.\n\nThe starting data frame\n\n\ndf <- data.frame(one = 1:10,\n                 two = rnorm(10))\ndf$three <- df$two + rnorm(10)\ndf$four <- sample(c(\"A\", \"B\"), 10, replace = TRUE)\n\n\ndf$five <- sample(c(\"apple\", \"huckleberry\"), 10, replace = TRUE)\ndf$six <- as.factor(df$five)\n\n\nnew_df <- df[,c(5, 1, 4, 2, 3)]\nnew_df\n\n          five one four          two      three\n1        apple   1    A -0.734241338 -1.1640627\n2        apple   2    B  0.288717482  0.1253103\n3  huckleberry   3    B -0.397096927 -0.8486531\n4  huckleberry   4    B -0.791676359 -0.1515198\n5        apple   5    B  0.478148825  0.2790986\n6        apple   6    B -0.006232795  0.5339883\n7        apple   7    B  0.778964597  0.2769545\n8        apple   8    B -1.676288902 -1.2153547\n9  huckleberry   9    A -1.776625935 -0.2332073\n10       apple  10    B  2.883090449  2.3562325\n\n\n\n\nLists\n\nThe list\n\n\nmylist = list(x1 = \"snow\", \n              x2 = 45:65, \n              x3 = rep(letters[1:3], each = 3), \n              x4 = matrix(1:100, nrow = 10, ncol=10))\nmylist\n\n$x1\n[1] \"snow\"\n\n$x2\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n$x3\n[1] \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"c\" \"c\" \"c\"\n\n$x4\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\nThere are two ways to remove x3. The First is to create a new list from the object ‘mylist’ and don’t include x3:\n\nmylist2 <- list(mylist[[1]], mylist[[2]], mylist[[4]])\nmylist2\n\n[[1]]\n[1] \"snow\"\n\n[[2]]\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n[[3]]\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\nLists also let you declare a list item as NULL which makes it completely go away!\n\nmylist[[3]] <- NULL\nmylist\n\n$x1\n[1] \"snow\"\n\n$x2\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n$x4\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\n\nA possible list:\n\n\nl1 <- list(v1, v2, d1)\n\nSet the 4th item of vector inside a list to NA. The first item is a vector, so we will use that.\n\nl1[[1]][4] <- NA\n\nYou can index a vector inside of a list by indexing the list first, then the vector.\n\nRemove list item:\n\n\nl1[[2]] <- NULL\n\nWhen an item is set to NULL in a list, it disappears.\n\n\n\n\n\n\nEvergreen lesson\n\n\n\nAlways always always check your object to make sure it looks like what you expected it to.\nCommon checks:\n\nthe dimensions (row number, column number, length, etc) are what you expect\nthe data types are what you expect\nthe values are what you expect"
  },
  {
    "objectID": "practice/solution-F.html",
    "href": "practice/solution-F.html",
    "title": "Solutions to Practice F",
    "section": "",
    "text": "First load the libraries.\n\nThen, import the data and create the new variable.\n\nmydata <- read_csv(here::here(\"data\", \"trial_metadata.csv\"),\n                   show_col_types = FALSE) %>%\n    unite(\"new_var\", location, irrigation, sep = \"_\", remove = FALSE )\n\nAnother option:\n\nmydata$new_var <- paste(mydata$location, mydata$irrigation, sep = \"_\")\n\nAnother option:\n\nmydata <- mydata %>% mutate(new_var = \n                              paste(location, irrigation, sep = \"_\"))\n\n\nFilter and sort:\n\n\nmydata_filtered <- mydata %>% filter(location == \"Parma\") %>%\n  arrange(planting_date)\n\n\nSelect and rename\n\n\nmydata_selected <- mydata %>% select(trial, grower_cooperator, \n                                     location, year) %>%\n    rename(farm = \"grower_cooperator\")\n\nOr in one step:\n\nmydata_selected <- mydata %>% select(trial, farm = \"grower_cooperator\",\n                                     location, year)\n\n\nReduce the identifying information in the weather data set to non-repetitive information. A data set will often several columns that reflect repetitive identifying information. It’s helpful to know how many unique observations are present:\n\n\nweather <- read.csv(here::here(\"data\", \"weather_data.csv\"))\n\nweather %>% select(1:5) %>% distinct()\n\n      station                           name latitude longitude elevation\n1 USC00453546             HATTON 9 SE, WA US 46.72250 -118.6524     458.7\n2 USC00456215           OTHELLO 6 ESE, WA US 46.78861 -119.0461     362.7\n3 USC00457059         RITZVILLE 1 SSE, WA US 47.11750 -118.3715     568.1\n4 USR0000WCNW COLUMBIA NWR WASHINGTON, WA US 46.88140 -119.3242     260.6\n\n\n\nPrep work:\n\n\ntrial_data <- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\ntrial_data$trial <- gsub(pattern = \"_H_\", \n                         replacement = \"_H-\", \n                         x = trial_data$trial)\n\nIt is helpful to know the levels we splitting so we can give the new columns informative names:\n\ndistinct(trial_data, trial)\n\n                         trial\n1  SWIdahoCereals_HRS_PAR_2016\n2  SWIdahoCereals_HWS_PAR_2016\n3  SWIdahoCereals_SWS_PAR_2016\n4  SWIdahoCereals_H-W_PAR_2017\n5  SWIdahoCereals_HRS_PAR_2017\n6  SWIdahoCereals_HWS_PAR_2017\n7  SWIdahoCereals_SWS_PAR_2017\n8  SWIdahoCereals_SWW_PAR_2017\n9  SWIdahoCereals_H-S_PAR_2018\n10 SWIdahoCereals_H-W_PAR_2018\n11 SWIdahoCereals_SWS_PAR_2018\n12 SWIdahoCereals_SWW_PAR_2018\n13 SWIdahoCereals_H-S_WEI_2018\n14 SWIdahoCereals_H-W_WEI_2018\n15 SWIdahoCereals_SWS_WEI_2018\n16 SWIdahoCereals_SWW_WEI_2018\n17 SWIdahoCereals_HRS_PAR_2019\n18 SWIdahoCereals_HRW_PAR_2019\n19 SWIdahoCereals_HWS_PAR_2019\n20 SWIdahoCereals_HWW_PAR_2019\n21 SWIdahoCereals_SWS_PAR_2019\n22 SWIdahoCereals_SWW_PAR_2019\n23 SWIdahoCereals_HRS_PAR_2020\n24 SWIdahoCereals_HRW_PAR_2020\n25 SWIdahoCereals_HWS_PAR_2020\n26 SWIdahoCereals_HWW_PAR_2020\n27 SWIdahoCereals_SWS_PAR_2020\n28 SWIdahoCereals_SWW_PAR_2020\n\n\nI will call the first column “program”, the second “crop” (those are wheat market classes), the third will be called “location” (PAR is an abbreviation for Parma), and the fourth column is year. This separate() command is being done on a character variable and will return all character variables, even though “year” could be coerced to be numeric.\n\ntrial_data_sep <- trial_data %>% \n  separate(trial, into = c(\"program\", \"crop\", \"location\", \"year\"), \n           sep = \"_\",  # specifying the separator between terms, an underscore\n           remove = FALSE) # tells R to keep the original variable \"trial\" in the data set\n\nSince I’m not sure of what are the two most recent years, lets check:\n\ntrial_data_sep %>% distinct(year) %>% arrange(desc(year))\n\n  year\n1 2020\n2 2019\n3 2018\n4 2017\n5 2016\n\n\nThe most recent two years are 2019 and 2020 and they are character variables. We can convert them to numeric with as.numeric(), but why bother in this instance?\n\ntrial_data_sep_filter <- trial_data_sep %>% \n  filter(year %in% c(\"2019\", \"2020\")) %>% \n  filter(variety %in% c(\"WA8268\", \"WB4418\", \"WB4311\", \"WB4623CLP\", \"WB4792\", \"WB7589\"))\n\n\nWrite out a result (any result) to file:\n\n\nwrite.csv(trial_data_sep_filter, \n          here::here(\"outputs\", \"problem_F_output.csv\"),\n          row.names = FALSE)"
  },
  {
    "objectID": "practice/solution-G.html",
    "href": "practice/solution-G.html",
    "title": "Solutions to Practice G",
    "section": "",
    "text": "Count missing data in “weather.csv”. This one is a bit hard!\n\nFirst, load libraries and import data:\n\nlibrary(dplyr); library(tidyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nweather <- read.csv(here::here(\"data\", \"weather_data.csv\")) \n\n\nweather %>%\n  group_by(station) %>%\n  summarise(tavg_na = sum(is.na(tavg)),\n            tmin_na = sum(is.na(tmin)),\n            tmax_na = sum(is.na(tmax)) )\n\n# A tibble: 4 × 4\n  station     tavg_na tmin_na tmax_na\n  <chr>         <int>   <int>   <int>\n1 USC00453546   13558       0       0\n2 USC00456215    6531       0       0\n3 USC00457059   15628       0       0\n4 USR0000WCNW       0       0       0\n\n\nUsing across()\n\nweather %>%\n  group_by(station) %>%\n  summarise(across(c(tavg, tmax, tmin), ~ sum(is.na(.x))))\n\n# A tibble: 4 × 4\n  station      tavg  tmax  tmin\n  <chr>       <int> <int> <int>\n1 USC00453546 13558     0     0\n2 USC00456215  6531     0     0\n3 USC00457059 15628     0     0\n4 USR0000WCNW     0     0     0\n\n\n\nCalculate average temperatures minimum and maximum\n\n\nweather %>% group_by(station) %>%\n    summarise(max_temp = mean(tmax, na.rm = TRUE),\n              min_temp = mean(tmin, na.rm = TRUE))\n\n# A tibble: 4 × 3\n  station     max_temp min_temp\n  <chr>          <dbl>    <dbl>\n1 USC00453546     17.0     4.56\n2 USC00456215     16.2     3.58\n3 USC00457059     15.8     2.66\n4 USR0000WCNW     18.1     5.40\n\n\n\nFind the largest and smallest differences between the daily minimum and maximum temperatures for each year.\n\n\nweather %>% \n    filter(!is.na(tmin) & !is.na(tmax)) %>%   # filter out missing data\n    mutate(temp_diff = abs(tmax - tmin)) %>% # make the calculation for all \n    group_by(year) %>% # grouping step\n    summarise(max_diff = max(temp_diff), # extract the maximum\n              min_diff = min(temp_diff)) # extract the minimum\n\n# A tibble: 43 × 3\n    year max_diff min_diff\n   <int>    <dbl>    <dbl>\n 1  1980     27.8    1.6  \n 2  1981     27.8    1.1  \n 3  1982     26.7    0.6  \n 4  1983     27.8    0.5  \n 5  1984     26.1    0.6  \n 6  1985     28.9    0.5  \n 7  1986     25      0.600\n 8  1987     27.7    1.1  \n 9  1988     25.5    0.6  \n10  1989     24.4    0.5  \n# … with 33 more rows\n\n\n\n\n\n\n\n\nProgramming Tip\n\n\n\nThis exercise is rather hard! It took me several tries to get it right. If you have trouble, take the exercise one step at a time, troubleshooting each step separately. It’s helpful to write down - with a pen and paper - what it is you want to do and how you think you might do this.\nThe function abs() was used to find the absolute difference. If both daily temperatures were negative, then the overall difference was negative, which ended up being the ‘minimum’, although by minimum difference, I was actually thinking about what was closest to zero. When there were wide swings in daily temperature, how big were they? And conversely, how small could these daily swings be?\nWriting down the exact problem you want to solve and how you want to solve it (the steps you want to take) can help you focus on what code is required to complete those steps. New programmers often merge the steps of how to fix a problem along with the effort required to write and troubleshoot code, which can quickly lead to distraction and feeling overwhelmed. One thing at a time, my peeps!"
  },
  {
    "objectID": "practice/solution-H.html",
    "href": "practice/solution-H.html",
    "title": "Solutions to Practice H",
    "section": "",
    "text": "Import data, remove unneeded columns, and pivot all columns but the first to long.\n\n\ngeno <- read.delim(here::here(\"data\", \"genotypic_data.txt\")) %>% dplyr::select(-(2:5))\ngeno_long <- geno %>% pivot_longer(cols = !1, \n                                   names_to = \"individual\",\n                                   values_to = \"marker_score\")\n\n\nnrow(geno_long)\n\n[1] 1717170\n\nhead(geno_long)\n\n# A tibble: 6 × 3\n  Markers                individual marker_score\n  <chr>                  <chr>             <int>\n1 recBobWhite_c10015_641 H0800080              0\n2 recBobWhite_c10015_641 H0800103L             0\n3 recBobWhite_c10015_641 H0800310              2\n4 recBobWhite_c10015_641 H0800314              2\n5 recBobWhite_c10015_641 H0900009              2\n6 recBobWhite_c10015_641 H0900081              0\n\n\n\nImport weather data and filter to 2000.\n\n\nweather <- read.csv(here::here(\"data\", \"weather_data.csv\")) %>% filter(year == 2000)\nweather_wide <- weather %>% select(station, julian_day, tmax_F) %>% \n  pivot_wider(id_cols = julian_day, \n              names_from = station, \n              values_from = tmax_F)\n\ndim(weather_wide)\n\n[1] 366   4\n\nhead(weather_wide)\n\n# A tibble: 6 × 4\n  julian_day USC00453546 USC00457059 USR0000WCNW\n       <int>       <dbl>       <dbl>       <dbl>\n1          1        39.0        32          35.1\n2          2        39.0        36.0        35.1\n3          3        35.1        33.1        34.0\n4          4        48.9        36.0        48.9\n5          5        43.0        43.0        48.0\n6          6        36.0        39.9        33.1\n\n\n\nExtra problem: transform “genotypic_data.txt” into “genotypic_data_rotated.csv”.\n\n\ngeno <- read.delim(here::here(\"data\", \"genotypic_data.txt\"))\ngeno2 <- dplyr::select(geno, -(1:5))\ngeno3 <- as.data.frame(t(geno2)) %>% mutate(individual = colnames(geno2)) %>% relocate(individual)\n### Next line is updated!!! 2023/02/06\ncolnames(geno3)[2:ncol(geno3)] <- geno$Markers\n### end updates\ngeno3$individual <- gsub(\"[.]\", \" \", geno3$individual) \n\n# check that things look okay: \ngeno3[sample(1:nrow(geno3), 5), sample(1:ncol(geno3), 5)]\n\ngsub() is relatively straightforward to use, but . without any modifiers is actually for wildcard matching (it matches everything!!) Regular expressions are crazy! So use [.] instead to specify that you in fact are referring to a period and not simply any character (including whitespace).\n\nreadr::write_csv(geno3, here::here(\"data\", \"genotypic_data_rotated.csv\"))"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This schedule is best understood as a draft that will be adjusted as needed.\n\n\n\nDate\nTopics\npractice problems\n\n\n\n\nBefore January 17\nDo Lesson Zero + Watch Video\n\n\n\nJanuary 17\nLesson 1: math operators\nLesson 2: vectorization\nLessons 1 & 2\n\n\nJanuary 19\nLesson 4: objects\nLesson 5: data structures\nLesson 5\nLesson 6\n\n\nJanuary 24\nLesson 6: R functions & help\nLesson 7: data import\nLesson 8: exporting data\nLesson 7\nLesson 8\n\n\nJanuary 26\nLesson 9: data wrangling\n\n\n\nJanuary 31\nLesson 9: data wrangling\nLesson 9\n\n\nFebruary 2\nLesson 10: data aggregation & summary\nLesson 11: reshaping data sets\nLesson 10\nLesson 11\n\n\nFebruary 7\nLesson 12: combining data sets\nLesson 13: your R set-up\n\n\n\nFebruary 9\nLesson 15: ggplotting\nFinal Lesson: Your R Future\n\n\n\nextra\nLesson 14: basic plotting\nLesson 16: repeating actions"
  }
]