[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This schedule is best understood as a draft that will be adjusted as needed.\n\n\n\nDate\nMain Topics\n\n\n\n\nBefore first day of class\nLesson Zero\n\n\nMay 20\nWorkshop orientation\nQuick tour of R Studio\nGetting to know data in R\n\n\nMay 21\nR documentation\nImporting tabular files\nData transformation & wrangling\nExporting R objects to file\n\n\nMay 22\nReshaping data\nCombining data sets\nData aggregation + summary\n\n\nMay 23\nCombining data sets (part 2)\nVisualizing data in R with ggplot\n\n\nMay 24\nFinding help\nReproducible research in R\nOpen time for questions\n\n\nExtra\nHow to do repeating actions",
    "crumbs": [
      "Course Info",
      "Schedule"
    ]
  },
  {
    "objectID": "practice/solution-I.html",
    "href": "practice/solution-I.html",
    "title": "Solutions to Practice I",
    "section": "",
    "text": "First, load all the libraries\n\nImport data sets:\n\n\ngenotypes &lt;- read_csv(here::here(\"data\", \"genotypic_data_rotated.csv\"), show_col_types = FALSE)\ntrials &lt;- read.csv(here::here(\"data\", \"trial_data.csv\"))\nmetadata &lt;- read.csv(here::here(\"data\", \"trial_metadata.csv\"))\n\n\nThe inner join:\n\n\nprob_innerjoin &lt;- inner_join(genotypes, trials, by = join_by(\"individual\" == \"variety\"))\n\n\nThe Semi-join:\n\n\nprob_semijoin_1 &lt;- semi_join(genotypes, trials, by = join_by(\"individual\" == \"variety\"))\nprob_semijoin_2 &lt;- semi_join(trials, genotypes, trials, by = join_by(\"variety\" == \"individual\"))\n\n\ndim(prob_innerjoin)\n\n[1]    76 10107\n\ndim(prob_semijoin_1)\n\n[1]     4 10102\n\ndim(prob_semijoin_2) \n\n[1] 76  6\n\n\nIt is the same group of varieties always returned, but in some cases (prob_innerjoin, prob_semijoin_2) it is all the observations from “trials” and sometimes it is all the observations from genotypes (prob_semijoin_1).\n\nThe anti-join:\n\n\nprob_antijoin &lt;- anti_join(genotypes, trials, by = join_by(\"individual\" == \"variety\"))\n\ndim(prob_antijoin)\n\n[1]   166 10102\n\n\n\nThe mega join:\n\nhere is one option\n\nmegajoin &lt;- full_join(trials, metadata, by = \"trial\") %&gt;% \n  semi_join(genotypes, by = join_by(\"variety\" == \"individual\"))"
  },
  {
    "objectID": "practice/solution-G.html",
    "href": "practice/solution-G.html",
    "title": "Solutions to Practice G",
    "section": "",
    "text": "Count missing data in “weather.csv”. This one is a bit hard!\n\nFirst, load libraries and import data:\n\nlibrary(dplyr); library(tidyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nweather &lt;- read.csv(here::here(\"data\", \"weather_data.csv\")) \n\n\nweather %&gt;%\n  group_by(station) %&gt;%\n  summarise(tavg_na = sum(is.na(tavg)),\n            tmin_na = sum(is.na(tmin)),\n            tmax_na = sum(is.na(tmax)) )\n\n# A tibble: 4 × 4\n  station     tavg_na tmin_na tmax_na\n  &lt;chr&gt;         &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n1 USC00453546   13558       0       0\n2 USC00456215    6531       0       0\n3 USC00457059   15628       0       0\n4 USR0000WCNW       0       0       0\n\n\nUsing across()\n\nweather %&gt;%\n  group_by(station) %&gt;%\n  summarise(across(c(tavg, tmax, tmin), ~ sum(is.na(.x))))\n\n# A tibble: 4 × 4\n  station      tavg  tmax  tmin\n  &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 USC00453546 13558     0     0\n2 USC00456215  6531     0     0\n3 USC00457059 15628     0     0\n4 USR0000WCNW     0     0     0\n\n\n\nCalculate average temperatures minimum and maximum\n\n\nweather %&gt;% group_by(station) %&gt;%\n    summarise(max_temp = mean(tmax, na.rm = TRUE),\n              min_temp = mean(tmin, na.rm = TRUE))\n\n# A tibble: 4 × 3\n  station     max_temp min_temp\n  &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n1 USC00453546     17.0     4.56\n2 USC00456215     16.2     3.58\n3 USC00457059     15.8     2.66\n4 USR0000WCNW     18.1     5.40\n\n\n\nFind the largest and smallest differences between the daily minimum and maximum temperatures for each year.\n\n\nweather %&gt;% \n    filter(!is.na(tmin) & !is.na(tmax)) %&gt;%   # filter out missing data\n    mutate(temp_diff = abs(tmax - tmin)) %&gt;% # make the calculation for all \n    group_by(year) %&gt;% # grouping step\n    summarise(max_diff = max(temp_diff), # extract the maximum\n              min_diff = min(temp_diff)) # extract the minimum\n\n# A tibble: 43 × 3\n    year max_diff min_diff\n   &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1  1980     27.8    1.6  \n 2  1981     27.8    1.1  \n 3  1982     26.7    0.6  \n 4  1983     27.8    0.5  \n 5  1984     26.1    0.6  \n 6  1985     28.9    0.5  \n 7  1986     25      0.600\n 8  1987     27.7    1.1  \n 9  1988     25.5    0.6  \n10  1989     24.4    0.5  \n# ℹ 33 more rows\n\n\n\n\n\n\n\n\nProgramming Tip\n\n\n\nThis exercise is rather hard! It took me several tries to get it right. If you have trouble, take the exercise one step at a time, troubleshooting each step separately. It’s helpful to write down - with a pen and paper - what it is you want to do and how you think you might do this.\nThe function abs() was used to find the absolute difference. If both daily temperatures were negative, then the overall difference was negative, which ended up being the ‘minimum’, although by minimum difference, I was actually thinking about what was closest to zero. When there were wide swings in daily temperature, how big were they? And conversely, how small could these daily swings be?\nWriting down the exact problem you want to solve and how you want to solve it (the steps you want to take) can help you focus on what code is required to complete those steps. New programmers often merge the steps of how to fix a problem along with the effort required to write and troubleshoot code, which can quickly lead to distraction and feeling overwhelmed. One thing at a time, my peeps!"
  },
  {
    "objectID": "practice/solution-C.html",
    "href": "practice/solution-C.html",
    "title": "Solutions to Practice C",
    "section": "",
    "text": "Vectors\n\nThere is no difference. If there is only item in a vector, it does not need to be indexed by position.\nThe way to do this shown in class:\n\n\nv1 = c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\")\nv1\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nThis is rather cumbersome. An easier way is to use the preset vectors letters and LETTERS which are the english alphabet in lowercase and uppercase, respectively. The index position 1 of each corresponds to the first letter of the alphabet, “a” or “A”.\n\nv1 &lt;- c(letters[1:13], LETTERS[14:26])\nv1\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\n\n\n\n\n\n\nFYI\n\n\n\nIf something seems tedious and slow in R, there is probably a shortcut.\n\n\n\nThe vector:\n\n\nv2 &lt;- c(1:10, 2:50)\n\n\n\nData Frames\n\nA possible data frame:\n\n\nd1 &lt;- data.frame(var1 = c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE),\n                 var2 = 1:6,\n                 var3 = \"orange\",\n                 var4 = as.factor(c(\"red\", \"blue\", \"blue\", \"purple\", \"green\", \"green\")))\n\nstr(d1)\n\n'data.frame':   6 obs. of  4 variables:\n $ var1: logi  TRUE TRUE TRUE FALSE FALSE FALSE\n $ var2: int  1 2 3 4 5 6\n $ var3: chr  \"orange\" \"orange\" \"orange\" \"orange\" ...\n $ var4: Factor w/ 4 levels \"blue\",\"green\",..: 4 1 1 3 2 2\n\n\nThe function str() is for checking the structure of an object. For a data frame, it will iterate over every column and give us the data type and some sample values.\n\nThe starting data frame\n\n\ndf &lt;- data.frame(one = 1:10,\n                 two = rnorm(10))\ndf$three &lt;- df$two + rnorm(10)\ndf$four &lt;- sample(c(\"A\", \"B\"), 10, replace = TRUE)\n\n\ndf$five &lt;- sample(c(\"apple\", \"huckleberry\"), 10, replace = TRUE)\ndf$six &lt;- as.factor(df$five)\n\n\nnew_df &lt;- df[,c(5, 1, 4, 2, 3)]\nnew_df\n\n          five one four         two        three\n1        apple   1    A  0.80384480  0.508446868\n2        apple   2    A -0.18909507 -0.003606352\n3        apple   3    B  0.21326690  0.496253983\n4        apple   4    A -0.60041568 -0.797644723\n5  huckleberry   5    B  0.36361247 -1.900992069\n6  huckleberry   6    A -0.13953946  1.505380238\n7        apple   7    B  1.90023686  2.726589574\n8  huckleberry   8    A  0.09647295  0.140269500\n9        apple   9    A  0.33298829 -0.007595899\n10 huckleberry  10    B  1.89340885  2.114726925\n\n\n\n\nLists\n\nThe list\n\n\nmylist = list(x1 = \"snow\", \n              x2 = 45:65, \n              x3 = rep(letters[1:3], each = 3), \n              x4 = matrix(1:100, nrow = 10, ncol=10))\nmylist\n\n$x1\n[1] \"snow\"\n\n$x2\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n$x3\n[1] \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"c\" \"c\" \"c\"\n\n$x4\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\nThere are two ways to remove x3. The First is to create a new list from the object ‘mylist’ and don’t include x3:\n\nmylist2 &lt;- list(mylist[[1]], mylist[[2]], mylist[[4]])\nmylist2\n\n[[1]]\n[1] \"snow\"\n\n[[2]]\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n[[3]]\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\nLists also let you declare a list item as NULL which makes it completely go away!\n\nmylist[[3]] &lt;- NULL\nmylist\n\n$x1\n[1] \"snow\"\n\n$x2\n [1] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n\n$x4\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\n\nA possible list:\n\n\nl1 &lt;- list(v1, v2, d1)\n\nSet the 4th item of vector inside a list to NA. The first item is a vector, so we will use that.\n\nl1[[1]][4] &lt;- NA\n\nYou can index a vector inside of a list by indexing the list first, then the vector.\n\nRemove list item:\n\n\nl1[[2]] &lt;- NULL\n\nWhen an item is set to NULL in a list, it disappears.\n\n\n\n\n\n\nEvergreen lesson\n\n\n\nAlways always always check your object to make sure it looks like what you expected it to.\nCommon checks:\n\nthe dimensions (row number, column number, length, etc) are what you expect\nthe data types are what you expect\nthe values are what you expect"
  },
  {
    "objectID": "practice/solution-A.html",
    "href": "practice/solution-A.html",
    "title": "Solutions to Practice A",
    "section": "",
    "text": "\\[ \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\]\n\\(\\pi\\) = 3.14 \\(e\\) = 2.718 \\(\\mu\\) = 50 \\(\\sigma\\) = 5 \\(x\\) = 20\n\nFor this problem, there are several possible solutions:\n\n\nManual the whole way down:\n\n\n1/(5*(2*3.14)^0.5)*2.718^(-0.5*((20-50)/5)^2)\n\n[1] 1.217755e-09\n\n\n\nEmploying a few shortcuts\n\n\n1/(5*sqrt(2*pi))*exp(-0.5*((20-50)/5)^2)\n\n[1] 1.215177e-09\n\n\n\nR function that estimates the standard normal density (the equation above is the probability density function for the normal distribution)\n\n\ndnorm(x = 20, mean = 50, sd = 5)\n\n[1] 1.215177e-09\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s not expected you would be aware of the second and third solutions given what has been taught thus far, but it’s helpful to be aware that many shortcuts exist in R to make coding easier.\n\n\n\nUsing the manual approach:\n\n\nx = c(10, 20, 30, 40, 50)\n1/(5*(2*3.14)^0.5)*2.718^(-0.5*((x-50)/5)^2)\n\n[1] 1.014069e-15 1.217755e-09 2.679505e-05 1.080317e-02 7.980869e-02"
  },
  {
    "objectID": "practice/practice-H.html",
    "href": "practice/practice-H.html",
    "title": "Practice H",
    "section": "",
    "text": "(for the data reshaping lesson)\n\nAs always, consider how these reshaping functions can support your own research and data analysis.\n\n\nImport “genotypic_data.txt” and remove columns 2 through 5 (‘CHROM’, ‘POS(cM)’, ‘Major_allele’, ‘Minor_allele’). What is left is genetic marker names and the marker scores for the individual lines (each column is an genetically distinct wheat line). Using pivot_longer(), reshape this object to long so there is one column for the marker name, one column for the wheat name, and the one column for the marker score. How many rows long is this object? Can you image trying to do this by hand??\nImport “weather_data.csv”. Filter to any single year and reshape the data from long to wide so that the levels in “station’ form the new column headers, ‘julian_day’ is the identifying column and the cells are filled with data from ‘tmax_F’.\nHere is a crazy extra exercise that utilizes transpose instead of pivoting. It’s not strictly related to reshaping. Only try this if you are in the mood for a challenge.\n\nThis problem is indicative of a data wrangling you can experience out in the wild. You are given a data set in one format, but a package requires your data be in another format.\nThe file “genotypic_data.txt” is a transposed version of “genotypic_data_rotated.csv”. Import “genotypic_data.txt” into R and use R commands to recreate “genotypic_data_rotated.csv”.\nThe column “individual” no longer has periods in the listed names, but the original file had periods in those names since they were column headers. Write code to remove those periods from the column “individual” in your transformed column (hint: look at the documentation for gsub()).\nSolution"
  },
  {
    "objectID": "practice/practice-F.html",
    "href": "practice/practice-F.html",
    "title": "Practice F",
    "section": "",
    "text": "(for the data wrangling lesson)\nIf you have your own data, import it and consider what sort of data wrangling you might need to do on the data set to ready it for analysis - does something need to be filtered or calculated? This is a good moment to apply skills learned. \n\nImport “trial_metadata.csv” with the readr function read_csv(). Create a new variable that combined information in the ‘location’ and ‘irrigation’ columns.\nFilter the imported data set for when the location is “Parma” and sort the data set based on planting date. Assign the results to a new object.\nSelect 4 columns from the data set and rename one of them. Assign these results to a new object.\nImport “weather_data.csv”, select the first five columns and reduce that data set to unique rows (look into using distinct() for extracting the unique observations).\nNEW: Import “trial_data.csv”. Split the “trials” column into 4 variables using separate() as we did in class (or see the lesson notes). Filter the data set to the 2 most recent years and the varieties WA8268, WB4418, WB4311, WB4623CLP, WB4792, and WB7589.\n\nHere is the prep work to do prior to separate():\n\ntrial_data &lt;- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\ntrial_data$trial &lt;- gsub(pattern = \"_H_\", \n                         replacement = \"_H-\", \n                         x = trial_data$trial)\n\n\nOutput the result from any of the previous problems to file.\n\nSolution"
  },
  {
    "objectID": "practice/practice-Day1.html",
    "href": "practice/practice-Day1.html",
    "title": "Day1",
    "section": "",
    "text": "(for lessons on getting to know data)\nnote: covered practice tests: A, B, C (to be removed from here)\n\nImport “caribbean_maize.csv” with the function read.csv() and assigns it to an object named “data2”.\nCreate the vector names ‘plot’, ‘ears’, and ‘site’ by extracting these variables from data2.\nWhat is the data type of these vectors?\nConvert ‘plot’ into factor. Inspect the results. What happened?\nCreate a new vector (M1) as a product of addition of 100 to ‘ears’.\nMake a data frame (data3) consisting of ‘plot’, ‘ears’, and ‘isle’ using data.frame() function and look at the structure of the data.\nExtract the values located in the first 2 rows and third column of data3.\nCreate a boxplot with ‘site’ and ‘ears’ variables from data3.\n\n\n\n\n\n\n\nProblem Set for Data Importation\n\n\n\n\n\nImport “caribbean_maize.csv” with the function read_csv() and assigns it to an object named “data2”.\n\n\n\n\n\n\n\n\n\ntest\n\n\n\n\n\ncontent"
  },
  {
    "objectID": "practice/practice-C.html",
    "href": "practice/practice-C.html",
    "title": "Practice C",
    "section": "",
    "text": "(for the lesson on data structures)\n\nVectors\n\nYou have this object in your R session: x = 7. What is the difference between x[1] and x?\nMake a vector of letters “a” to “m” (all lowercase) and letters “N” to “Z” (all uppercase).\nMake a vector of numbers 1 to 10 and 2 to 50.\n\n\n\nData Frames\n\nMake a data frame consisting of 6 rows and 4 columns, where one is a character variable, another is numeric, another is logical and the another is a factor. Verify that each column type is what you intended it to be.\nYou have this data frame:\n\n\ndf &lt;- data.frame(one = 1:10,\n                 two = rnorm(10))\ndf$three &lt;- df$two + rnorm(10)\ndf$four &lt;- sample(c(\"A\", \"B\"), 10, replace = TRUE)\n\n\nAdd another column called ‘five’ that is a character variable consisting of levels that are fruits of your choice.\nAdd another column called ‘six’ that is ‘five’ coerced into a factor.\nMake a new data frame with the columns in this order: “five”, “one”, “four”, “two”, “three”.\n\n\n\nLists\n\nYou have this list: mylist = list(x1 = \"snow\", x2 = 45:65, x3 = rep(letters[1:3], each = 3), x4 = matrix(1:100, nrow = 10)). Return this list without x3.\nPut all your vectors and the data frame from the previous problems in this exercise set into a list. For the first list item that has a vector, change the forth item of that vector to missing.\nFor the list created in the previous problem, delete the second item.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nthe functions letters() and LETTERS() provide a shortcut for problem #3.\ntry using NULL for the last problem (under the “Lists” heading).\n\n\n\n\nSolution"
  },
  {
    "objectID": "practice/practice-A.html",
    "href": "practice/practice-A.html",
    "title": "Practice A",
    "section": "",
    "text": "(for lessons on R for mathematics and vectorized operations)\n\nMake this calculation using R math operators\n\n\\[ \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\] Where: \\(\\pi\\) = 3.14, \\(e\\) = 2.718, \\(\\mu\\) = 50, \\(\\sigma\\) = 5, \\(x\\) = 20\n\nRepeat this calculation where \\(x\\) = {10, 30, 40, 50, 60}\n\nThe Solution"
  },
  {
    "objectID": "lessons/rstudio-tour.html",
    "href": "lessons/rstudio-tour.html",
    "title": "Introduction to RStudio",
    "section": "",
    "text": "Learning Recap\n\n\n\n\n\nAt the end of this lesson, you should understand:\n\nwhat the different tabs in each of the panes of RStudio do\nwhat is in each menu item in Rstudio and have a general sense of functionality available\nRStudio is more than a graphical user interface for R. It is an integrated development environment (IDE), that is a full service application for supporting software development. It can perform multitudes, so much more than what most R users need.\nIt is the supermarket of R functionality. Like a supermarket, there are parts of RStudio you will visit frequently and parts you will rarely if ever use. After 12+ years of using RStudio on a near daily basis, there are several parts of it that I continue to be unfamiliar with! Ths is okay - clearly, I have not needed those parts. You will come to find what sections you will need most over time and practice.\nStill, it helps to have a guided tour. Let’s dive into this.",
    "crumbs": [
      "Lessons",
      "Quick tour of R studio"
    ]
  },
  {
    "objectID": "lessons/rstudio-tour.html#the-panes",
    "href": "lessons/rstudio-tour.html#the-panes",
    "title": "Introduction to RStudio",
    "section": "The Panes",
    "text": "The Panes\nHere is a simplified schematic:\n\n\n\n\n\n\n\n\n\nThese can be rearranged, but for this class, we will use the default arrangement.\n\nThe Console/Terminal/Background Jobs\nDefault location: left or bottom left\n\n\n\n\n\n\n\nTab\nPurpose\n\n\n\n\nConsole\nwhere R commands are actually done\n\n\nTerminal\nuse a terminal language such as bash or the windows command prompt\n\n\nBackground jobs\nusual pacakage installation\n\n\n\nIn this workshop, we will only be using the Console.\n\n\nFiles/Plots/Packages/Help/Viewer/Presentation\n\n\n\n\n\n\n\n\n\nDefault location: bottom right\nProbably the most useful pane - we will be here frequently!\n\n\n\nTab\nPurpose\n\n\n\n\nPlots\nview plots\n\n\nFiles\nexplore your file system\n\n\nPackages\ninstall, update and load packages\n\n\nHelp\nhelps files & examples\n\n\nViewer\nfor previewing websites\n\n\nPresentation\nfor previewing presentations\n\n\n\nWe will not be using the Viewer or Presentations tabs in this workshop.\nWhat are Packages?\nThese make the world go around in R. All of R consists of packages or libraries that have certain functionality associated with them. Some of are maintained by the R core team, others are maintained by outsiders. All packages are open source and most are a volunteer effort. When you open R, several packages are loaded automatically: base, datasets, graphics, grDevices, methods, stats, utils.\nWe will talk about package installation and usage later in this course/workshop.\n\n\nEnvironment/History/Connections/Build/Git/Tutorial\n\n\n\n\n\n\n\n\n\n\n\n\nTab\nPurpose\n\n\n\n\nEnvironment\nobjects created and existing in your current R session\n\n\nHistory\nprevious R command run\n\n\nConnections\nto connect to an external database\n\n\nBuild\nfor building R packages and other large projects\n\n\nGit\nonly visible if you’ve initialized a git repository\n\n\nTutorial\ntutorials build by Posit (very helpful)\n\n\n\nhere\n\n\nOur Scripts Pane\n\n\n\n\n\n\n\n\n\ndefault location: upper left\nThese are all the files we create and edit: .R, .Rmd, .txt, etc. When we open files from the “Files” pane, this is where it shows up.",
    "crumbs": [
      "Lessons",
      "Quick tour of R studio"
    ]
  },
  {
    "objectID": "lessons/rstudio-tour.html#the-upper-menu-items",
    "href": "lessons/rstudio-tour.html#the-upper-menu-items",
    "title": "Introduction to RStudio",
    "section": "The Upper Menu Items",
    "text": "The Upper Menu Items\n\n\n\n\n\n\n\n\n\n\nFile\n\nOpening and/or creating files\n\nOpening and/or creating projects\n\nRecent files, recent project\n…standard file functionality\n\n\n\nEdit\n\nCopy, paste, find\nVery handy “find in files” feature!\n\n\n\nCode\n\nIncredible useful set of commands\nSome are very simple (e.g. “comment lines”), others are complex (e.g. “rename in scope”)\nOver time, you will learn what these mean and perhaps make use of them (if you don’t, that is okay)\n\n\n\nView\n\nRearrange panes\nZoom in/out\nOverall not that useful, except for the shortcuts\n\n\n\nPlots\n\n(self explanatory)\n\n\n\nSession\n\nVery handy for restarting your R session\nManually set the working directory\n\n\n\nBuild\n\nAdvanced tools for building packages, websites, et cetera. I’ve never visited this part of the supermarket.\n\n\n\nDebug\n\nTools for debugging code (removing scripting errors). We will not use this in the workshop! But you can learn more about it here.\n\n\n\nProfile\n\nFor code profiling (checking how long it takes your code to run). We will also not be using this in the workshop. This is part of the supermarket I rarely visit.\n\n\n\nTools\n\nSome handy utility function. I mostly use this menu item to set preferences via “Global Options”.\n\n\n\nHelp\n\nMmore utility functions. You can check for RStudio updates here, access community help forum, and other forms of documentation in addition to standard help files.\n\n\n\nmore\nRstudio has a massive number of keyboard shortcuts. You can find them in the menu (Help –&gt; Cheat Sheets) and summarized in this cheat sheet",
    "crumbs": [
      "Lessons",
      "Quick tour of R studio"
    ]
  },
  {
    "objectID": "lessons/reproducible-research.html",
    "href": "lessons/reproducible-research.html",
    "title": "Setting up R for Reproducible Research",
    "section": "",
    "text": "This lesson assumes you have installed R and RStudio.\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nknow to disable saving .Rdata\nknow to set up an R Project\nknow what reproducible research and be aware of practices that support this\n\n\n\n\n\nWhat is Reproducible Research?\nSlide set\n(navigate through the slides with your keyboard arrows)\nLearn More\n\n\nOptimal Set-up for Reproducible Research\nSlide set\n\n\n\n\n\n\nPutting it all together\n\n\n\nThese “meta” aspects of how to use R and implement reproducible research practices in your daily work will benfit you greatly. There is some upfront effort, but the final result is clearer code that you can understand in future and reuse."
  },
  {
    "objectID": "lessons/r-style-conventions.html",
    "href": "lessons/r-style-conventions.html",
    "title": "Object Naming and Other Style Concerns",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nunderstand how to assign variables and collections of numbers to an object name\nknow the rules for how to name objects\nunderstand reserved words in R and how to find them\nunderstand how white space functions in R\n\n\n\n\n\nObject assignment\nIt is rather cumbersome to continually retype or paste information. We can avoid this by assigning information to an R object.\nTraditionally in R, the left arrow is used for object assignment, &lt;- (the less-than symbol and a dash), but the standard equals sign, = also works.\nThese are equivalent:\n\nx &lt;- 1\nx\n\n[1] 1\n\nx = 1\nx\n\n[1] 1\n\n\nWe can assign multiple numbers to an object:\n\nx_vector &lt;- 1:10\ny_vector &lt;- c(2, 4, 6, 8, 10)\n\nThe left arrow assignment &lt;- takes everything on the right side of the arrow and assigns it the object name on the left.\n\n\nObject naming\nIt is your choice (mostly) about what to name R objects. There are a few rules and conventions to follow:\n\nChoose a name that is short, yet descriptive.\nSpaces are generally not allowed and a huge pain - so avoid doing this.\nDon’t start an object name with a number or symbol (this is technically possible, but also a pain).\nR is case sensitive, so test is different from Test and TEST. Be mindful of this! It trips many folks up.\nIt is possible that future you will thank your past self for using lowercase and avoiding special symbols (aside from . and _)\nIf you start a function name with a “.” (e.g. .variable), you won’t see it listed in the global environment (which can be frustrating). This is not recommended for newer R users.\nYou cannot use “reserved words” from the R language (terms set aside for very specific purposes in R). When typing these in an R console, they usually light up in a special colors.\n\nHere is some discussion on object naming in R.\n\n\nReserved words\n\n\n\n\n\n\n\nreserved word\nmeaning\n\n\n\n\nTRUE FALSE\nlogical\n\n\nNA\nmissing value\n\n\nNaN\nnot a number/undefined\n\n\nNULL\nno value/undefined\n\n\nInf -Inf\ninfinity\n\n\nfor in\nfor loops\n\n\nif else while break next repeat\ncontrol flow\n\n\nNA_integer_ NA_real_ NA_complex_ NA_character_\nmissing data by data type\n\n\n\nIt’s easy to forgot these. Run ?reserved in an R console or check here to remind yourself if need be.\nSome examples of reserved words in the wild:\n\nlog(0)\n\n[1] -Inf\n\n0/0\n\n[1] NaN\n\n2/0\n\n[1] Inf\n\n\n\n\nSome additional notes on R syntax\n\nmost often, the amount of white space does not matter.\n\nThese are the same:\n\n4/3\n\n[1] 1.333333\n\n4/    3\n\n[1] 1.333333\n\n4    /  3\n\n[1] 1.333333\n\n\nThese are also the same:\n\nlog(10)\n\n[1] 2.302585\n\nlog( 10 )\n\n[1] 2.302585\n\nlog ( 10)\n\n[1] 2.302585\n\n\n\nR expects certain things to be paired or completed before it will send it to the interpreter\nAs mentioned, earlier a hard return is sufficient to send a command to the R interpreter.\nExceptions: binary operators (= those expecting 2 numbers): +, -, *, /, ^, ==, etc. R is waiting for these to be ‘completed’.\nExceptions: unclosed parentheses (), brackets [] {}, or quotes ' ' \" \". R will wait for these to be completed. A single quote must always be complemented by a second single quote, and a double quote likewise must always have a second quote to complete it. Left parentheses, curly braces, or brackets much also be accompanying by their right-sided complement.\nExamples\n\n\n1 + 2\n{ }\n( )\n[ ]\n\"  \"\n' '\n` `\n\nErrors\n\n\n1 + \n'\n(  } ] \n\"\n' \"\n\nThere is no difference between double and single quotes on a practical level, but R will interpret them as different commands (so a single quote cannot close a double quote). This is useful when there is nested levels of quoting. This is uncommon, but, it does happens now and then.\n\nExample:\n\n\"r `format(Sys.Date(), '%b %d, %Y')`\"\n\n[1] \"r `format(Sys.Date(), '%b %d, %Y')`\"\n\n\nIf this particular piece of code makes no sense to you, do not worry. The point of presenting this code at this stage in your journey of learning R is to demonstrate how single quotes, double quotes and the backtick ` can be used together in single statement.\n\n\n\n\n\n\nPutting it all together\n\n\n\nMatching parentheses, quotes, and other paired structures is important in R. The R interpreter may stop if it is waiting for a statement to be ‘closed’. As a result, RStudio will often automatically append a pair while you type. Try typing a single quote, double quote, square bracket, curly bracket, parentheses or backtick and notice how this happens.\nRstudio furthers this practice when you highlight text. In RStudio, highlight some text and then type the key for double quotes. What happened? Try the same with parentheses and the other keys/symbols mentioned. Once you get used to this, it will save you some time!",
    "crumbs": [
      "Lessons",
      "R style conventions"
    ]
  },
  {
    "objectID": "lessons/math-operators.html",
    "href": "lessons/math-operators.html",
    "title": "Math Operators & Vectorizing",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nunderstand sorts of math operators available in R and how to use them\nunderstand logical operators in R\nbe aware of the order of operations\nbe aware of how whitespace is interpreted in R\nunderstand how to use parentheses, brackets, braces and quotations in R\nbe able to repeat a set of operations across a vector\nbe able to create a sequence of numbers in R using any starting value and any ending value\n\n\n\n\n\nR as a calculator\n\nAddition, subtraction, multiplication, division\n\n1 + 3\n\n[1] 4\n\n10 - 15\n\n[1] -5\n\n2*8\n\n[1] 16\n\n60/12\n\n[1] 5\n\n\nA hard return between lines of code is sufficient to separate the commands.\n\n\nExponentiation\n\n3^2\n\n[1] 9\n\n2^4\n\n[1] 16\n\n9^0\n\n[1] 1\n\n2^-2\n\n[1] 0.25\n\n\nR can also handle scientific notation. This number, 3e2 is equivalent to \\(3 * 10^2\\), or \\(3000\\).\n\n\nRoots (square, cube, ….)\n\n4^(1/2)\n\n[1] 2\n\n8^(1/3)\n\n[1] 2\n\n\n\n\nLogs\n\nlog(10)\n\n[1] 2.302585\n\n\n(base e)\nlog with base 10\n\nlog10(10)\n\n[1] 1\n\n\nlog with base 2\n\nlog2(4)\n\n[1] 2\n\n\nIf you have other bases:\n\nlog(10, base = 4)\n\n[1] 1.660964\n\n\n\n\nOperations with sign\n(positive and negative signs are called “unary operators”)\n\n3*-4\n\n[1] -12\n\n\nLike in standard math, only negatively signed numbers need to be specified.\n\n\nInteger division (the remainder is discarded)\n\n5 %/% 3\n\n[1] 1\n\n\n\n\nModulus operator (return the remainder after division)\n\n5 %% 3\n\n[1] 2\n\n\n….and so much more\n\n\n\nLogical Operators\nThese test for conditions (“is this true?”) and return either a TRUE or FALSE\n\n\n\nsyntax\nFunction\n\n\n\n\n==\nequal\n\n\n!=\ndoes not equal\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n&lt;=, &gt;=\nless than and equal to, and greater than equivalent\n\n\n\nExamples\n\n1 == 1\n\n[1] TRUE\n\n1 == 2\n\n[1] FALSE\n\n1 != 2\n\n[1] TRUE\n\n1 &lt; 1\n\n[1] FALSE\n\n1 &gt; 1\n\n[1] FALSE\n\n1 &lt;= 1\n\n[1] TRUE\n\n1 &gt;= 1\n\n[1] TRUE\n\n\nWhen testing multiple conditions: use & (‘and’) if two things must be true and | (‘or’) if one of two things must be true:\n\n1 &lt; 2 & 1 != 1 \n\n[1] FALSE\n\n1 &lt; 2 | 1 != 1\n\n[1] TRUE\n\n\n\n\nOrder of operations.\nThe rules:\n\noperations go left to right\nexponents are first, followed by ‘unary operators’ (+/- signs)\nmultiplication and division before subtraction and/or addition\nlogical operators come after all mathematical transformations\nParentheses overall all other rules!\n\nWhat results from this?\n\n2^3+4+12*7/2 &lt;= -6*9\n\nWhen in doubt about the order of operations use parentheses!\nHere is the official R guide to order of operations (warning: this is complicated and refers to functions beyond mathematical operators).\n\n\n\n\n\n\nNote\n\n\n\nIf you become stuck with an unfinished command, you can use the escape key, ESC, to get out of it.\n\n\n\n\nVectorizing operations\nUsing R as a calculator between a few numbers is handy, but typically we are hoping to do so much more with it, such as performing a calculations across a long list of numbers.\nR is naturally vectorized, which means that you can easily perform a mathematical operation across a vector of numbers (no need to write loops!)\nSay we have a collection of numbers from 10 to 20 and we want to multiple them all by 12. We can create a sequence of numbers by wrapping them all in c() command (for “concatenate”) and separating each with a comma.\n\nc(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\nThen those numbers can be operated on by any math operator:\n\nc(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20) * 10 - 1\n\n [1]  99 109 119 129 139 149 159 169 179 189 199\n\n\nThere’s also a quicker way to specify a sequence of integers using the notation start:end:\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nIt also counts down:\n\n20:10\n\n [1] 20 19 18 17 16 15 14 13 12 11 10\n\n\nAnd works with negative integers:\n\n-5:5\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n\nThese can be operated on:\n\n(-5:5)^2\n\n [1] 25 16  9  4  1  0  1  4  9 16 25\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nCheck the “History” tab in the upper right hand pane (this should be to the right of the “Environment” tab). What is there?\nIf you followed along and coded the above examples, you should see the command you ran previously (including any mistakes). This is your command history. There are several icons directly above your history - explore what those do (hoover before clicking any icon to make sure you are okay with action before performing it).",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Math Operators"
    ]
  },
  {
    "objectID": "lessons/ggplotting.html",
    "href": "lessons/ggplotting.html",
    "title": "Publication-Quality Plots with ggplot2",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nunderstand how to construct a ggplot\nunderstand that a ggplot is composed of layers\nknow how to map data set information to a ggplot\nbe able to save a ggplot to your file system\n\n\n\n\n\nData and packages\nWe will load ggplot2, which will automatically load a useful package of color palette, RColorBrewer. The package dplyr is also loaded since we will need to use some of their functions to prepare the data for plots.\nThe data set, “nass.hay” is from the agridat package. It is historic data on hay production across U.S. states from 1909 to 2012 gathered by the National Agricultural Statistics Service. This script also creates a data object only containing data from Idaho, and a data object with hay production stats from 2012.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nThe package ‘agridat’ is needed for this lesson.\n\nif(!require(agridat)) {\n  install.packages(\"agridat\")\n  library(agridat)}\n\nagridat is a package consisting solely of several hundred agricultural data sets, along with example code for data visualiztion or analysis. This is an extraordinary resource! This lesson will use a data set from the National Agricultural Statistics Service (NASS). This is hay yields between 1909 and 2012 for by state (in the US). Some states do not have Ha\n\ndata(\"nass.hay\")\nstr(nass.hay)\n\n'data.frame':   5044 obs. of  4 variables:\n $ year : int  1909 1909 1909 1909 1909 1909 1909 1909 1909 1909 ...\n $ state: Factor w/ 49 levels \"Alabama\",\"Alaska\",..: 1 3 4 5 6 7 8 9 10 11 ...\n $ acres: num  275000 98000 409000 2503000 1180000 ...\n $ yield: num  0.96 2.42 1.05 1.61 1.73 1.15 1.22 0.69 0.86 2.16 ...\n\nsummary(nass.hay)\n\n      year              state          acres             yield      \n Min.   :1909   Alabama    : 104   Min.   :   6900   Min.   :0.250  \n 1st Qu.:1935   Arizona    : 104   1st Qu.: 370000   1st Qu.:1.228  \n Median :1961   Arkansas   : 104   Median : 998500   Median :1.700  \n Mean   :1961   California : 104   Mean   :1368800   Mean   :1.867  \n 3rd Qu.:1987   Colorado   : 104   3rd Qu.:2050000   3rd Qu.:2.240  \n Max.   :2012   Connecticut: 104   Max.   :5964000   Max.   :8.160  \n                (Other)    :4420                     NA's   :48     \n\nhead(nass.hay)\n\n  year       state   acres yield\n1 1909     Alabama  275000  0.96\n2 1909     Arizona   98000  2.42\n3 1909    Arkansas  409000  1.05\n4 1909  California 2503000  1.61\n5 1909    Colorado 1180000  1.73\n6 1909 Connecticut  387000  1.15\n\n\nFirst, let’s create a few smaller data sets by filtering the data by different conditions.\n\n# all observations from Idaho\nhay_idaho &lt;- filter(nass.hay, state == \"Idaho\") \n# all observations for 2012 \nhay2012 &lt;- filter(nass.hay, year == 2012)\n# all observations for Idaho, Oregon, Washinton and Montana\nhay_pnw &lt;- filter(nass.hay, state %in% c(\"Oregon\", \"Washington\", \"Montana\",\"Idaho\")) |&gt; \n  mutate(state = as.character(state)) \n\n\n\nBuilding a ggplot\n\nA ggplot needs 3 parts:\n\ndata\naesthetics which connect or map the data to the geom\na type of plot, or geom, to implement\n\nNote:\n\nggplot2 uses the + notation in their plots (see below). It’s my understanding that there is some regret over this style decision by the ggplot authors, but it is now an accepted convention.\nggplot2 also uses non-standard evaluation, so, often column names do not need to be quoted\n\ncommon mapping aesthetics:\n\nx (the x variable)\n\ny (the y variable)\n\ncol (color for lines, points, outlines)\n\nfill (color when something has a fill color such as a boxplot)\n\ngroup (when a plotted option should be grouped, then plotted)\n\n\n\n\n\nbuild a simple plot\nGoal: plot yield over time for hay production in Idaho\nHere is what the final plot will look like:\n\n\n\n\n\n\n\n\n\n\nStep 1: Add the data\n\nggplot(hay_idaho)\n\n\n\n\n\n\n\n\nThere is not much to see here since we have not specified anything beyond the data set to use.\n\n\nStep 2: Add aesthetics\n\nggplot(hay_idaho, mapping = aes(x = year, y = yield))\n\n\n\n\n\n\n\n\nThis step mapped “year” and “yield” from the hay_idaho data set to the x and y axes, respectively. Nothing is plotted because we have not specified what type of plot geom we want.\n\n\nStep 3: Add a geom\n(explicit mapping command dropped - use a positional argument instead)\n\nggplot(hay_idaho, aes(x = year, y = yield)) +\n  geom_line(na.rm = TRUE)\n\n\n\n\n\n\n\n\nWe can ignore this warning telling us there is missing data. That happens when using NASS data!\nQuestion: What happens if we use |&gt; instead of +?\n(try it to find out)\n\n\n\nCommon plot improvements\n\nplot title and axis labels\n\nggplot(hay_idaho, aes(x = year, y = yield)) +\n  geom_line(na.rm=TRUE) +\n  ggtitle(\"Total historic hay yields in Idaho\") + \n  xlab(\"Year\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\n\n\nChange line settings\n(and other geom arguments)\n\nggplot(hay_idaho, aes(x = year, y = yield)) +\n  geom_line(color = \"turquoise3\", linewidth = 1, linetype = 1, na.rm=TRUE) +\n  ggtitle(\"Total historic hay yields in Idaho\") + \n  xlab(\"Year\") +\n  ylab(\"yield (1000's of tons)\")\n\n\n\n\n\n\n\n\nThe default line type is “1”, which is a plain line. There are other types:\n\n\n\n\n\n\n\n\n\n\n\n\nOther common geoms:\n\npoints\n\nggplot(hay_idaho, aes(x = year, y = yield)) +\n  geom_point(shape = 2, col = \"navy\", na.rm=TRUE) +\n  ggtitle(\"Total historic hay yields in Idaho\") + \n  xlab(\"Year\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\nThere are many options for the type of plotting character (“pch” in base R plotting and “shape” in ggplot):\n\nThe default shape is “1” (the circle). Plotting symbols 21 - 25 have outline color and fill attributes, while the other symbols only take a single color argument.\n\n\narea\n\nggplot(hay_idaho, aes(x = year, y = yield)) +\n  geom_area(fill = \"orange\", col = \"gray20\", na.rm=TRUE) +\n  ggtitle(\"Total historic hay yields in Idaho\") + \n  xlab(\"Year\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\n\n\nboxplot\n\nggplot(hay_pnw, aes(x = state, y = yield)) +\n  geom_boxplot(na.rm=TRUE) +\n  ggtitle(\"Yearly hay yields in the Pacific Northwest\") + \n  xlab(\"State\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\nColor all boxplots the same:\n\nggplot(hay_pnw, aes(x = state, y = yield)) +\n  geom_boxplot(fill = \"yellow\", na.rm=TRUE) +\n  ggtitle(\"Yearly hay yields in the Pacific Northwest\") + \n  xlab(\"State\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\nColor boxplots by state:\n(This requires an aes statement)\n\nggplot(hay_pnw, aes(x = state, y = yield, fill = state)) +\n  geom_boxplot(na.rm=TRUE) +\n  ggtitle(\"Yearly hay yields in the Pacific Northwest\") + \n  xlab(\"State\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\nQuestion: What happens if we specify “color = state” instead of “fill = state”?\n(Try it and find out).\n\n\n\n\n\n\nNote\n\n\n\nAesthetic statements (those wrapped in aes()) can be made in the first ggplot argument or within a specific geom. These two examples are equivalent:\nexample\nggplot(mydata, aes(x, y)) +\n  geom_line()\nexample 2\nggplot(mydata) +\n  geom_line(aes(x, y))\nThe aes() argument is sometimes specified within a geom if a particular aesthetic changes between geom (e.g. the fill aesthetic changes). Otherwise, the default aesthetic is whatever was previously specified.\n\n\n\n\nhistograms and density plots:\n\nggplot(hay_idaho, aes(x = yield)) +\n  geom_histogram(fill = \"gray70\", col = \"black\", bins = 20, na.rm=TRUE)\n\n\n\n\n\n\n\n\nUnlike in base R plotting, creating a density plot and shading the are under the curve is easy.\n\nggplot(hay_pnw, aes(x = yield, fill = state)) +\n  geom_density(na.rm=TRUE)\n\n\n\n\n\n\n\n\nIn this plot, it is hard to see what is going on since the each distribution covers up the one plotted before it (so we can’t really see Idaho, but Washington’s hay yield distribution is clear). The attribute “alpha” can be used to add a transparency to colors. The code is alpha =  n where n is the proportion of the color that is shown (0 is completely transparent and 1 is no transparency).\n\nggplot(hay_pnw, aes(x = yield, fill = state)) +\n  geom_density(alpha = 0.5, na.rm=TRUE)\n\n\n\n\n\n\n\n\n\n\nCombining geoms\nGeoms are best thought of as plotting layers. Additional geoms can be added to a single plot, adding additional layers of information. Each geom is added to the plot in the order it is specified in the ggplot statement.\n\n\n\n\n\n\n\n\n\nAdding an overall of points over boxplots is a good way to summarise the empirical distribution of a large number of data points:\n\nggplot(hay_pnw, aes(x = state, y = yield, fill = state)) +\n  geom_boxplot(na.rm = TRUE) +\n  geom_point(na.rm = TRUE) +\n  ggtitle(\"Yearly hay yields in the Pacific Northwest\") + \n  xlab(\"State\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\nIn this example, it is likely there is over-plotting of data since each state has 104 data point associated with it. The geom geom_jitter() can be used to jiggle overlapping points. Points can be jittered in the vertical and horizontal direction. In this case, jittering in the horizontal direction will result in no change in the interpretation since the y-axis indicates actual value associated with each point.\n\nggplot(hay_pnw, aes(x = state, y = yield, fill = state)) +\n  geom_boxplot(na.rm = TRUE) +\n  geom_jitter(width = 0.2, height = 0, na.rm = TRUE, alpha = 0.7) +\n  ggtitle(\"Yearly hay yields in the Pacific Northwest\") + \n  xlab(\"State\") +\n  ylab(\"yield (1000s of tons)\")\n\n\n\n\n\n\n\n\n\n\n\nOther common plotting options\n\nFaceting\nSometimes, it is useful to create a set of similar plots with the same scaling. Facets are useful for this purpose.\nFor an example, below is a plot of the distributions from above using facet_grid().\n\nggplot(hay_pnw, aes(x = yield)) +\n  geom_density(col = \"blue\", fill = \"dodgerblue\", alpha = 0.6, na.rm = TRUE) +\n  facet_grid(. ~ state) # for a horizontal facet\n\n\n\n\n\n\n\nggplot(hay_pnw, aes(x = yield)) +\n  geom_density(col = \"darkgreen\", fill = \"springgreen3\", alpha = 0.6, na.rm = TRUE) +\n  facet_grid(state ~ .) # for a vertical facet\n\n\n\n\n\n\n\n\nFaceting can also be done be used to create a grid of plots with facet_wrap():\n\nggplot(hay_pnw) +\n  geom_line(aes(x = year, y = yield), col = \"darkcyan\", na.rm=TRUE) +\n  facet_wrap(. ~ state, nrow = 2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nRepresenting error information\nExample: create a band indicates the minimum and maximum range of values\n\nhay_yearly &lt;- nass.hay |&gt; group_by(year) |&gt; \n  summarise(Yield = mean(yield), yield_min = min(yield), yield_max = max(yield))\n\nggplot(hay_yearly, aes(x = year)) + \n  geom_ribbon(aes(ymin = yield_min, ymax = yield_max), fill = \"gray70\", na.rm=TRUE) +\n  geom_line(aes(y = Yield), linewidth = 0.8, na.rm=TRUE)\n\n\n\n\n\n\n\n\nExample: add error bars\nTwo other plot adjustments included: * indicate the range of numbers that the y-axis should span * flip the x and y axes\n\nhay_pnw_summary &lt;- hay_pnw |&gt; group_by(state) |&gt; \n  summarise(Yield = mean(yield, na.rm = T), yield_sd = sd(yield, na.rm = T))\n\nggplot(hay_pnw_summary, aes(y = state)) + \n  geom_errorbar(aes(xmin = Yield - yield_sd, xmax = Yield + yield_sd), width = 0.2) +\n  geom_point(aes(x = Yield), shape = 18, size = 5, col = \"blue\") +\n  # set the limits (lower and upper bounds for the x-axis)\n  xlim(c(0, 3.7)) +\n  ylab(\"\") \n\n\n\n\n\n\n\n\n\n\nAdd regression lines to a plot\n\nP &lt;- ggplot(hay_idaho, aes(x = acres, y = yield)) +\n  geom_point(shape = 16, alpha = 0.6, size = 2.5, na.rm=TRUE)\nP  # Plots can be assigned to an object and then later added to\n\n\n\n\n\n\n\nP +\n  geom_smooth(method = \"lm\", na.rm=TRUE) +\n  geom_smooth(method = \"loess\", col = \"yellowgreen\", na.rm = TRUE)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusting non-data items\n\nAdjustments to the background, text size and other details are done in the theme() argument command.\nthe complete list of option is available in the ggplot2 documentation\nthere are several pre-built themes:\n\n\n\nMore ggplot themes\n\n\nImplementing a ggplot theme\n\nfacet.plot &lt;- ggplot(hay_pnw) +\n  geom_line(aes(x = year, y = yield), col = \"darkcyan\", na.rm=TRUE) +\n  facet_wrap(. ~ state, nrow = 2, ncol = 2)\n\nfacet.plot + theme_minimal() \n\n\n\n\n\n\n\n\nThis is not exactly what I want. Larger labels on everything would be helpful, as well as an outline around each plot. And while we are at it, labeling the x-axis for each decade rather than every 25 years would be easier to interpret.\n\n\nAdjusting text size\n\nfacet.plot + \n  theme_minimal() +   # the theme must be added to plot *before* manual theme adjustments \n  theme(\n   axis.title = element_text(size = 14),\n   axis.text = element_text(size = 13)\n )\n\n\n\n\n\n\n\n\n\n\nAdjusting the axis and gridlines\n\nfacet.plot + \n  scale_x_continuous(breaks = c(seq(1910, 2015, by = 10)))  +\n  theme_minimal() + \n   theme(\n     axis.title = element_text(size = 14),\n     axis.text = element_text(size = 13)\n   ) \n\n\n\n\n\n\n\n\nIt looks like the years are spaced too close together and there are too many grid lines. This can all be fixed.\n\nfacet.plot + \n  scale_x_continuous(breaks = c(seq(1910, 2015, by = 10)))  +\n  theme_minimal() + # this must be added to plot before manual theme adjustments \n   theme(\n     axis.title = element_text(size = 14),  # adsjut title of the axes\n     axis.text = element_text(size = 13),  # adjust axes tick labels\n     axis.text.x = element_text(angle = 45, hjust = 1), # adjust individual axis tick labels \n     panel.grid.minor = element_blank(),  # remove minor grid lines (the major grid lines were retained)\n     panel.border = element_rect(colour = \"black\", fill = \"transparent\"), # create a border around each panel\n     strip.text = element_text(size = 15) # adjust panel labels (e.g. \"Idaho\")\n   ) \n\n\n\n\n\n\n\n\n\n\nAdjusting the legend\n\nggplot(hay_pnw) +\n  geom_line(aes(x = year, y = yield, col = state), na.rm = TRUE) +\n  # set the scale for x-axis (yer)\n  scale_x_continuous(breaks = c(seq(1910, 2015, by = 10)))  +\n  theme_bw() \n\n\n\n\n\n\n\n\nThis looks okay, but it could be better. There is room to put the legend inside the plot and the text should probably be larger. Also, the legend title is not really needed.\n\nggplot(hay_pnw) +\n  geom_line(aes(x = year, y = yield, col = state), na.rm = TRUE) +\n  scale_x_continuous(breaks = c(seq(1910, 2015, by = 10)))  +\n  theme_bw() +\n  theme(\n    legend.position = c(0.15, 0.8), # give exact coordinates (ranging from 0 to 1)\n    legend.background = element_rect(colour = \"black\"),\n    legend.text = element_text(size = 12),\n    legend.title = element_blank()\n  )\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\nThe legend can also be moved to locations outside the main plotting area with arguments such as legend.position = \"top\", legend.position = \"left\" and so on.\n\n\n\n\n\n\nPractice Problem\n\n\n\n\n\n\nCreate a point scatter plot for yield over years and add color & shape effect for the state factor.\n\n\n\n\n\n\nSummary\nThere are many options for adjusting elements of a ggplot. You you will inevitable need to consult help files at some point.\n\n\n\nA bit on colors\nR has a rich set of colors and some excellent palettes that provide excellent contrast and/or work for color-blind individuals. Several are automatically loaded with ggplot2, such as the RColorBrewer:\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\n\n\n\n\n\n\nThe package viridis also has some nice color palettes that are widely used. Also check out the paletteer and the accompanying R palette picker for a wider set of options.\n\n\nOther Important Stuff\n\nHow to save plots\n\nThe function ggsave() is the recommended approach.\nBy default, it will save the the last plot created.\n\n\nggplot(hay_pnw) +\n  geom_line(aes(x = year, y = yield), col = \"violetred\", na.rm=TRUE) +\n  facet_wrap(. ~ state, nrow = 2, ncol = 2) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nggsave(\"PNW_hay_production.png\", dpi = 300)\n\n\nother acceptable formats:\n\n.jpeg\n.tiff\n.bmp\n.svg\n.wmf (on windows machines)\n.pdf\n.eps\n.ps\n.tex\n.pd\n\ncan specify the size of the saved plot (in centimeters, millimeters or inches) and the resolution in DPI (dots per square inch)\n\n\n\nOther great geoms\n\n\n\n\n\n\n\ngeom\npurpose\n\n\n\n\ngeom_violin()\nviolin plot\n\n\ngeom_ribbon()\nhorizontal filled undulating band\n\n\ngeom_bar()\nfor creating bar plots\n\n\ngeom_abline(), geom_hline(), geom_vline()\nfor adding straight lines to a plot\n\n\ngeom_map()\npart of the rich ecosystem of ggplot mapping functions\n\n\ngeom_rug()\nadds rug plots to edges of a plot\n\n\n\nHere is the compplete list of ggplotting options available in ggplot2.\n\n\n\nggplot extensions\nMany packages have been developed to extend ggplot’s functionality. Here are a few notable examples:\n\nggridge\n\n# break hay data into decennial increments (roughly)\nnass.hay$decade &lt;- cut(nass.hay$year, breaks = c(1900, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2020), labels = c(\"pre-1920\", \"1920s\", \"1930s\", \"1940s\", \"1950s\", \"1960s\", \"1970s\", \"1980s\", \"1990s\", \"2000s\"))\n\nlibrary(ggridges); library(viridis)\n\nggplot(nass.hay, aes(x = yield, y = reorder(decade, desc(decade)), fill = after_stat(x))) +\n  geom_density_ridges_gradient(rel_min_height = 0.001) +\n  scale_fill_viridis(direction = -1) + \n  ylab(\"\") # suppress the y-axis label\n\n\n\n\n\n\n\n\n\n\nplotly\n\nlibrary(plotly)\n\npl &lt;- ggplot(nass.hay, aes(x = year, y = yield, color = acres)) +\n  geom_point(na.rm = TRUE) +\n  geom_point(aes(text = state), na.rm = TRUE) + \n  scale_color_gradientn(colors = alpha(rainbow(10), 0.5)) +\n  theme_bw()\n\nggplotly(pl)\n\n\n\n\n\nTo save an interactive plot, use htmlwidgets::saveWidget().\n\n\ngganimate example\n\nPlot from “Learn gganimate”.\n\n\n\nOther resources\n\nPackage documentation\nOfficial ggplot guidebook\nTutorials put together by package authors\n\n\nvignette(\"ggplot2\")\n\n\nThere are innumerable ggplot tutorials like this one on the interwebs, such as this one, this one, and this one, among many others.\nggplot-focused data visualization workshop by Cédric Scherer.\nR Graphics Cookbook Online Book, which is also a purchasable book. This is written by Winston Chang, one of the main authors of the ggplot2 package. It is a very helpful resource for consulting.\n\n\n\nggplot can be fun\nPlot of shots made by NBA Player Steph Curry, made using gganimate:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nggplot is part of the Tidyverse, despite having different conventions, like the use of the “+” operator for adding plot layers. You can take Tidyverse output from piped operations and pipe that directly into a ggplot:\n\nmydata |&gt; filter(var == \"some_conditions\") |&gt; \n  ggplot(...)"
  },
  {
    "objectID": "lessons/final_Lesson.html",
    "href": "lessons/final_Lesson.html",
    "title": "Moving on",
    "section": "",
    "text": "If you made this far, congratulations! Learning any programming language takes a big effort.\nThis is only the beginning. You will probably need more R knowledge, both generalized and specialized, to accomplish your research goals. Here are a few resources to develop stronger data science skills in R.\nI tried to get everyone a bit up this learning curve and out of the zone of pain:\n\n\n\n\n\n\n\n\n\n\nData Science in a Box is a online course by Mine Çetinkaya-Rundel with videos for further development of R skills.\nR 4 Data Science by Hadley Wickham and Garret Grolemund is a comprehensive book providing guidance on leveraging R for data science aims\nWhat They Forgot to Teach you about R (and workshop version) describes some meta processes for ensuring a repeatable workflow.\norginal R manuals (highly technical)\n\nThere are many other resources to help develop skills in genetics, bioinformatics, geospatial analysis, Bayesian statistics, ….you name it. Look for the resources that will help you develop skills in R. One very reliable place to start are CRAN Task Views which provide a list of packages and other relevant R resources specific for a given topic such as environmetrics (ecology), spatial tools and agriculture.\nAnother good source for keeping up with major developments in R, contributed R packages and other R resources is R Weekly which puts out a weekly blog post (also available in a weekly podcast and an RSS feed)."
  },
  {
    "objectID": "lessons/data-types.html",
    "href": "lessons/data-types.html",
    "title": "Lesson 4: Introduction to R data types",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nUnderstand what object class means and how to determine and object’s class\nUnderstand the difference between the 5 main object classes: logical, integer, numeric, character and factors.\nknow how to coerce objects from one class to another\n\n\n\n\nR is a programming language and like all programming languages, it has special conventions for defining how information is classified on your computer and what types of actions can be performed on different data types.\nMuch of this is related to your computer hardware, how computer memory is allocated for R objects and processes and so forth. You don’t need to understand the guts of this to use R (but should you ever want to learn, this is fascinating material).\nThe most common object types and the rules that govern them are described in this lesson.\n\nData types\n\nNumeric\nPreviously, we created an object in R that was a collection or sequence of numbers.\n\nx1 &lt;- 1:10\n\nThese numbers are technically integers (sometimes called “long integers”). We can also create “floating point numbers” (e.g. with precision past the decimal point):\n\nx2 &lt;- c(1.25, 2.718, 10.000)\n\nThese are also called “double precision numbers” or “double” for short.\n\n\nCharacter\nThese can also be created for character variables:\n\nx3 &lt;- \"apple\"\nx4 &lt;- c(\"orange\", \"banana\")\n\nCheck the type for each R object\n\n class(x1)\n\n[1] \"integer\"\n\n class(x2)\n\n[1] \"numeric\"\n\n class(x3)\n\n[1] \"character\"\n\n class(x4)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can force a number to be a integer by adding an L to a number as long as it does not contain a decimal pont (e.g. c(0L, 1L, 2L))\n\n\nThere are two other special classes:\n\n\nLogical\n\nconsisting of TRUE and FALSE values\n\n\nx5 &lt;- c(TRUE, FALSE, FALSE, TRUE)\nclass(x5)\n\n[1] \"logical\"\n\n\n\n\n\nObject type coercion\n\nR will automatically an assign an object type based on the items present within object. It will try to assign the simplest type possible. Here are the types from simplest to most complex:\n\n\\[logical &lt; integer &lt; numeric &lt; character\\]\nWhat classes do you think results from each of these?\n\nx8 &lt;- c(8, 9.2)\nx9 &lt;- c(0, 0, 0, 0)\nx10 &lt;- c(TRUE, FALSE, 1, 0)\nx11 &lt;- c(1, 2, \"pear\", -6:2, TRUE)\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\nclass(x8)\n\n[1] \"numeric\"\n\nclass(x9)\n\n[1] \"numeric\"\n\nclass(x10)\n\n[1] \"numeric\"\n\nclass(x11)\n\n[1] \"character\"\n\n\n\n\n\nWhen you start importing data, you may notice variables did not come in as expected. This is due to the values in the original data file. For example, there may be a column that is only supposed to contain numeric values, yet it imported as character. The column in the file may contain something like this:\n\nc(1.3, 8, 23, \"0 (dropped sample)\", 100, 84)\n\n[1] \"1.3\"                \"8\"                  \"23\"                \n[4] \"0 (dropped sample)\" \"100\"                \"84\"                \n\n\nThis would import as character because of that one single value that is not numeric!\nYou can check if items are classified as specific types:\n\nis.numeric(x10)\n\n[1] TRUE\n\nis.logical(x10)\n\n[1] FALSE\n\nis.logical(x5)\n\n[1] TRUE\n\nis.character(x4)\n\n[1] TRUE\n\n\nObjects can be coerced with these functions:\n\nas.character(x8)\nas.logical(x10)\nas.numeric(x11)\n\n\n\nSpecial object type: The Factor\nThis is a very unusual data type that is specific to R and its history as a language for statistical analysis.\n\n\nFUN Fact\nR’s predecessor, “S”, was invented at Bell Labs for doing data analysis\n\nFactors look like a character variable:\n\nf1 &lt;- factor(c(\"blue\", \"blue\", \"purple\", \"green\", \"green\", \"yellow\", \"green\"))\nf1\n\n[1] blue   blue   purple green  green  yellow green \nLevels: blue green purple yellow\n\n\nIt is a character variable, with pre-defined levels that are alphabetized. The text “Levels: …” are the predefined levels associated with that factor. Let’s compare this to a character variable by manually converting it to character.\n\nas.character(f1)\n\n[1] \"blue\"   \"blue\"   \"purple\" \"green\"  \"green\"  \"yellow\" \"green\" \n\n\nIn the character type, all the observations are in quotes and there is no “Level” information.\nLike other data types, you can manually coerce a fabric as thus:\n\nas.factor(x4)\n\n[1] orange banana\nLevels: banana orange\n\n\nUnder the hood, deep in the R internals, these are integers. The first factor level is designated 1, the second level is designated 2 and so forth. This order is set alphanumerically, but it can be manipulated by hand (run ?factor in the console for more information on how to do this).\n\nas.integer(f1)\n\n[1] 1 1 3 2 2 4 2\n\n\nFactors are used in statistical analysis and can be manipulated in several ways. To a large extent, you can ignore factors. However, you will see them referred to in R functions occasionally. It’s good to know they exist and the very basics of how they work.\n\n\n\n\n\n\nPutting it all together\n\n\n\nLook at the object created in the lesson in the Global Environment pane. For each object, the object class and the first few values will be listed.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Data Types"
    ]
  },
  {
    "objectID": "lessons/data-merging.html",
    "href": "lessons/data-merging.html",
    "title": "Combining Data Sets",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nunderstand the concept of a “key” for merging\nbe able to merge two data sets together\nknow the difference between left join, right join, full join, semi-join and anti-join\nAs usual, let’s start by importing data\nFor merging, it is done in groups of two; that is, two tables at a time are merged together.",
    "crumbs": [
      "Lessons",
      "Combining data sets"
    ]
  },
  {
    "objectID": "lessons/data-merging.html#bind-rows",
    "href": "lessons/data-merging.html#bind-rows",
    "title": "Combining Data Sets",
    "section": "Bind rows",
    "text": "Bind rows\nIf you have two data sets of different observations (the keys do not match) but similar or identical column headers, these rows can be stacked togther using a row bind.\nExample syntax of a row_bind:\n\nnew1 &lt;- bind_rows(x, y)\n\nIn this function, the column names are matched and ordered according to the first data frame listed (“x” in this example). The default behavior is to return all unique columns from both data sets and fill in with missing data as needed.\n\n\n\n\n\n\n\n\n\nWe can manufacture a version of this with our data sets by filtering to a single trial and selecting a few columns. This is a silly toy example, but most of the time you will not be handed these data sets that are already merged. You will be given two or more data sets that need to be combined. Perhaps these are field experiments from different years or lab results from two different runs.\n\ntrial_1 &lt;- variety_trial %&gt;% filter(trial == \"SWIdahoCereals_HRS_PAR_2016\") %&gt;% select(trial, rep, variety, yield)\ntrial_2 &lt;- variety_trial %&gt;% filter(trial == \"SWIdahoCereals_SWS_PAR_2018\") %&gt;% select(trial, variety, rep, grain_protein)\n\nCompare data sets:\n\nhead(trial_1)\n\n                        trial rep    variety     yield\n1 SWIdahoCereals_HRS_PAR_2016   1   LCS Iron  78.27131\n2 SWIdahoCereals_HRS_PAR_2016   2   LCS Iron 124.19389\n3 SWIdahoCereals_HRS_PAR_2016   3   LCS Iron  85.20458\n4 SWIdahoCereals_HRS_PAR_2016   4   LCS Iron 140.56490\n5 SWIdahoCereals_HRS_PAR_2016   1 10SB0087-B  94.18977\n6 SWIdahoCereals_HRS_PAR_2016   2 10SB0087-B 121.59047\n\nhead(trial_2)\n\n                        trial     variety rep grain_protein\n1 SWIdahoCereals_SWS_PAR_2018       Melba   1        8.4525\n2 SWIdahoCereals_SWS_PAR_2018       Melba   2        7.7625\n3 SWIdahoCereals_SWS_PAR_2018       Melba   3        8.5675\n4 SWIdahoCereals_SWS_PAR_2018       Melba   4       10.4075\n5 SWIdahoCereals_SWS_PAR_2018 14-FAC-2043   1        8.3375\n6 SWIdahoCereals_SWS_PAR_2018 14-FAC-2043   2        8.2225\n\n\nBind the rows together:\n\ntogether &lt;- bind_rows(trial_2, trial_1)\nhead(together)\n\n                        trial     variety rep grain_protein yield\n1 SWIdahoCereals_SWS_PAR_2018       Melba   1        8.4525    NA\n2 SWIdahoCereals_SWS_PAR_2018       Melba   2        7.7625    NA\n3 SWIdahoCereals_SWS_PAR_2018       Melba   3        8.5675    NA\n4 SWIdahoCereals_SWS_PAR_2018       Melba   4       10.4075    NA\n5 SWIdahoCereals_SWS_PAR_2018 14-FAC-2043   1        8.3375    NA\n6 SWIdahoCereals_SWS_PAR_2018 14-FAC-2043   2        8.2225    NA\n\n\nIf you have ever used rbind(), this is an improvement. It will match column names across data sets and order them appropriately.",
    "crumbs": [
      "Lessons",
      "Combining data sets"
    ]
  },
  {
    "objectID": "lessons/data-merging.html#joins",
    "href": "lessons/data-merging.html#joins",
    "title": "Combining Data Sets",
    "section": "Joins",
    "text": "Joins\nMerging two data sets when it goes beyond a row bind can take an effort.\nAll joins follow this syntax:\n\nxxx_join(left_dataset, right_dataset)\n\nWhere “left_dataset” and “right_dataset” correspond to the left and right data sets in this diagram:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe importance of ‘keys’\n\n\n\nAll joins rely on “keys” to match observations. A key is a unique identifier; it is usually a unique for each row. This can be a single column or the result of multiple columns. This information is used to match information in one table (or data frame) with another. The extent to which these keys match or do not match is the essence of a merge.\n\n\nLet’s look at matches between “genotype”, “variety_trial”, and “metadata”.\nThe key between “metadata” and “variety_trial” is “trial”. There is exactly one row in the “metadata” file for each level of trial. The metadata file was designed to be like this. We did not need all those extra columns when it could be compressed into a smaller data set.\nThe file “genotype” is from a wholly different study. The extent of matches is considerably less complete than the matching between “variety_trial” and “metadata”.\n\nFull join\nAll observations are returned, regardless if matched.\nLet’s match “variety_trial” and “metadata”:\n\nex_fulljoin &lt;- full_join(metadata, variety_trial, by = \"trial\")\n\ndim(ex_fulljoin)\n\n\n\ninner join\nReturns only the rows with matching information. Non-matches are filtered out of the data set.\nLet’s match “genotypes” and “variety_trial” (this will be big!).\nHow to check homany of these match (where the key is “variety” that matches “individual” in the object “genotypes”)?\n\nbase::intersect(variety_trial$variety, genotypes$individual)\n\n[1] \"Jefferson\"   \"UI Platinum\" \"LCS Star\"    \"UI Stone\"   \n\n\n\nex_innerjoin &lt;- inner_join(variety_trial, genotypes, by = join_by(\"variety\" == \"individual\"))\n\nCheck results\n\ndim(ex_innerjoin)\n\n[1]    76 10107\n\nsort(unique(ex_innerjoin$variety))\n\n[1] \"Jefferson\"   \"LCS Star\"    \"UI Platinum\" \"UI Stone\"   \n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\nComplete this expression:\n\ntest &lt;- inner_join(genotypes, trial_1, by = join_by(         ))\n\n\n\n\n\n\nLeft join and right join\nThese preserves all the rows in one data set and matches to that dataset in the other. In the left join, it is the first data set (the one on the left) where all the rows are kep. In the right join, it’s the data set to the right that is full preserved.\nLet’s compare the different when merging ‘trial_2’ with ‘metadata’.\n\nLeft join\n\nex_leftjoin_1 &lt;- left_join(trial_2, metadata, by = \"trial\")\nex_leftjoin_2 &lt;- left_join(metadata, trial_2, by = \"trial\")\n\n\n\nRight join\n\n#ex_rightjoin_1 &lt;- right_join(metadata, trial_2, by = \"trial\")\nex_rightjoin_2 &lt;- right_join(trial_2, metadata, by = \"trial\")\n\nHow are these 4 joins similar?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nex_leftjoin_1 is the exact equivalent of ex_rightjoin_1, but the columns are in a different order.\n\nex_leftjoin_2 is the exact equivalent of ex_rightjoin_2, but the columsn are in a different order.\n\n\n\n\n\n\n\nSemi-join\nOne of my favorite joins! It does an inner join, but only return the columns for the first data set listed. It’s handy when you don’t want to generate gigantic objects.\nLet’s revisit matching “genotypes” and “variety_trial” like in the inner_join() example above.\n\nex_semijoin &lt;- semi_join(variety_trial, genotypes, by = join_by(\"variety\" == \"individual\"))\n\nHow do the dimensions of this object compare to the dimensions of ‘ex_innerjoin’?\n\n\nAnti-join\nThis is similar to semi_join(). It will return all the rows that do not match, and only the columns from the first data set mentioned.\n\nex_antijoin &lt;- anti_join(variety_trial, genotypes, by = join_by(\"variety\" == \"individual\"))\n\nDo any of the variety names match?\n\ntable(ex_antijoin$variety %in% genotypes$individual)\n\n\nFALSE \n 1806 \n\n\n\n\n\n\n\n\nNote\n\n\n\ndplyr can do complex joins.!\nIt can do some very flexible matching by numeric values, dates and other factors. More on this can be found in the documentation for join_by. This topic is complext and beyond the scope of this introductory workshop.",
    "crumbs": [
      "Lessons",
      "Combining data sets"
    ]
  },
  {
    "objectID": "lessons/data-merging.html#final-notes",
    "href": "lessons/data-merging.html#final-notes",
    "title": "Combining Data Sets",
    "section": "Final Notes",
    "text": "Final Notes\nThis is near the end of lessons on data wrangling. There is additional functionality that we have not touched on that you may find useful to know.\nHere is the complete list of dplyr functions and tidyr functions.\nR 4 Data Science by Hadley Wickam and Garret Grolemund provides comprehensive guide to data wrangling.\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nImport “genotypic_data_rotated.csv” (see script below), along with “trial_data.csv”, and “trial_metadata.csv”.\nDo an inner join between “genotypic_data_rotated.csv” and “trial_data.csv” using variety names.\nDo a semi-join of “genotypic_data_rotated.csv” with “trial_data.csv” and do the reverse. How does this compare with the inner join from the previous problem?\nDo an anti-join between “genotypic_data_rotated.csv” and “trial_data.csv”.\nJoin together all common observations between the 3 files (your choice on join).\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nAlthough this lesson did not demonstrate the use of the pipe, %&gt;%, it can be used with joins:\n\nobj &lt;- left_join(x, y) %&gt;% right_join(z)\n\nThe first join is a left join like any other. The second join presumes that the first argument is what was passed to it through the pipe. An equivalent:\n\ntemp &lt;- left_join(x, y)\nobj &lt;-  right_join(temp, z)",
    "crumbs": [
      "Lessons",
      "Combining data sets"
    ]
  },
  {
    "objectID": "lessons/data-export.html",
    "href": "lessons/data-export.html",
    "title": "Exporting Data",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nBe able to export tabular data from R into a text file, .csv or .xlsx file\nBe able to save an R object and reload it into an R session.\nThis lesson is focused on exporting tabular data. It is a very short lesson because exporting data is quite similar to importing data. Like in data import, exporting data involves opening a connection between R and file system, writing the data to file and closing the connection.\nFirst, we need to load some data to write to file. R packages often come with data sets that can loaded with the data() command.\ndata(\"mtcars\")",
    "crumbs": [
      "Lessons",
      "Exporting R objects to file"
    ]
  },
  {
    "objectID": "lessons/data-export.html#exporting-to-csv-files",
    "href": "lessons/data-export.html#exporting-to-csv-files",
    "title": "Exporting Data",
    "section": "Exporting to CSV files",
    "text": "Exporting to CSV files\n\nwrite.csv()\nFirst, check the documentation: ?write.csv\n\nwrite.csv(mtcars, here::here(\"outputs\", \"mtcars_1.csv\"), row.names = FALSE)\n\nSetting the row.names argument to FALSE ensures that a column of numbers without a header is not included in the file (which is likely to cause import errors in the future).\n\n\nwrite.table()\nThis function looks very similar to write.csv() because it is technically the same function. write.csv() is wrapper for write.table() using a specific set of default arguments for CSV files (e.g. sep = \",\"). In this case, we cannot rely on those default and must specify\n\nwrite.table(mtcars, here::here(\"outputs\", \"mtcars_2.csv\"), \n          row.names = FALSE, sep = \",\", quote = FALSE)\n\n\n\nwrite_csv()\nThis function is very similar to read.csv(), but it does not have a row names argument because it does not output rownames.\n\nlibrary(readr)\n\nwrite_csv(mtcars, here::here(\"outputs\", \"mtcars_3.csv\"))\n\nwrite_csv() is wrapper for write_delim().",
    "crumbs": [
      "Lessons",
      "Exporting R objects to file"
    ]
  },
  {
    "objectID": "lessons/data-export.html#exporting-to-text-file",
    "href": "lessons/data-export.html#exporting-to-text-file",
    "title": "Exporting Data",
    "section": "Exporting to text file",
    "text": "Exporting to text file\nThis also uses write.table() or write.table():\n\nwrite.table(mtcars, here::here(\"outputs\", \"mtcars.txt\"), sep = \"\\t\",\n            quote = \"none\")\n\nwrite_delim(mtcars, here::here(\"outputs\", \"mtcars.txt\"), delim = \"\\t\",\n            quote = \"none\")",
    "crumbs": [
      "Lessons",
      "Exporting R objects to file"
    ]
  },
  {
    "objectID": "lessons/data-export.html#exporting-to-excel-file",
    "href": "lessons/data-export.html#exporting-to-excel-file",
    "title": "Exporting Data",
    "section": "Exporting to Excel file",
    "text": "Exporting to Excel file\nUse the writexl package:\n\nlibrary(writexl)\n\nwrite_xlsx(mtcars, here::here(\"outputs\", \"mtcars.xlsx\"))\n\nThe help file is informative: ?write_xlsx",
    "crumbs": [
      "Lessons",
      "Exporting R objects to file"
    ]
  },
  {
    "objectID": "lessons/data-export.html#other-options",
    "href": "lessons/data-export.html#other-options",
    "title": "Exporting Data",
    "section": "Other options",
    "text": "Other options\n\nsave()\nThis is special option to save objects in your environment to file. These can only be used by R, but are convenient if you plan to return to these object:\nSave one object:\n\nsave(mtcars, file = here::here(\"outputs\", \"mydata.RData\"))\n\nSave multiple objects:\n\ndata(\"sleep\")\nsave(mtcars, sleep, file = here::here(\"outputs\", \"more.RData\"))\n\nThese can be loaded back into an R session as thus:\n\nload(here::here(\"outputs\", \"mydata.RData\"))\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are working with a specialized file type that has dedicated libraries for importing them into R and manipulating those objects, those dedicated libraries likely have export functions for that file type. For spatial object, the package sf can import, alter, and export shapefiles.\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nImport one of your data sets using two of the functions taught:\n\n(save your data in different format to enable this)\n\nread.csv()\nread_csv()\nread_excel()\nread.delim()\n\n\nExamine the data imported using View(imported_data). Did everything import as expected? Are your variables coded as they should be? Are numeric variables numeric? Are missing data detected as thus? Where any row names accidentally introduced? Were missing cells converted to “NA”? Did any data become unexpectedly quoted?\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nExporting data is a good thing to do during the data wrangling process. Once you have arranged in your data set into an ideal state, save it so you an easily reload it later.\nIt is very important that you check your output file (especially as a newer R programmer!) to make sure everything is as you expect. We have all accidentally output “myfile” instead of “myfile.csv”, and this can be highly inconvenient! You can do by manually opening the file or by importing back into R; either should tell you if the file export went as expected or not.",
    "crumbs": [
      "Lessons",
      "Exporting R objects to file"
    ]
  },
  {
    "objectID": "lessons/control-flow.html",
    "href": "lessons/control-flow.html",
    "title": "Control Flow Variables in R",
    "section": "",
    "text": "Here is a very brief introduction to control flow variables in R!\n\nwhile and if\n\nwhile indicates that a process will repeat until a condition is met. A function will loop through until the the test for while() evaluates to FALSE. Be careful not to get this stuck in an infinite loop!\n\n\nwhile(sometest) {\n  do something\n}\n\n\nif will only allow an action to occur if a test is passed. The action will only occur once (there is no looping).\n\n\nif(sometest) {\n  do action\n}\n\n\nif can be paired with else. Anything that evaluated to FALSE in the if test will go through the processes described in else. There is no TRUE/FALSE test for else, it just takes everything that evaluated to FALSE in the if test.\n\n\nif(sometest) {\n  do action\n} else {\n  do another action\n}\n\n\nnext is used within a while statement or for loop along with if. It indicates that the remaining commands in the loop should be skipped and the process moves onto the next iteration:\n\n\nwhile(sometest) {\n  do something\n  if(anothertest) \n    next # when \"anothertest\" is TRUE, \"other things to do\" is skipped\n          # and the next iteration is performed\n  other things to do \n}\n\n\nbreak is similar to next, except that it causes all of the repeating/looping to terminate. Like next, it is used within a while statement or for loop along with if.\n\n\nwhile(sometest) {\n  do something\n  if(anothertest) \n    break # when \"anothertest\" is TRUE,\n          # the entire process terminates immediately\n  other things to do \n}\n\n\n\nRow median polish example\n\n# initial the variables \nm &lt;- matrix(1:90, nrow = 9, ncol = 10, byrow = TRUE)\ndiff = 1\n# a while + if example function\nwhile (diff &gt; 0.001){\n  if(exists(\"new_m\")) {mat = new_m}\n    else {mat = m}\n  row_med1 = apply(mat, 1, median)\n  \n  if(exists(\"row_med2\")) {\n    diff = max(abs(row_med1 - row_med2))}\n  print(diff)\n  # this is a good place for 'break' statement, \n    # because without it, this code below must run \n    # and the loop restarted at the top in order for the \n    # 'while' statement to be evaluated again\n  over_eff = median(row_med1)\n  row_med2 &lt;- row_med1 - over_eff\n  med_matrix = matrix(rep(row_med1, each = ncol(mat)), \n                       nrow = nrow(mat), ncol = ncol(mat), byrow=TRUE)\n  new_m = mat - med_matrix\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introductory R for Scientists",
    "section": "",
    "text": "This workshop will take you from zero to hero over the course of 30 hours of instruction and practice. It will introduce the R programming language, the graphical user interface RStudio and how R can be used to manage and analyse your data. At the end of this workshop, you will be able to:\n\nimport & export data\nunderstand data types and object types\nfilter, reshape, merge and manipulate your data\nmathematically transform data\ndo repeat actions in R\nplot data\nnavigate R help files\n\n\nWho is This workshop for?\nThis workshop is intended for beginner R users. No previous experience in R or any other programming or statistical language is expected (although previous R users whose skills have lapsed are welcome)\n\n\nWhat this workshop will not cover\n\nstatistical analysis\ngit, GitHub, or any version control\nusage of the terminal (e.g. bash)\n\n\n\nRequirements\n\nA laptop. You can opt to install R and RStudio on it (recommended if you plan to continue using R beyond the workshop), or you can use the online R programming environment provided by Posit Cloud.\n\n\n\nWhen\nMay 20-24, 2024\nMonday - Friday\n9am - 12pm | 1pm - 4pm Pacific Time\nAll sessions will take place on the University of Idaho campus in Moscow, Idaho.\n\n\nInstructors\nJulia Piaskowski\nHarpreet Kaur",
    "crumbs": [
      "Course Info",
      "Overview"
    ]
  },
  {
    "objectID": "CoC.html",
    "href": "CoC.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "University of Idaho Carpentries is dedicated to providing a harassment-free experience for participants of the conference regardless of age, gender, sexual orientation, disability, physical appearance, race, or religion (or lack thereof).\nWe encourage the open exchange of ideas and expression and thus require an environment that recognizes the inherent worth of every person and group. An inclusive space free of harassment encourages interaction among diverse groups. We want to make certain our workshops and courses are welcoming, and encourages participants to be involved moving forward.\nAll participants (including organizers, attendees, instructors and volunteers) at UI Carpentries Workshops are required to agree to the following code of conduct. Reports of violation to this Code of Conduct should be addressed to the course/workshop lead instructor.\nThis Code of Conduct (CoC) applies to any participant in a University of Idaho Carpentries Workshop. Note that this code augments rather than replaces legal rights and obligations pertaining to any particular situation.\n\nExpected Behavior\nAll workshop/course participants are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior, and all applicable laws.\nWe’re committed to providing welcome environments where people behave according to professional standards. We expect everyone at any UI Carpentries-affiliated event to contribute to a welcoming, civil, safe, and tolerant environment.\nExamples of encouraged behavior that contributes to a positive environment include:\n\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for everyone at the event\nShowing empathy towards other participants\n\n\n\nUnacceptable Behavior\nHarassment will not be tolerated in any form, including but not limited to:\n\nIntimidation or harassment of any kind.\nOffensive comments related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held.\nUnwelcome comments regarding a person’s lifestyle choices and practices, including those related to food, health, parenting, drugs, and employment.\nDeliberate misgendering, “outing,” or use of “dead” or rejected names.\nGratuitous or off-topic blatant sexual images or behavior in spaces where they are not appropriate.\nNot respecting the privacy of other participants\n\n\n\nHarassment in online channels\nSome of our workshops are online events. Please use these guidelines when engaging with participants. The above Code of Conduct applies to an online event, with the addition of:\n\nAvoid using overtly sexual or offensive usernames or profile photos which might detract from a friendly, safe and welcoming environment for all.\nDo not publish text/screenshots of anything shared in private communication channels without explicit consent from the author. This includes screenshots of private messages to public channels, as well as conversations on public channels to anywhere outside of UI Carpentries Workshop.\nDo not direct message someone without their permission.\nDo not record sessions without the presenter’s permission.\nThe meeting host/organizer should be aware of privacy concerns for different tools. For tips on security, a good place to start is: Securing Your Zoom Meetings.\n\nThis CoC applies to all University of Idaho Carpentries online spaces.\n\n\nResponses to Code of Conduct Violations\nWe will follow all University of Idaho and Idaho State requirements regarding how to handle incidents of harassment.\n\n\nWhat To Do If You Witness or Are Subject To Unacceptable Behavior\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact the lead instructor immediately.\n\n\nAcknowledgements\nThis CoC is adapted from RConsortium CoC and the Carpentries CoC This policy is licensed under a Creative Commons Attribution 4.0 International license.",
    "crumbs": [
      "Course Info",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "learning-quarto.html",
    "href": "learning-quarto.html",
    "title": "Working with Quarto Documents",
    "section": "",
    "text": "Quarto is a file format for weaving together code (R, python, and others), output, and text into a single notebook. It is a nice tool for putting together reports or doing analysis for yourself. Quarto also has applications for building websites (this website is build with Quarto!), formatting books, and making slideshow presentations. These are advanced applications that over time, you may want to try out yourself.\nWhile Quarto offers many advanced features, using only the basic features will enable users of many abilities to communicate their results with others. You can choose to learn more, but Quarto is nevertheless useful using only its foundational tools: mixing text, code, and code outputs.\nIt follows some of the standard syntax of markdown, which is a highly simplified version of HTML (“hypertext markup language”).\nA .qmd document can simply exist as is (and is highly useful), or you can choose to output it to many enabled formats such as .html (the easiest to do), .pdf, .docx and more. Click on “Render” at the top of a .qmd file in RStudio to see a rendered version of your Quarto document.",
    "crumbs": [
      "Course Info",
      "Quarto basics"
    ]
  },
  {
    "objectID": "learning-quarto.html#what-is-quarto-and-why-should-you-use-it",
    "href": "learning-quarto.html#what-is-quarto-and-why-should-you-use-it",
    "title": "Working with Quarto Documents",
    "section": "",
    "text": "Quarto is a file format for weaving together code (R, python, and others), output, and text into a single notebook. It is a nice tool for putting together reports or doing analysis for yourself. Quarto also has applications for building websites (this website is build with Quarto!), formatting books, and making slideshow presentations. These are advanced applications that over time, you may want to try out yourself.\nWhile Quarto offers many advanced features, using only the basic features will enable users of many abilities to communicate their results with others. You can choose to learn more, but Quarto is nevertheless useful using only its foundational tools: mixing text, code, and code outputs.\nIt follows some of the standard syntax of markdown, which is a highly simplified version of HTML (“hypertext markup language”).\nA .qmd document can simply exist as is (and is highly useful), or you can choose to output it to many enabled formats such as .html (the easiest to do), .pdf, .docx and more. Click on “Render” at the top of a .qmd file in RStudio to see a rendered version of your Quarto document.",
    "crumbs": [
      "Course Info",
      "Quarto basics"
    ]
  },
  {
    "objectID": "learning-quarto.html#basics-of-quarto",
    "href": "learning-quarto.html#basics-of-quarto",
    "title": "Working with Quarto Documents",
    "section": "Basics of quarto",
    "text": "Basics of quarto\n\nText Formatting\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n*italics* and **bold**\nitalics and bold\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n\n\n\nHeadings\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n# Header 1\nHeader 1\n\n\n## Header 2\nHeader 2\n\n\n### Header 3\nHeader 3\n\n\n#### Header 4\nHeader 4\n\n\n##### Header 5\nHeader 5\n\n\n###### Header 6\nHeader 6\n\n\n\n\n\nLists\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n*   item 2\n\n    Continued (indent 4 spaces)\n\nitem 2\nContinued (indent 4 spaces)\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\nitem 2\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n(@)  A list whose numbering\n\ncontinues after\n\n(@)  an interruption\n\nA list whose numbering\n\ncontinues after\n\nan interruption\n\n\n\nterm\n: definition\n\nterm\n\ndefinition\n\n\n\n\n\n\n\nSource Code\nUse ``` to delimit blocks of source code:\n```\ncode\n``` \nAdd a language to syntax highlight code blocks:\n```r\n1 + 1\n``` \nIf you are creating HTML output there is a wide variety of options available for code block output. See the article on code blocks for additional details.\n\n\nTables\n\nMarkdown Syntax\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\nOutput\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nTo Learn More\n\n\n\nThere are many more options for formatting Quarto documents and embedding information in a Quarto document. Visit Quarto’s markdown page to learn more.",
    "crumbs": [
      "Course Info",
      "Quarto basics"
    ]
  },
  {
    "objectID": "learning-quarto.html#what-else-can-quarto-be-used-for",
    "href": "learning-quarto.html#what-else-can-quarto-be-used-for",
    "title": "Working with Quarto Documents",
    "section": "What else can quarto be used for?",
    "text": "What else can quarto be used for?\nThere is a rich array of possibilities for Quarto documents, the majority of which we will not address in this class. Take a look at this gallery to get a better sense of what you can do with Quarto and decide for yourself if it’s worth the effort to learn better.\nI started learning how to use markdown for html documents, then made a few presentations with Quarto’s predecessor, Rmarkdown (I’m not sure this is worth the effort). I next started building website with Rmarkdown and Quarto, and have found this to be a great tool for sharing information via websites. If you never do this, that is completely okay! Not everyone neesd these tools, but it you do, Quarto can make implementation easier.",
    "crumbs": [
      "Course Info",
      "Quarto basics"
    ]
  },
  {
    "objectID": "lessons/data-aggregation.html",
    "href": "lessons/data-aggregation.html",
    "title": "Aggregating & Summarising Data",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to aggregate data and perform actions on those aggregated data using group_by() and summarise()\nunderstand when to use rowwise() for operations\n\n\n\n\nYou may find yourself wanting to calculate summary statistics across a grouping variable. To do this, a data set needs to be split up by that variable, a summary statistic calculated, and the resulting data recombined, or ‘split-apply-combine’. There’s some nice tools to do this in the dplyr package.\n\nPrep Work\nFirst, load libraries & import data:\n\nlibrary(dplyr)\n\nvariety_trials &lt;- read.csv(here::here(\"data\", \"trial_data.csv\")) %&gt;% \n  mutate(trial = gsub(\"_H_\", \"_H-\", trial)) %&gt;% \n  tidyr::separate(trial, c(\"program\", \"crop\", \"location\", \"year\"),\n                  sep = \"_\", remove = FALSE)\n\n\n\nBasic grouping & aggregation\nThe group_by will group data and then any statistic can be calculated or summary action can be done on that grouped data using summarise().\nThe basic formula:\n\nmydata %&gt;% group_by(variable) %&gt;% summarise(new_var = ...)\n\nThis data set has several categorical variables that can be used for grouping:\n\nstr(variety_trials)\n\n'data.frame':   1882 obs. of  10 variables:\n $ trial        : chr  \"SWIdahoCereals_H-S_PAR_2018\" \"SWIdahoCereals_H-S_PAR_2018\" \"SWIdahoCereals_H-S_PAR_2018\" \"SWIdahoCereals_H-S_PAR_2018\" ...\n $ program      : chr  \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ crop         : chr  \"H-S\" \"H-S\" \"H-S\" \"H-S\" ...\n $ location     : chr  \"PAR\" \"PAR\" \"PAR\" \"PAR\" ...\n $ year         : chr  \"2018\" \"2018\" \"2018\" \"2018\" ...\n $ rep          : int  1 2 3 4 1 2 3 4 1 2 ...\n $ variety      : chr  \"12SB0197\" \"12SB0197\" \"12SB0197\" \"12SB0197\" ...\n $ yield        : num  71.7 108.6 81.7 103.8 65.3 ...\n $ grain_protein: num  9.83 9.6 11.27 10.35 10.23 ...\n $ test_weight  : num  62.1 64.2 65.6 64.3 62.8 65.2 65.1 65.6 65 65.3 ...\n\n\nThe function tally() counts observations:\n\nvariety_trials %&gt;% group_by(trial) %&gt;% tally()\n\n# A tibble: 28 × 2\n   trial                           n\n   &lt;chr&gt;                       &lt;int&gt;\n 1 SWIdahoCereals_H-S_PAR_2018    88\n 2 SWIdahoCereals_H-S_WEI_2018    96\n 3 SWIdahoCereals_H-W_PAR_2017   120\n 4 SWIdahoCereals_H-W_PAR_2018    80\n 5 SWIdahoCereals_H-W_WEI_2018    48\n 6 SWIdahoCereals_HRS_PAR_2016    60\n 7 SWIdahoCereals_HRS_PAR_2017    32\n 8 SWIdahoCereals_HRS_PAR_2019    60\n 9 SWIdahoCereals_HRS_PAR_2020    48\n10 SWIdahoCereals_HRW_PAR_2019    44\n# ℹ 18 more rows\n\n\nLet’s group by crop and pull out the mean yield and standard deviation.\n\nyield_crop &lt;- variety_trials %&gt;% group_by(crop) %&gt;% \n  summarise(yield_mean = mean(yield, na.rm = TRUE),\n            yield_sd = sd(yield, na.rm = TRUE),\n            yield_min = min(yield, na.rm = TRUE),\n            yield_max = max(yield, na.rm = TRUE),\n            total = n())\n\nyield_crop\n\n# A tibble: 8 × 6\n  crop  yield_mean yield_sd yield_min yield_max total\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 H-S         57.6     34.3    16.6        119.   184\n2 H-W         84.4     42.2     4.17       199.   248\n3 HRS        111.      38.5    56.0        498.   200\n4 HRW        136.      45.0    66.2        197.   100\n5 HWS        116.      32.0    56.6        253.   132\n6 HWW        115.      38.5    68.7        192.    76\n7 SWS        104.      42.4    12.1        219.   316\n8 SWW         94.0     43.9     0.705      201.   626\n\n\n\n\n\n\n\n\nNote\n\n\n\nsummarise() only returns a single value back for each group. If you want more than that (e.g. to run a linear model on each group), there are other tools for that. This is intended to be addressed in Lesson ‘repeating actions’.\n\n\n\n\nGrouping across multiple variables\nLet’s examine how many crops and years there are using the table() command:\n\ntable(variety_trials$crop, variety_trials$year)\n\n     \n      2016 2017 2018 2019 2020\n  H-S    0    0  184    0    0\n  H-W    0  120  128    0    0\n  HRS   60   32    0   60   48\n  HRW    0    0    0   44   56\n  HWS   44   32    0   24   32\n  HWW    0    0    0   44   32\n  SWS   40   40  132   56   48\n  SWW    0  160  206  108  152\n\n\nThis tells us how many rows of data occur for each variable combination. This information can help inform us how to group information.\nYou can group by as many conditions as you want:\n\nvariety_trials %&gt;% group_by(crop, year) %&gt;% \n  summarise(protein_na = sum(is.na(grain_protein))) %&gt;% arrange(desc(protein_na))\n\n`summarise()` has grouped output by 'crop'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 24 × 3\n# Groups:   crop [8]\n   crop  year  protein_na\n   &lt;chr&gt; &lt;chr&gt;      &lt;int&gt;\n 1 SWW   2017         160\n 2 H-W   2018         128\n 3 H-W   2017         120\n 4 H-S   2018          96\n 5 SWW   2018          90\n 6 SWS   2018          64\n 7 SWS   2017          40\n 8 HRS   2017          32\n 9 HWS   2017          32\n10 HRW   2019           4\n# ℹ 14 more rows\n\n\n\n\n\n\n\n\nFYI\n\n\n\nYou can group by a numeric variable. If you do that, dplyr will look for common values to group observations. This can be successful when there are repeat ‘integers’ (e.g. year, replicate), but if all values are unique (which is often the case with floating point numbers), then the number of groups is the number of observations.\n\n\n\n\nSummarising across multiple variables\nUse across() to conduct the same summary action(s) across multiple columns.\n\nvariety_trials %&gt;% group_by(trial) %&gt;% \n  summarise(across(c(yield, grain_protein), ~ mean(.x, na.rm = TRUE)))\n\n# A tibble: 28 × 3\n   trial                       yield grain_protein\n   &lt;chr&gt;                       &lt;dbl&gt;         &lt;dbl&gt;\n 1 SWIdahoCereals_H-S_PAR_2018  91.0         10.9 \n 2 SWIdahoCereals_H-S_WEI_2018  27.0        NaN   \n 3 SWIdahoCereals_H-W_PAR_2017 121.         NaN   \n 4 SWIdahoCereals_H-W_PAR_2018  63.1        NaN   \n 5 SWIdahoCereals_H-W_WEI_2018  28.4        NaN   \n 6 SWIdahoCereals_HRS_PAR_2016 111.          14.3 \n 7 SWIdahoCereals_HRS_PAR_2017 150.         NaN   \n 8 SWIdahoCereals_HRS_PAR_2019 106.          11.7 \n 9 SWIdahoCereals_HRS_PAR_2020  90.6         12.7 \n10 SWIdahoCereals_HRW_PAR_2019  88.2          8.20\n# ℹ 18 more rows\n\nvariety_trials %&gt;% group_by(trial) %&gt;% \n  summarise(across(c(yield, grain_protein), ~ sd(.x, na.rm = TRUE)))\n\n# A tibble: 28 × 3\n   trial                       yield grain_protein\n   &lt;chr&gt;                       &lt;dbl&gt;         &lt;dbl&gt;\n 1 SWIdahoCereals_H-S_PAR_2018 16.9          1.00 \n 2 SWIdahoCereals_H-S_WEI_2018  5.52        NA    \n 3 SWIdahoCereals_H-W_PAR_2017 26.3         NA    \n 4 SWIdahoCereals_H-W_PAR_2018  7.64        NA    \n 5 SWIdahoCereals_H-W_WEI_2018 11.2         NA    \n 6 SWIdahoCereals_HRS_PAR_2016 24.3          0.908\n 7 SWIdahoCereals_HRS_PAR_2017 75.3         NA    \n 8 SWIdahoCereals_HRS_PAR_2019 10.2          0.780\n 9 SWIdahoCereals_HRS_PAR_2020 13.2          1.14 \n10 SWIdahoCereals_HRW_PAR_2019 10.2          0.612\n# ℹ 18 more rows\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nAs usual, consider how these data aggregation functions can support your own work.\nFor some of these exercises, you may need to use other dplyr functions.\n\n\nCount the number of observations for each ‘variety’ in the ‘variety_trials’ data set.\nUse ‘variety-trials’ data, group data by ‘variety’ and calculate the summary statistics (mean, sd, min, and max) for ‘grain_protein’.\nUse ‘variety-trials’ data, group data by ‘crop’ and ‘year’ variables and calculate the mean and standard deviation across ‘test_weight’ and ‘grain_protein’.\n\n\n\n\n\n\nRow-wise summaries\nMany operations in R are already vectorized across rows, but when they are not, you can use rowwise() to implement that.\nField disease scoring may benefit from this system. Often, several measurements are made on a single experimental unit (usually a plot), and those measurements are averaged together to create a final disease incidence score. Here is how to do that with rowwise().\nFirst, simulate a set of disease scores between 0 and 100 (indicating percent infection).\n\n# step 1: generate a set of possible scores: 0, 10, 20,...100\nscore_range &lt;- c(0:10 * 10L)\n# sample those possible scores to generate 50 data points\nscores &lt;- sample(score_range, 50, replace = TRUE)\n# arrange those 50 data points into a datafrmae of 5 columns, each column reflecting 10 observations\ndisease_df &lt;- data.frame(plot = letters[1:10],\n                         score1 = scores[1:10],\n                         score5 = scores[11:20],\n                         score3 = scores[21:30],\n                         score4 = scores[31:40],\n                         score2 = scores[41:50])\ndisease_df\n\n   plot score1 score5 score3 score4 score2\n1     a     20     90      0     40     80\n2     b     60     60     40      0     90\n3     c     60     40    100    100     50\n4     d      0     80     50     50     70\n5     e      0     50     50     10     10\n6     f     20     60     60     80     80\n7     g     10     50     90      0     80\n8     h     20     40     50     80      0\n9     i     20     10     80     30     20\n10    j    100     40     40     20     10\n\n\nData sets exist like this. A person might have a set of 10 experimental plots to evaluate for some trait. The trait assay protocol may require that multiple observations be gathered per plot (from a statistical standpoint, this is a technical replicate, not a true replicate) and then reduced to a single number per plot using a simple mean. Row-wise functions can accomplish this.\n\ndisease_df_sum &lt;- disease_df %&gt;% rowwise() %&gt;% \n  mutate(score_final = mean(score1:score2),\n        max_score = max(score1:score2))\ndisease_df_sum\n\n# A tibble: 10 × 8\n# Rowwise: \n   plot  score1 score5 score3 score4 score2 score_final max_score\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;     &lt;int&gt;\n 1 a         20     90      0     40     80          50        80\n 2 b         60     60     40      0     90          75        90\n 3 c         60     40    100    100     50          55        60\n 4 d          0     80     50     50     70          35        70\n 5 e          0     50     50     10     10           5        10\n 6 f         20     60     60     80     80          50        80\n 7 g         10     50     90      0     80          45        80\n 8 h         20     40     50     80      0          10        20\n 9 i         20     10     80     30     20          20        20\n10 j        100     40     40     20     10          55       100\n\n\n\ndisease_df_sum1 &lt;- disease_df %&gt;% select(score1, score4, score5) %&gt;% \nrowwise() %&gt;% \n  mutate(score_final = mean(c(score1, score4)),\n        median_score = median(c(score1, score4)))\ndisease_df_sum1\n\n# A tibble: 10 × 5\n# Rowwise: \n   score1 score4 score5 score_final median_score\n    &lt;int&gt;  &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1     20     40     90          30           30\n 2     60      0     60          30           30\n 3     60    100     40          80           80\n 4      0     50     80          25           25\n 5      0     10     50           5            5\n 6     20     80     60          50           50\n 7     10      0     50           5            5\n 8     20     80     40          50           50\n 9     20     30     10          25           25\n10    100     20     40          60           60\n\n\n\n\n\n\n\n\nPractice Problem\n\n\n\n\n\n\nImport “weather_data.csv”, select ‘station, ’tmin_F’ and ‘tmax_F’ using a select() function. Calculate the sum, mean, and median for ‘tmin_F’ and ‘tmax_F’ using rowwise() function.\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nIt is possible use mutate() or summary() commands on a grouped data frame. A summary() call will return one value per group + summary function (e.g. mean). A mutate() call will return one value per row + summary function. All the previous examples in this lesson used summary(). Here is one example using mutate():\n\nvariety_trials %&gt;% \n  select(trial, rep, variety, crop, yield) %&gt;% group_by(crop) %&gt;%\n  mutate(relative_yield = yield/mean(yield, na.rm=TRUE)) %&gt;% \n  arrange(desc(yield)) %&gt;% head(15)\n\n# A tibble: 15 × 6\n# Groups:   crop [6]\n   trial                         rep variety        crop  yield relative_yield\n   &lt;chr&gt;                       &lt;int&gt; &lt;chr&gt;          &lt;chr&gt; &lt;dbl&gt;          &lt;dbl&gt;\n 1 SWIdahoCereals_HRS_PAR_2017     1 WB9411         HRS    498.           4.50\n 2 SWIdahoCereals_HRS_PAR_2017     3 12SB0197       HRS    297.           2.68\n 3 SWIdahoCereals_HWS_PAR_2017     3 Dayn           HWS    253.           2.18\n 4 SWIdahoCereals_SWS_PAR_2017     1 UI Stone       SWS    219.           2.12\n 5 SWIdahoCereals_SWS_PAR_2017     4 UI Stone       SWS    217.           2.09\n 6 SWIdahoCereals_SWS_PAR_2017     4 WA8277         SWS    204.           1.97\n 7 SWIdahoCereals_SWW_PAR_2017     1 Bobtail        SWW    201.           2.14\n 8 SWIdahoCereals_H-W_PAR_2017     3 WA8269         H-W    199.           2.36\n 9 SWIdahoCereals_HWS_PAR_2017     1 LCS Star       HWS    198.           1.71\n10 SWIdahoCereals_HRW_PAR_2020     2 LCS Jet        HRW    197.           1.45\n11 SWIdahoCereals_HRW_PAR_2020     3 LCS Rocket     HRW    196.           1.44\n12 SWIdahoCereals_SWW_PAR_2017     2 Agripro Legion SWW    194.           2.06\n13 SWIdahoCereals_H-W_PAR_2017     4 NSA10-2196     H-W    193.           2.29\n14 SWIdahoCereals_HWS_PAR_2017     4 LCS Star       HWS    193.           1.66\n15 SWIdahoCereals_HRW_PAR_2020     2 Scorpio        HRW    193.           1.42\n\n\nIn this case, the mean value used for calculating ‘relative_yield’ is the group mean.",
    "crumbs": [
      "Lessons",
      "Data aggregation"
    ]
  },
  {
    "objectID": "lessons/data-import.html",
    "href": "lessons/data-import.html",
    "title": "Importing Data into R",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nknow how to set your working directory\nknow how to specify a file path\nBe able to import CSV and Excel files into R\nunderstand the main arguments for importing .xlsx, .xls and .csv files",
    "crumbs": [
      "Lessons",
      "Importing tabular file"
    ]
  },
  {
    "objectID": "lessons/data-import.html#working-directory-and-file-paths",
    "href": "lessons/data-import.html#working-directory-and-file-paths",
    "title": "Importing Data into R",
    "section": "Working directory and file paths",
    "text": "Working directory and file paths\nWhile you can simulate data or load existing data sets associated with packages for your research, most of you will need to load pre-existing data sets from you computer, or a cloud server, some other external device.\nThe first thing you need to understand is the working directory and file paths. When an R session is initiated, it ascertains what the root working directory is based on the default settings for your R installation and any other.\nYou can check this with getwd(). You can set the file path relative to the current working directory or set an absolute path (that is, independent of your current directory). You can read more about absolute and relative paths here.\nWhen opening an R project (an .Rproj file), the working directory is automatically set to the directory where the .Rproj is located. Otherise, you can set the working directory using setwd() or under “Session” in the RStudio Ribbon.\n\nQuarto files and the {Here} package\nWhen working with an R notebook like a Quarto document or an Rmarkdown document, the working directory within code chunks is automatically set to where the quarto document is located on your file system. This is the case regardless of whether you set the working directory or where the .Rproj file is located.\nTo import a data set located in another directory from where the quarto document is located, you can use bash strategies for navigating up and down directory structures (e.g. “../data/somefile.csv”). Another solution is to use the here.\nThe function here() in the here package will reconstruct a path based on the system you are using (Windows, Mac, Linux, etc). Each directory must be specified and the final item specified is the file to import.\n\nlibrary(here)\n\nhere() starts at /home/runner/work/r-for-ag-scientists/r-for-ag-scientists\n\nhere(\"directory1\", \"subdirectory\", \"my_file.txt\")\n\n[1] \"/home/runner/work/r-for-ag-scientists/r-for-ag-scientists/directory1/subdirectory/my_file.txt\"\n\n\nIf you don’t want to load an entire package, but use the function from it, you can use the notation package_name::function(). The code below uses that when calling the here() function: here::here().",
    "crumbs": [
      "Lessons",
      "Importing tabular file"
    ]
  },
  {
    "objectID": "lessons/data-import.html#how-to-import",
    "href": "lessons/data-import.html#how-to-import",
    "title": "Importing Data into R",
    "section": "How to Import",
    "text": "How to Import\nThere are several ways to import data into R.\n\nUse the “Import Dataset” tool in the Environment pane.\n\n\n\n\n\n\n\n\n\n\n\nUse the Files pane in RStudio\n\n\n\n\n\n\n\n\n\n\nBoth of them open a new window that looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhile these point-and-click interfaces are very convenient, they don’t automatically leave a trail of breadcrumbs to help you repeat the process in the future. But, they do generate R code that we can capture and reuse. They are handy shortcuts that I have found especially helpful when trying to import file formats I work with rarely.\n\n\n\nManual command line import\n\nUltimately, this is how anything is imported into R. As mentioned, first two options listed above are actually tools for generating code that will import a data set through the command-line!\nThere’s 4 common approaches for importing data into R:\n\nread.csv()\nread_csv()\nread_excel()\nread_delim()\n\n\nread.csv()\nA very commonly used function for reading in “comma separated values” (CSV) files. I personally like this format because it is not proprietary and is compatible across many operating systems. It also limits all sorts of extraneous formatting that itself is a barrier to reproducible research (e.g. highlighting is discarded once a CSV file is closed).\nExample usage:\n\nmycsv1 &lt;- read.csv(here::here(\"data\", \"trial_metadata.csv\"))\n\nResult:\n\nstr(mycsv1)\n\n'data.frame':   28 obs. of  13 variables:\n $ trial            : chr  \"SWIdahoCereals_HWW_PAR_2020\" \"SWIdahoCereals_SWW_PAR_2020\" \"SWIdahoCereals_H_W_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2018\" ...\n $ program          : chr  \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ pi               : chr  \"OWalsh\" \"OWalsh\" \"OWalsh\" \"OWalsh\" ...\n $ nursery          : chr  \"HWW\" \"SWW\" \"H_W\" \"SWW\" ...\n $ year             : int  2020 2020 2018 2018 2018 2018 2016 2016 2016 2017 ...\n $ location         : chr  \"Parma\" \"Parma\" \"Parma\" \"Parma\" ...\n $ grower_cooperator: chr  \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" ...\n $ irrigation       : chr  \"irrigated\" \"irrigated\" \"irrigated\" \"irrigated\" ...\n $ latitude         : num  43.8 43.8 43.8 43.8 43.8 ...\n $ longitude        : num  -117 -117 -117 -117 -117 ...\n $ planting_date    : chr  \"10/7/2019\" \"10/7/2019\" \"10/25/2017\" \"10/25/2017\" ...\n $ harvest_date     : chr  \"7/21/2020\" \"7/21/2020\" \"7/17/2018\" \"7/17/2018\" ...\n $ exp_design       : chr  \"RCBD\" \"RCBD\" \"RCBD\" \"RCBD\" ...\n\n\nDetails:\nread.csv() is actually a “wrapper” for another function, read.table(). It has taken read.table() and set the default arguments to work with CSV files. read.table() is a more generalized form providing more flexibility.\nThe default arguments include:\n\ncolnames = TRUE: the first row of data is assumed to be the column names * nothing in the data set will be used for row names unless we explicitly indicate so\nsep = \",\": each data point is separated from another by a comma * a newline indicator is used to separate rows of data\nna.strings = c(\"NA\", \"\"): cells with a either no data (““) or an”NA” will be treated as missing.\nif a column of data consists of non-numeric characters, that column vector will be treated as character and not a factor\n\n\n\nread_csv()\nThis function is part of readr. It has very similar functionality to read.csv(), but it parses the data a wee bit different.\nExample Usage:\nFirst, load the package readr that contains the function read_csv().\n\nlibrary(readr)\nmycsv2 &lt;- read_csv(here::here(\"data\", \"trial_metadata.csv\"))\n\nRows: 28 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): trial, program, pi, nursery, location, grower_cooperator, irrigati...\ndbl  (3): year, latitude, longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nResult:\n\nstr(mycsv2)\n\nspc_tbl_ [28 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ trial            : chr [1:28] \"SWIdahoCereals_HWW_PAR_2020\" \"SWIdahoCereals_SWW_PAR_2020\" \"SWIdahoCereals_H_W_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2018\" ...\n $ program          : chr [1:28] \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" \"SWIdahoCereals\" ...\n $ pi               : chr [1:28] \"OWalsh\" \"OWalsh\" \"OWalsh\" \"OWalsh\" ...\n $ nursery          : chr [1:28] \"HWW\" \"SWW\" \"H_W\" \"SWW\" ...\n $ year             : num [1:28] 2020 2020 2018 2018 2018 ...\n $ location         : chr [1:28] \"Parma\" \"Parma\" \"Parma\" \"Parma\" ...\n $ grower_cooperator: chr [1:28] \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" \"UI Parma REE Center\" ...\n $ irrigation       : chr [1:28] \"irrigated\" \"irrigated\" \"irrigated\" \"irrigated\" ...\n $ latitude         : num [1:28] 43.8 43.8 43.8 43.8 43.8 ...\n $ longitude        : num [1:28] -117 -117 -117 -117 -117 ...\n $ planting_date    : chr [1:28] \"10/7/2019\" \"10/7/2019\" \"10/25/2017\" \"10/25/2017\" ...\n $ harvest_date     : chr [1:28] \"7/21/2020\" \"7/21/2020\" \"7/17/2018\" \"7/17/2018\" ...\n $ exp_design       : chr [1:28] \"RCBD\" \"RCBD\" \"RCBD\" \"RCBD\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   trial = col_character(),\n  ..   program = col_character(),\n  ..   pi = col_character(),\n  ..   nursery = col_character(),\n  ..   year = col_double(),\n  ..   location = col_character(),\n  ..   grower_cooperator = col_character(),\n  ..   irrigation = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double(),\n  ..   planting_date = col_character(),\n  ..   harvest_date = col_character(),\n  ..   exp_design = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nDetails:\nThis function takes similar arguments to read.csv(), although the output is more extensive.\n\nLike in read.csv(), the default separator is “,”, missing data are coded as empty string \"\" or NA and the first line is assumed to be the column header\nit does not bother with a row names attribute\nthe argument trim_ws will remove leading and trailing whitespace for data entries. So the column header ” soil pH” will become “soil pH”.\nColumn are preserved more clearly than read.csv() (including spaces and special characters). I’m honestly not fond of this behavior and usually clean up weird column names with janitor::clean_names().\n\nThe output is largely similar, although read_csv() actually parses dates, unlike read.csv().\n\n\nread_excel()\nThis function will read in MS Excel files (reliably)! It is truly amazing. For many many years, it was cumbersome and/or impossible to read Excel files direclty into R.\nExample Usage:\nLoad the package that contains the function read_excel(), readxl.\n\nlibrary(readxl)\nmyxl &lt;- read_excel(here::here(\"data\", \"field_trial_2009.xlsx\"), \n                   sheet = \"site_02\", \n                   trim_ws = TRUE, \n                   na = c(\"\", \"NA\"))\n\nResults:\n\nstr(myxl)\n\ntibble [80 × 30] (S3: tbl_df/tbl/data.frame)\n $ plot    : num [1:80] 1 2 3 4 5 6 7 8 9 10 ...\n $ bloc    : num [1:80] 1 1 1 1 1 1 1 1 1 1 ...\n $ rep     : num [1:80] 1 1 1 1 1 1 1 1 1 1 ...\n $ Ptrt    : chr [1:80] \"high\" \"high\" \"high\" \"high\" ...\n $ inoc    : chr [1:80] \"myco\" \"myco\" \"myco\" \"myco\" ...\n $ Cv      : chr [1:80] \"OTIS\" \"ALPOWA\" \"BlancaG\" \"WALWORTH\" ...\n $ order   : num [1:80] 1 2 3 4 5 17 18 16 20 19 ...\n $ height  : num [1:80] 49 48.7 40.3 45.7 59 ...\n $ spikes  : num [1:80] NA 240 192 360 216 340 220 228 208 256 ...\n $ tstwt   : num [1:80] 61.9 61.2 61.3 60.6 61.7 60.2 61.2 61.2 62.1 62.1 ...\n $ HI      : num [1:80] 0.385 0.375 0.444 0.385 0.481 0.387 0.5 0.5 0.474 0.409 ...\n $ YieldKg : num [1:80] 1144 1274 1026 1026 922 ...\n $ YieldBu : num [1:80] 16.5 18.5 14.9 15.1 13.3 ...\n $ tkw     : num [1:80] 35.1 32.2 37.6 30.8 40.1 ...\n $ myco    : num [1:80] 37.5 30 35.7 15.4 14.3 ...\n $ PT1     : num [1:80] 4391 4500 4546 3436 4121 ...\n $ PT2     : num [1:80] 1040 726 605 702 1036 ...\n $ PT3     : num [1:80] 375 85.5 315.6 247.4 161.9 ...\n $ Pseeds  : num [1:80] 3182 2523 3156 3389 2473 ...\n $ cruc    : num [1:80] 6 10 4 5 2 3 9 7 39 66 ...\n $ Cu      : num [1:80] 6.11 4.72 5.99 5.69 4.48 ...\n $ Fe      : num [1:80] 46.4 27.2 46.8 36.5 34.2 ...\n $ Mn      : num [1:80] 28 21.5 28.2 28.4 23.8 ...\n $ Zn      : num [1:80] 16.2 14.2 18.3 22.1 15.1 ...\n $ Protein : num [1:80] 14.3 12.7 14.7 16.3 12 ...\n $ SDS     : num [1:80] 9.9 9.9 13.1 12.5 9.6 13.7 13.4 9.3 9.6 10.2 ...\n $ PT1_2   : num [1:80] 4371 4455 4442 3481 4146 ...\n $ PT2_2   : num [1:80] 968 659 544 635 965 ...\n $ PT3_2   : num [1:80] 387 104 328 262 179 ...\n $ Pseeds_2: num [1:80] 3103 2482 3083 3296 2434 ...\n\n\nDetails\n\nBy default, read_excel() will import the first sheet unless it named by position (e.g. 1, 2, 3) or name (like in the previous example).\nThe default argument for missing values is only an empty string \"\"\nIt returns results very similar to read_csv().\nThere is also an argument, range for setting a custom range of cells to read in.\n\n\n\nread_delim()\nFor reading in text files! It’s pretty simple. Text files are not used terribly frequently, but I see them now and then with really huge files, such as genotyping data.\n\nmytxt &lt;- read.delim(here::here(\"data\", \"genotypic_data.txt\"))\n\nDetails\nThis function is a more extensive version of read.csv(). It has a longer list of argument and slight different default values for those arguments that read.csv. Run ?write.delim in the console for more details.\n\n\n\n\n\n\nNote\n\n\n\nIt’s useful to understand how R has read a data set into an R session. R has opened a connection to the file that you have specified, read file information into the R session using system memory (your computer’s RAM), and then closed the connection.\nThis is a one-way process from your file to R\nOnce a file is loaded and the connection closed, there is no longer any link between the object loaded into memory in R and its origin file (located on on your computer, a cloud server, etc). Any changes made to the object in R will not change the file on your computer unless you explicitly run scripts to overwrite that file. This is good thing; it gives you freedom to experiment with and manipulate an object without worrying about messing up the original file.\nWe will discuss later how to export R objects to your file system when you want to capture changes made to an object.\n\n\n\n\nTroubleshooting Import errors\nThings frequently go wrong when importing data. This can sometimes be corrected by changing the import arguments, but often it indicates problems with the incoming data.\nSome possible errors and how to fix them:\n\nSome variables which should be numeric are characters instead. At least one item contains an unexpected character that renders that observation - and the rest of the vector - as a character. This might be two decimal points, a comma, or a “O” instead of “0”. If possible, manually inspect the data and correct the error.\nMissing data are not coded as missing. Import functions have default values for what is interpreted as missing. Check the documentation and adjust the arguments as needed to capture what code a data sets is using to indicate missing data.\n\nThe best choice is to properly arrange your data set prior to import. Broman & Woo (2018) provides some straightforward recommendations on how to manage data in spreadsheets.\n\n\nImporting Other Data types\nThe instructions provided above are for importing tabular data that is generally not “big data”.\nBig data is a subjective term that is system-dependent (and is rapidly changing as PC computing power and memory increases). Some personal computers can easily handle a 50 Mb file, while others cannot. If you are waiting more than 5 seconds for your data to import, then consider other options. A deep discussion about how to handle large data sets are beyond the scope of this workshop, but at the very minimum, consider the package data.table and its high-performance functions for reading and writing data, fread() and fwrite(). If your data sets are too big to load directly into R, consider arrow.\nYou may also be working with data types that are not strictly tabular, at least in the form they are stored on a computer. Here are some common non-tabular data types and packages to handle import of those.\n\nspatial data: sf, sp, raster\nSAS data sets: haven, haven::read_sas()\nSPSS data sets: haven, haven::read_sav()\ntabular files on Google drive: googledrive\nimage files: magick\n\n…and so much more.\n\n\n\n\n\n\nPractice Problem\n\n\n\n\n\n\nImport one of your data sets using two of the functions taught:\n\n(save your data in different format to enable this)\n\nread.csv()\nread_csv()\nread_excel()\nread.delim()\n\n\nExamine the data imported using View(imported_data). Did everything import as expected? Are your variables coded as they should be? Are numeric variables numeric? Are missing data detected as thus?\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nNote how easy it is to import data from the ‘Files’ pane; navigate to the file and click on it! It’s important that that the code generated is saved so (1) you can reuse the code; and (2) so you can link the data set loaded to a set of R commands you ran should you ever need to rerun them (which is highly likely).",
    "crumbs": [
      "Lessons",
      "Importing tabular file"
    ]
  },
  {
    "objectID": "lessons/data-structures.html",
    "href": "lessons/data-structures.html",
    "title": "Data Structures",
    "section": "",
    "text": "The longest and most important lesson of them all! These are the foundation of everything you are likely to do R as a scientists. Understanding these will take time and practice, so you may find yourself returning to this page to remind yourself of these data structures.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Data Structures"
    ]
  },
  {
    "objectID": "lessons/data-structures.html#introduction-to-common-data-structures",
    "href": "lessons/data-structures.html#introduction-to-common-data-structures",
    "title": "Data Structures",
    "section": "Introduction to Common Data Structures",
    "text": "Introduction to Common Data Structures\nPreviously, we looked at data types. Now we need to consider how those types are arranged into complex structures (that is, objects) we can access and manipulate.\nThere are several data structures commonly used in R:\n\nvector\ndata.frame\nmatrix\nlist\n\n\nThe vector\nA collection of items all coerced to be the same data type that we learned about in the previous lesson. These are sometimes called “atomic vectors” in the R documentation.\n\nv1 &lt;- 1:10\nv2 &lt;- c(\"apples\", \"pears\", \"oranges\")\nv3 &lt;- c(1, 5, 7, 85)\n\nA vector can also consist of only one value or no value.\n\nv4 &lt;- \"violets\"\nv5 &lt;- TRUE\nv6 &lt;- NA\n\nIt has the attribute length and each item in a vector can also be named.\n\nlength(v1); length(v2); length(v3)\n\n[1] 10\n\n\n[1] 3\n\n\n[1] 4\n\n\n\nnames(v3) &lt;- c(\"A\", \"B\", \"C\", \"D\")\nv3\n\n A  B  C  D \n 1  5  7 85 \n\n\n\nAccessing items\nItems in a vector can be accessed by referencing the numeric position in the vector, starting at 1 and ending at the vector length. If a vector has length of one, it not necessary to index that.\nx[1] will access the first item in the vector, while x[5] will access the 5th element. Multiple item can be indexed: x[c(1,5)]. If an index position, it repeated, that item will be returned as often as it is called:\n\nv1[1]\n\n[1] 1\n\nv1[5]\n\n[1] 5\n\nv1[c(1,5)]\n\n[1] 1 5\n\nv1[c(1,1)]\n\n[1] 1 1\n\n\nAny collection of numbers can be used to index items in a vector:\n\nv1[c(1, 1:5)]\n\n[1] 1 1 2 3 4 5\n\n\nWhat happens if a negative number is used?\n\nv1[-1]\n\n[1]  2  3  4  5  6  7  8  9 10\n\n\nEverything but that index position is returned.\nWhat if you index a position that does not exist?\n\nv1[0]\n\ninteger(0)\n\nv1[20]\n\n[1] NA\n\n\nItems in a vector can also be accessed by their name:\n\nv3[\"A\"]\n\nA \n1 \n\n\nWhat happens if there are replicate names in a vector and you try to index (extract a value) for that name?\n\nnames(v3) &lt;- c(\"A\", \"B\", \"C\", \"A\")\nv3\n\n A  B  C  A \n 1  5  7 85 \n\nv3[\"A\"]\n\nA \n1 \n\n\nOnly the first instance of a name is returned.\n\n\n\nThe data frame\nA collection of vectors all of the name length. Each vector is a single data type, but different columns can be different data types. This is similar to a typical workbook you might open in Excel or another spreadsheet program. These can be only one column wide, but they often consist of more than that.\n\nd1 &lt;- data.frame(var1 = 1:5,\n                 var2 = c(\"a\", \"b\", \"a\", \"b\", \"c\"),\n                 var3 = c(\"alpha\", \"beta\", \"gamma\", \"zeta\", \"psi\"))\nd1\n\n  var1 var2  var3\n1    1    a alpha\n2    2    b  beta\n3    3    a gamma\n4    4    b  zeta\n5    5    c   psi\n\n\nNotes that is a single value is supplied for a column, it will be repeated for the entire column.\nA data frame has attributes for:\n\nnrow number of rows\nncol number of columns\ncolnames column names\nrownames row names (if none are provided, R will generate integer row names starting at 1)\n\n\n\n\n\n\n\nNote\n\n\n\nWhile duplicate column names in a data frame are allowed, they are not advised, and may throw an error during data import, depending on the import function used.\n\n\nCheck the number of rows and columns:\n\nnrow(d1)\n\n[1] 5\n\nncol(d1); length(d1)\n\n[1] 3\n\n\n[1] 3\n\ndim(d1) # tells us row and column lengths in one command\n\n[1] 5 3\n\n\nLook at the rownames and colnames atrributes:\n\nrownames(d1)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\ncolnames(d1)\n\n[1] \"var1\" \"var2\" \"var3\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe rownames attribute can be set, but if it is not, it is automatically created within R from 1 to the total number of rows. Row names are a tricky attribute than many packages in R do not support. A function may toss out your row names without any warning!\nIn general, I do not recommend setting the row names attribute in data frames to anything other than the default values unless a package function specifically requires it.\n\n\nWhat does length(d1) return? How about names(d1)?\nWe can look at the overall structure of a data.frame with View():\n\nView(d1)\n\nIf a particularly large file is loaded into R, using View() may be very slow (if you have a large number of rows) and provide an incomplete view (if you have a large number of columns). In that case, you can use str() to look at a data frame’s structure:\n\nstr(d1)\n\n'data.frame':   5 obs. of  3 variables:\n $ var1: int  1 2 3 4 5\n $ var2: chr  \"a\" \"b\" \"a\" \"b\" ...\n $ var3: chr  \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n\n\nThe data frame is the most common data structure scientists use in R\n\nAccessing items\nLike vectors, data frames can be indexed by position, except now we have two dimensions to consider. You can extract individual elements in a data frame by references the row and column position, my_dataframe[row, column].\n\nExtract the items located in the first 2 row2 and last 2 columns:\n\nVisual of what we want:\n\n\n\n\n\n\n\n\n\n(This graphic is an overlay of green over blue, creating a dark teal color. The green represents rows indexed, the blue is columns indexed and the teal is the intersection between those two. If a color is not visible, that is because it is under the teal overlay.)\n\nd1[1:2, 2:3]\n\n  var2  var3\n1    a alpha\n2    b  beta\n\n\n\nExtract the first two rows and all of the columns:\n\n\n\n\n\n\n\n\n\n\n\nd1[1:2, ]\n\n  var1 var2  var3\n1    1    a alpha\n2    2    b  beta\n\n\nWhen the column position is left empty, all columns are returned\n\nExtract the entire first column and all rows:\n\n\n\n\n\n\n\n\n\n\n\nd1[ ,1]\n\n[1] 1 2 3 4 5\n\n\nWhen the row position is left empty, all rows are returned\n\nExtract the values located in the first 2 rows and first two columns:\n\n\n\n\n\n\n\n\n\n\n\nd1[1:2, 1:2]\n\n  var1 var2\n1    1    a\n2    2    b\n\n\n\nReturn everything except the third columns\n\n\n\n\n\n\n\n\n\n\n\nd1[ ,-3]\n\n  var1 var2\n1    1    a\n2    2    b\n3    3    a\n4    4    b\n5    5    c\n\n\n\nReturn everything except the first 2 rows:\n\n\n\n\n\n\n\n\n\n\n\nd1[-(1:2),  ]\n\n  var1 var2  var3\n3    3    a gamma\n4    4    b  zeta\n5    5    c   psi\n\n\n\n\n\n\n\n\nThings to note\n\n\n\nIndexing accepts numeric/integer vectors, so you can use a sequence (3:10), or concatenated positions (c(1, 2, 5, 10)), or a combination of both (c(1:10, 13)).\nWhen indexing positions in a vector or data frame (or anything else), the amount of white space does not affect the outcome. These are equivalent: d[1,2], d[1, 2], d[ 1, 2]\n\n\n\n\nColumn Referencing\nData in R data frames can also be referred to by their column names using the notation dataframe$column_name:\n\nd1$var1\n\n[1] 1 2 3 4 5\n\n\nThe data are returned as a vector (with the typical attributes of a vector: length and names).\nThis can also be used to create a new column in the data frame:\n\nd1$var4 &lt;- 0:-4\n\nIn this example, a new column called “var4” was created, consisting of sequence numbers from zero to -4.\n\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3    a gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\n\n\n\nValue replacement\nThere are likely to be moments when you want to replace values in a data frame or vector with something else. You can do that with indexing and variable assignment.\nLet’s image that we want to assign the third value in the second column as NA. First, we index the that position, then we assign a value to it (NA in this case):\n\nd1[3, 2] &lt;- NA\n\n\n\n\nThe matrix\nA very mile-high view of the matrix is given here because you while may encounter this, it is a less commonly used data structure in R.\nLike a data frame, a matrix is a collection of vectors all the same length, except all vectors must be the same data type (e.g. numeric, character, etc).\nAn R matrix is not strictly identical to the mathematical concept of a matrix, but if you make an R matrix consisting only of numbers, it can be used like a mathematical matrix. Furthermore, there several mathematical operations that are intended to only work on matrices such as matrix pre-multiplication %*% or extraction of a diagonal from a square matrix, diag().\nA matrix lacks some of the attributes and functionality that are possible for data frames. Columns names can be given, but they cannot be used to index columns (i.e. my_matrix$col will throw an error).\nMatrices are not commonly seen in user-facing functions in R, but within R internals, they are widely used. You may occasionally come across a package requiring a matrix or perhaps you work in a math-intensive discipline where matrix operations are part of your regular work.\n\n\n\n\n\n\nFYI: how to make a matrix\n\n\n\n\n\nA matrix can be created by providing a vector of numbers and telling it to populate a table of given dimensions:\n\nx = 1:100\nm1 &lt;- matrix(data = x, nrow = 5, ncol = 20, byrow = TRUE)\n\n\n\n\n\n\nThe list\nThis is the least structured and hence most flexible data structure that exists in R. A list is like a closet that happens to be filled with other objects, or your kitchen sink, or the trunk of your car. It’s a collection of objects of varying sizes, types, and so on. A vector, scalar and data frame can all be combined into a list. A list can contain other lists inside of it (although this list nesting can be cumbersome to deal with).\n\nL1 &lt;- list(v1, v2, v3, d1, m1)\nstr(L1)\n\nList of 5\n $ : int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ : chr [1:3] \"apples\" \"pears\" \"oranges\"\n $ : Named num [1:4] 1 5 7 85\n  ..- attr(*, \"names\")= chr [1:4] \"A\" \"B\" \"C\" \"A\"\n $ :'data.frame':   5 obs. of  4 variables:\n  ..$ var1: int [1:5] 1 2 3 4 5\n  ..$ var2: chr [1:5] \"a\" \"b\" NA \"b\" ...\n  ..$ var3: chr [1:5] \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n  ..$ var4: int [1:5] 0 -1 -2 -3 -4\n $ : int [1:5, 1:20] 1 21 41 61 81 2 22 42 62 82 ...\n\n\nEach list item can have a name. Or not.\n\nL1 &lt;- list(\"number\" = v1, \"flower\" = v3, v4, \"df\" = d1, m1)\nnames(L1)\n\n[1] \"number\" \"flower\" \"\"       \"df\"     \"\"      \n\nstr(L1)\n\nList of 5\n $ number: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ flower: Named num [1:4] 1 5 7 85\n  ..- attr(*, \"names\")= chr [1:4] \"A\" \"B\" \"C\" \"A\"\n $       : chr \"violets\"\n $ df    :'data.frame': 5 obs. of  4 variables:\n  ..$ var1: int [1:5] 1 2 3 4 5\n  ..$ var2: chr [1:5] \"a\" \"b\" NA \"b\" ...\n  ..$ var3: chr [1:5] \"alpha\" \"beta\" \"gamma\" \"zeta\" ...\n  ..$ var4: int [1:5] 0 -1 -2 -3 -4\n $       : int [1:5, 1:20] 1 21 41 61 81 2 22 42 62 82 ...\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you end up with too many objects in your global environment, you can always delete them with the rm() function:\nrm(myvar)\nrm(var1, var2, var3)\nIf one object ends up with the wrong name, you can copy the object to a new name and delete the old version:\nnew &lt;- old\nrm(old)\n\n\n\nAccessing items\nAs mentioned earlier, lists are relatively unstructured and follow fewer rules. You can access list items by their numeric position, list[[1]], or their name (if it exists), list$name.\n\nL1[[1]]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nL1$df\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3 &lt;NA&gt; gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\n\nOnce a list item is accessed, the normal indexing rules apply. The 4th item in the list called “L1” is a data frame.\n\nL1[[4]]\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1\n3    3 &lt;NA&gt; gamma   -2\n4    4    b  zeta   -3\n5    5    c   psi   -4\n\nL1[[4]]$var1\n\n[1] 1 2 3 4 5\n\nL1[[4]][1:2,]\n\n  var1 var2  var3 var4\n1    1    a alpha    0\n2    2    b  beta   -1",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Data Structures"
    ]
  },
  {
    "objectID": "lessons/data-structures.html#checking-the-class-of-a-data-structure",
    "href": "lessons/data-structures.html#checking-the-class-of-a-data-structure",
    "title": "Data Structures",
    "section": "Checking the class of a data structure",
    "text": "Checking the class of a data structure\nUse the class() command.\n\nclass(v1)\n\n[1] \"integer\"\n\nclass(d1)\n\n[1] \"data.frame\"\n\nclass(L1)\n\n[1] \"list\"\n\n\nYou can also explicitly ask R if an object is a specific data structure:\n\nis.data.frame(d1)\n\n[1] TRUE\n\nis.matrix(d1)\n\n[1] FALSE\n\nis.list(L1)\n\n[1] TRUE\n\nis.data.frame(L1)\n\n[1] FALSE\n\n\nCoercion from is also possible. If you find yourself working with matrices, you can convert a data.frame to a matrix. Or a function may return a matrix that you need converted back to a data frame:\n\nas.data.frame()\nas.matrix()\nas.list()",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Data Structures"
    ]
  },
  {
    "objectID": "lessons/data-structures.html#final-notes",
    "href": "lessons/data-structures.html#final-notes",
    "title": "Data Structures",
    "section": "Final Notes",
    "text": "Final Notes\nThere are several more object types, but these are by far the ones you are most likely to encounter and use.\n\nMore resources:\n\nFor a deeper look into vectors, read this chapter from R 4 Data Science\nTo learn more about subsetting, read this chapter from Advanced R (they are not kidding; this book is advanced.)\n\nFor a very comprehensive guide to R object types, check out the official R language manual. Warning: this manual is extremely technical! If you choose to check it out, be patient with yourself. It may take several readings to fully understand the content.\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen information is extracted from a vector, data.frame, matrix or list using these tools, the returned information can always be assigned to a new object:\n\nnew &lt;- d1[1:2, -3]\n\nSometimes, we need that information assigned to a new object so we can it use later. Other times, printing the extracted information to the console is sufficient for meeting researcher needs.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R",
      "Data Structures"
    ]
  },
  {
    "objectID": "lessons/data-wrangling.html",
    "href": "lessons/data-wrangling.html",
    "title": "Introduction to Data Wrangling",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to select columns in R using select()\nbe able to filter a data set using filter()\nbe aware of how to conditionally create new variables using case_when()\nknow to create new variables using mutate()\nbe able to rename variables using rename()\nbe able to sort a data set using arrange()\nunderstand how to handle missing values with drop_na(), na_if() and replace_na()\nbe table to use separate() to split up single variables into multiple variables\n\n\n\n\nFirst, load libraries:\n\nlibrary(dplyr); library(tidyr)\n\nNext, import data:\n\nvariety_trials &lt;- read.csv(here::here(\"data\", \"trial_data.csv\"))\nweather &lt;- read.csv(here::here(\"data\", \"weather_data.csv\"))\n\n\n\n\n\n\n\nWhat is going on with here::here()?\n\n\n\n\n\nThe here() function is from the here package. This package simplifies working directory issues by setting it to where the nearest .Rproj files exists. When using a .qmd file, it looks for the .Rproj file that is the same directory as that file and moves up the directory tree.\n\n\n\n\nTidyverse notes\nThis lesson relies on group of packages called the “Tidyverse”, in particular dplyr and tidyr.\nThese packages follow a special set of rules called “non-standard evaluation” (sometimes abbreviated “NSE”). Tidyverse non-standard evaluation uses quotes far less often than “base R” (base R are package that are installed automatically when R is updated). It also uses indexing $ less frequently. You can name a variable directly instead of using dataset$var.\nMany functions in the Tidyverse follow this structure:\nfunction(dataset, action)\nWhere “dataset” is the data framed being input and “action” is whatever action is being taken.\n\n\nSelection columns\nThe function select is used to specify column you want to keep (all rows are returned). Columns can be specified by name or position (i.e. the first two columns in the data set would be 1:2).\nSelect by name:\n\nselect1 &lt;- select(variety_trials, variety, yield, grain_protein)\nhead(select1)\n\n    variety     yield grain_protein\n1  12SB0197  71.69333        9.8325\n2  12SB0197 108.60301        9.6025\n3  12SB0197  81.71237       11.2700\n4  12SB0197 103.84303       10.3500\n5 Jefferson  65.26589       10.2350\n6 Jefferson 104.37355       11.0400\n\n\nYou can also select on what columns you do not want:\n\nselect2 &lt;- select(variety_trials, -trial)\nselect3 &lt;- select(variety_trials, -c(trial))\n\nhead(select2); head(select3)\n\n  rep   variety     yield grain_protein test_weight\n1   1  12SB0197  71.69333        9.8325        62.1\n2   2  12SB0197 108.60301        9.6025        64.2\n3   3  12SB0197  81.71237       11.2700        65.6\n4   4  12SB0197 103.84303       10.3500        64.3\n5   1 Jefferson  65.26589       10.2350        62.8\n6   2 Jefferson 104.37355       11.0400        65.2\n\n\n  rep   variety     yield grain_protein test_weight\n1   1  12SB0197  71.69333        9.8325        62.1\n2   2  12SB0197 108.60301        9.6025        64.2\n3   3  12SB0197  81.71237       11.2700        65.6\n4   4  12SB0197 103.84303       10.3500        64.3\n5   1 Jefferson  65.26589       10.2350        62.8\n6   2 Jefferson 104.37355       11.0400        65.2\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe variables specified in select() will appear in the new data frame in exactly the order they were listed in the function call.\n\n\nSometimes, you might want to select many columns that share something common about their name:\n\nselect4 &lt;- select(variety_trials, starts_with(\"r\"))\nhead(select4)\n\n  rep\n1   1\n2   2\n3   3\n4   4\n5   1\n6   2\n\n\nThis particular example is not all that useful, but you might have a large data set, with several dozen variables that all start with “snp” followed by some alpha-numeric code (e.g. “snp4738”). This function will enable you to select these column more efficiently than naming every single one.\nThere are more options for pattern matching on column names:\n\n?tidyselect::starts_with #another option for searching help from the R console\n\n\n\n\n\n\n\n\n\n\n\n\nFiltering rows\nThe function filter is used to specify rows you want to keep (all columns are returned). This command uses logical operators for deciding what to keep.\n\nfilter1 &lt;- filter(variety_trials, variety == \"Stephens\") # match one name\nfilter2 &lt;- filter(variety_trials, variety %in% c(\"Stephens\", \"Bobtail\")) # match multiple names\nfilter3 &lt;- filter(variety_trials, yield &gt; 50 & grain_protein &lt;= 14) # filter on multiple conditions\n\ndim(filter1); dim(filter2); dim(filter3)\n\n[1] 4 6\n\n\n[1] 16  6\n\n\n[1] 1017    6\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is also possible to select by numeric position:\n\nselect(variety_trials, c(1:3, 4))\n\nWhile selecting by numeric position works, it is an unreliable choice because it depends on column order or row order being exactly as you expect it. This may work the first time you write + run code, but it is likely to fail over time as you sort, augment or change data sets.\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nImport “trial_data.csv” with the readr function read_csv().\nSelect columns that contain “i” in the column name and assign it a name “select_colm”.\nUsing the object from importing “trial_data.csv”, filter when variety is “Jefferson” and “Dayn”, and yield greater than or equal to 70. Assign these results to a new object.\n\n\n\n\n\n\nCreating new variables\nYou can quite create new variables with a mutate() function call:\nmutate(dataset, var_name = variable)\nExamples:\n\nnew_var &lt;- rbinom(n = nrow(variety_trials), size = 1, prob = 0.5)\n\nmutate1 &lt;- mutate(variety_trials, \n                    dataset = \"example\",\n                    row_position = 1:n(),\n                    trial_id = trial,\n                    random_yield = yield + rnorm(n = n()),\n                    binom_var = new_var, \n                    yield_protein = yield + grain_protein)\n\ntable(new_var)\n\nnew_var\n  0   1 \n931 951 \n\nhead(mutate1)\n\n                        trial rep   variety     yield grain_protein test_weight\n1 SWIdahoCereals_H_S_PAR_2018   1  12SB0197  71.69333        9.8325        62.1\n2 SWIdahoCereals_H_S_PAR_2018   2  12SB0197 108.60301        9.6025        64.2\n3 SWIdahoCereals_H_S_PAR_2018   3  12SB0197  81.71237       11.2700        65.6\n4 SWIdahoCereals_H_S_PAR_2018   4  12SB0197 103.84303       10.3500        64.3\n5 SWIdahoCereals_H_S_PAR_2018   1 Jefferson  65.26589       10.2350        62.8\n6 SWIdahoCereals_H_S_PAR_2018   2 Jefferson 104.37355       11.0400        65.2\n  dataset row_position                    trial_id random_yield binom_var\n1 example            1 SWIdahoCereals_H_S_PAR_2018     70.88930         0\n2 example            2 SWIdahoCereals_H_S_PAR_2018    108.96284         0\n3 example            3 SWIdahoCereals_H_S_PAR_2018     81.99077         1\n4 example            4 SWIdahoCereals_H_S_PAR_2018    104.92011         1\n5 example            5 SWIdahoCereals_H_S_PAR_2018     65.86923         1\n6 example            6 SWIdahoCereals_H_S_PAR_2018    103.88999         0\n  yield_protein\n1      81.52583\n2     118.20551\n3      92.98237\n4     114.19303\n5      75.50089\n6     115.41355\n\n\nThis created 6 new variables:\n\ndataset which is a character with the value “example” for all rows\nrow_position providing the row number, starting at 1 and ending at n(), a function that returns the total nubmer of rows in the data frame\nrange_new which is a copy of the variable “range”\nrandom_yield which is the sum of the value for yield plus a random deviation from the function rnorm. This operation is vectorized, using the ‘yield’ measurement for each row and generating a new random deviate for each row.\nbinom_var the binomial outcomes variable created in the new_var .... statement.\nyield_protein the addition of two variables in the data set (this is also vectorized, calculating this for each row)\n\nThese example cover the majority of what you are likely to experience: creating a constant, calculating new variables from existing variables, pulling in an external variables, and so forth.\nThis is equivalent to what was taught earlier using $ notation:\n\nmutate1 &lt;- variety_trials # first, copy the data frame\nmutate1$dateset &lt;- \"example\"\nmutate1$row_position &lt;- 1:nrow(mutate1)\nmutate1$trial_new &lt;- mutate1$trial # note that NSE cannot be used\nmutate1$random_yield &lt;- mutate1$yield + rnorm(nrow(mutate1))\nmutate1$binom_var = new_var\nmutate1$yield_protein &lt;- mutate1$yield + mutate1$grain_protein\n\nThis can be a bit longer and cumbersome compared to mutate statements, but it does work.\n\ncase_when(), a special addition to mutate statements\nOccasionally, you will need a define a variable conditionally, based on information from other variables. Here is an example for variety trial data. Here, a special minimum value is created where all data for “yield” less than 100 are set at 100:\n\nVar1 &lt;- mutate(variety_trials, new_min = case_when(\n  yield &lt;= 100 ~ 100,\n  TRUE ~ yield))\nhead(Var1)\n\nEverything to the left of the tilde ~ is a logical expression to evaluate. Everything to the right of the tilde is the value to put if the logical expression evaluates to TRUE.\nThis can easily become more complex with the addition of other logical expressions and categorical levels to create.\nIf you have a categorical variable that needs further refinement (e.g. collapsing of multiple levels into one), check out the package forcats, which provides many functions for manipulating categorical (factor or character) variables.\n\n\n\nRenaming Variables\nCompared to mutate(), the function for renaming variables, rename(), is a breeze!\nrename(dataset, new_name = \"old_name\")\nThis is similar to variable assignment:\nnew_name &lt;- old_name\nExcept that quotes are always used when specifying the old variable name.\nExample:\n\nrename1 &lt;- rename(variety_trials, cultivar = \"variety\")\nhead(rename1, 3)\n\n                        trial rep cultivar     yield grain_protein test_weight\n1 SWIdahoCereals_H_S_PAR_2018   1 12SB0197  71.69333        9.8325        62.1\n2 SWIdahoCereals_H_S_PAR_2018   2 12SB0197 108.60301        9.6025        64.2\n3 SWIdahoCereals_H_S_PAR_2018   3 12SB0197  81.71237       11.2700        65.6\n\n\nAlso, you can use rename notation in select statements:\n\nrename2 &lt;- select(variety_trials, cultivar = \"variety\", yield, protein = \"grain_protein\")\n\nThis function selected the columns “variety”, “yield” and “grain_protein”, while renaming “variety to”cultivar” and “grain_protein” to “protein” - a handy shortcut.\n\n\nSplit up variables\nYou may encounter variables with information about multiple things. In agriculture, I see variables with values such as “Moscow_2021”, “Moscow_2022”, “StJohn_2021”, “StJohn_2022”. This variables is indicating multiple things - location and year in this exmample. This is a useful variable by itself, but a researcher might want to separate out location and year for other analytical purposes. The tidyr function separate() can do that.\nThe first column of “variety_trials” contains considerable information, all separated by an underscore:\n\nvariety_trials$trial[1]\n\n[1] \"SWIdahoCereals_H_S_PAR_2018\"\n\n\nThe first term is the program conducting the trial, the second is the crop grown, the third term is a location code, and the last term is the year. Let’s separate those terms into separate columns/variables.\nBefore running a separate() command, always check the variable to make sure it is structured as you expect.\nUse distinct() to determine the unique observations for the column “trial” in the the object “variety_trials”.\n\ndistinct(variety_trials, trial)\n\n                         trial\n1  SWIdahoCereals_H_S_PAR_2018\n2  SWIdahoCereals_H_S_WEI_2018\n3  SWIdahoCereals_H_W_PAR_2017\n4  SWIdahoCereals_H_W_PAR_2018\n5  SWIdahoCereals_H_W_WEI_2018\n6  SWIdahoCereals_HRS_PAR_2016\n7  SWIdahoCereals_HRS_PAR_2017\n8  SWIdahoCereals_HRS_PAR_2019\n9  SWIdahoCereals_HRS_PAR_2020\n10 SWIdahoCereals_HRW_PAR_2019\n11 SWIdahoCereals_HRW_PAR_2020\n12 SWIdahoCereals_HWS_PAR_2016\n13 SWIdahoCereals_HWS_PAR_2017\n14 SWIdahoCereals_HWS_PAR_2019\n15 SWIdahoCereals_HWS_PAR_2020\n16 SWIdahoCereals_HWW_PAR_2019\n17 SWIdahoCereals_HWW_PAR_2020\n18 SWIdahoCereals_SWS_PAR_2016\n19 SWIdahoCereals_SWS_PAR_2017\n20 SWIdahoCereals_SWS_PAR_2018\n21 SWIdahoCereals_SWS_PAR_2019\n22 SWIdahoCereals_SWS_PAR_2020\n23 SWIdahoCereals_SWS_WEI_2018\n24 SWIdahoCereals_SWW_PAR_2017\n25 SWIdahoCereals_SWW_PAR_2018\n26 SWIdahoCereals_SWW_PAR_2019\n27 SWIdahoCereals_SWW_PAR_2020\n28 SWIdahoCereals_SWW_WEI_2018\n\n\nThe variable variety_trials$trial uses an underscore to separate its components. However, one of the terms we mean to keep as one component does have an underscore inside of it, which will interpreted incorrectly as a term separator. The function gsub() can be used to fix this.\n\nvariety_trials$trial &lt;- gsub(pattern = \"_H_\", replacement = \"_H-\", x = variety_trials$trial)\n\nNow, separate() will split the variable into 4 components:\n\nvariety_trials &lt;- separate(variety_trials, trial, \n                           into = c(\"program\", \"crop\", \"location\", \"year\"),\n                           sep = \"_\", \n                           remove = FALSE)\n\nThe argument remove = FALSE indicates that we want to keep the input variable (“trial”). By default, it would be removed.\nThe opposite function is tidyr::unite() which will paste these variable together, separate by any character string you specify. unite() also can ignore missing data when pasting information together, avoiding this unfortunate result: “some.var_NA_NA_another.var”. You would get “some.var_another.var” instead.\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nImport “weather.csv” with the readr::read_csv(). Filter the weather data set for station “USC00456215”\nCreate a new variable named T_avg as an average of ‘tmin_F’ and ‘tmax_F’ using a mutate() function and name this data frame as ‘weather1’.\nSelect “name” column from the weather1 data set and rename it as “location”.\nIn weather1 data set, select the first five columns and reduce that data set to unique rows (look into using distinct() for extracting the unique observations).\nUsing weather1 data set, create a new variable as combination of station and name variables separated by “_” (e.g. station_name) using the unite() function.\n\nTip: search for unite() in help.\n\n\n\n\n\nFunctions for Missing Data\n\nRemove missing data\ndplyr::filter() can be used to filter missing data, but tidyr has a function, drop_na() that makes this easier. You can filter out rows based on missing data in any number of columns, including all columns. Note that this works on observations R has designated as NA. If an observation has white space instead of NA after data import into R, those are not equivalent.\nThis will remove all rows with any missing data.\n\nna_filter_ex1 &lt;- drop_na(variety_trials)\n\nThis will remove rows with missing data in ‘grain_protein’ and ‘test_weight’.\n\nna_filter_ex2 &lt;- drop_na(variety_trials, grain_protein, test_weight)\n\n\n\nDesignate missing data\nSometimes, you may have some odd observations you would like designated as missing. This can be accomplished with the mutate() function, but sometimes this shortcut is preferred. na_if() works on vectors, within a data frame or by itself.\n\ntrial_data &lt;- mutate(variety_trials, var2 = na_if(variety, \"Dayn\"))\n# check that it worked as intended:\nfilter(trial_data, var2 == \"Dayn\")\n\n [1] trial         program       crop          location      year         \n [6] rep           variety       yield         grain_protein test_weight  \n[11] var2         \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nThis also might be useful if specific columns use ‘-9’ to indicate missing values:\n\n# not that this demonstration code will not change the data frame because we did not use -\nvariety_trial &lt;- mutate(variety_trials, yield2 = na_if(trial, \"-9\"))\n\n\n\nReplace missing data with a value\nThere are other moments that you may want to replace missing values with something in particular (perhaps zero, but be cautious when doing so). replace_na() can accomplish this. Like na_if(), this function operates on vectors.\n\nvariety_trials &lt;- mutate(variety_trials, protein = replace_na(grain_protein, -9))\n# check that it worked as intended:\nhist(variety_trials$protein)\n\n\n\n\n\n\n\n\nSometimes, data sets have clear indications when a values is intended to be filled:\n\ndata1 &lt;- data.frame(experiment = c(\"exp1\", NA, NA, NA, \"exp2\", NA, NA, NA),\n                    observation = rnorm(n = 8, mean = 50, sd = 1))\ndata1\n\n  experiment observation\n1       exp1    50.84336\n2       &lt;NA&gt;    49.60324\n3       &lt;NA&gt;    48.24958\n4       &lt;NA&gt;    48.72382\n5       exp2    51.28513\n6       &lt;NA&gt;    49.60987\n7       &lt;NA&gt;    50.17672\n8       &lt;NA&gt;    50.67595\n\n\n\ndata2 &lt;- fill(data1, experiment, .direction = \"down\")\ndata2\n\n  experiment observation\n1       exp1    50.84336\n2       exp1    49.60324\n3       exp1    48.24958\n4       exp1    48.72382\n5       exp2    51.28513\n6       exp2    49.60987\n7       exp2    50.17672\n8       exp2    50.67595\n\n\n\n\n\nSorting a data set\nPrior to dplyr, sorting in R was a nightmare. Excel makes this so easy! Why was R torturing us??? But, dplyr has made this much easier:\narrange(dataset, variable1, variable2, ....)\nYou can sort on as many variables as you like! It will sort on the first variables listed and within that, the second variable listed, and so on.\nExample;\n\narrange1 &lt;- arrange(variety_trials, variety, yield)\n\n\nOutput file\nLet’s output this object to file so we can use it later.\n\nwrite.csv(variety_trials, here::here(\"outputs\", \"variety_trials_clean.csv\"), row.names = FALSE)\n\n\n\n\nThe pipe\nThe pipe operator %&gt;% or its newer replacement |&gt; are magic, or at least, they make our (data wrangling) lives so much easier.\nThe pipe operator works as thus:\noperation_1 %&gt;% operation_2\nOne operation can be performed (e.g. a select() command), and that resulting data frame is passed on to the next operation (e.g. filter()).\nExample: filter then sort\n\npipe1 &lt;- filter(variety_trials, yield &lt; 75) %&gt;% arrange(variety)\n\nThe data set is not named in the second operation because it is assumed to be dataset provided in the first operation. Whatever is being output directly left of the pipe operator is in the input data set.\nWe can take this even further by making the first operation our addition of the data set to the pipes:\n\npipe2 &lt;- variety_trials %&gt;% filter(yield &lt; 75) %&gt;% arrange(variety)\n\nThe pipe has made data wrangling so much easier! Before the pipe, each of these operations can be specified separately with its own object. So when you were done, you had roughly 50 objects in your environment, 48 of which were not needed anymore.\nIt also saved us from the “parentheses cascade” where one function is nested inside another function, which is nested within another, and so forth. It can be difficult to ascertain what parentheses belong to what operation, which often leads to coding errors. In a set of nestd functions, the inner functions are first executed and the outer functions are executed last. no longer had any sense of which set of parentheses belong to which operation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\nUsing piping, import “trial_metadata.csv”, filter by 2 nurseries of your choosing, then sort by year and planting date\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhat going on this notation?\ntibble::rownames_to_column()\nThis is a normal function call (the function being rownames_to_column()), and it is specifying that the package where this function resides is tibble (a tibble is the Tidyverse alternative to the data frame).\nYou want to use this notation in 2 circumstance:\n\nYou don’t want to load the entire package with a library() call, especially if you only need one function from it\nThe name of the function you want to call from a package conflicts with function names from another package. A very common example is filter() - this is a dplyr function, but it is also a base R function. Sometimes, you may receive a very puzzling error when using filter() that essentially is indicating that the wrong package was used. Using notation like dplyr::filter() clarified to R that you want to use the dplyr version of filter(). By default, the most recent package loaded overrides other function name conflicts, but sometiimes, it’s helpful to be unambiguous in your R function calls.",
    "crumbs": [
      "Lessons",
      "Data transformation and wrangling"
    ]
  },
  {
    "objectID": "lessons/getting-to-know-data.html",
    "href": "lessons/getting-to-know-data.html",
    "title": "Getting to Know Your Data in R",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should know:\n\nhow to import data in R.\n\nseveral methods of data exploration in R.\n\nhow to make cross tabulations of data.\n\nhow to make histograms and pairwise plots in R.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R"
    ]
  },
  {
    "objectID": "lessons/getting-to-know-data.html#import-a-csv-file",
    "href": "lessons/getting-to-know-data.html#import-a-csv-file",
    "title": "Getting to Know Your Data in R",
    "section": "Import a CSV file",
    "text": "Import a CSV file\nThis code read_csv() reads a CSV file named “caribbean_maize.csv” and assigns it to an object named “data1”.\nThe second line of code uses the “head” function to display the first 5 rows of the “data1” data frame. The View() will open the data set in new RStudio video where you can look up at the rows and columns.\n\n\n     isle site block plot  trt ears yield disease\n1 Antigua DBAN    B1    1 T111   42  4.96    TRUE\n2 Antigua DBAN    B1    2 T000   41  3.94   FALSE\n3 Antigua DBAN    B1    3 T311   49  6.35   FALSE\n4 Antigua DBAN    B1    4 T202   48  5.56    TRUE\n5 Antigua DBAN    B1    5 T111   45  5.36   FALSE\n\n\n\ndata1 &lt;- read.csv(\"data/caribbean_maize.csv\")\nView(data1)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis data set has been imported and stored in an R session as a “data frame” (we will describe what that is later). This data frame only exists while your session is running. You can choose to save or export this object before closing your R session. Unless you purposely export this object and write over the original file, any changes you make to this object in an R session will not affect the original file that was imported.\n\n\n\nThere are several functions for enabling a quick examination of a data frame.\n\ndim() gives the number of rows and columns; head() prints out the first 5 rows; and summary() provides summaries of each column of a data frame.\n\n\ndim(data1)\n\n[1] 288   8\n\nhead(data1, 5)\n\n     isle site block plot  trt ears yield disease\n1 Antigua DBAN    B1    1 T111   42  4.96    TRUE\n2 Antigua DBAN    B1    2 T000   41  3.94   FALSE\n3 Antigua DBAN    B1    3 T311   49  6.35   FALSE\n4 Antigua DBAN    B1    4 T202   48  5.56    TRUE\n5 Antigua DBAN    B1    5 T111   45  5.36   FALSE\n\nsummary(data1)\n\n     isle               site              block                plot      \n Length:288         Length:288         Length:288         Min.   : 1.00  \n Class :character   Class :character   Class :character   1st Qu.: 9.75  \n Mode  :character   Mode  :character   Mode  :character   Median :18.50  \n                                                          Mean   :18.50  \n                                                          3rd Qu.:27.25  \n                                                          Max.   :36.00  \n                                                                         \n     trt                 ears           yield        disease       \n Length:288         Min.   :10.00   Min.   :0.830   Mode :logical  \n Class :character   1st Qu.:36.00   1st Qu.:2.485   FALSE:143      \n Mode  :character   Median :41.00   Median :3.930   TRUE :145      \n                    Mean   :40.43   Mean   :4.033                  \n                    3rd Qu.:45.00   3rd Qu.:5.400                  \n                    Max.   :69.00   Max.   :7.870                  \n                    NA's   :1       NA's   :1",
    "crumbs": [
      "Lessons",
      "Getting to know data in R"
    ]
  },
  {
    "objectID": "lessons/getting-to-know-data.html#common-data-structures-in-r",
    "href": "lessons/getting-to-know-data.html#common-data-structures-in-r",
    "title": "Getting to Know Your Data in R",
    "section": "Common Data Structures in R",
    "text": "Common Data Structures in R\nLet’s consider how imported data sets are arranged into complex structures (that is, objects) that we can access and manipulate.\nThere are several data structures commonly used in R:\n\nvector\ndata.frame\nmatrix\nlist\n\nThis lesson covers vectors and data frames, the two most common object types in R.\n\nThe vector\nA vector in R is an object that contain one or more elements of the same type (types are covered later in this lesson). If we select a single column variable in data1, it will be returned to us as a vector.\nData in R data frames can be referred to by their column names using the notation dataframe$column_name:\n\nVector Exploration\n\nAscertaining vector length\n\nTo find out how many items a vector has, use the length() function:\n\nlength(data1$site)\n\n[1] 288\n\n\nNote that this will also count missing values.\n\nSorting vectors\n\nTo sort items in a vector alphabetically or numerically, use the sort() function:\n\nsort(data1$yield)  # sort a number\nsort(data1$site)  # Sort a character\n\n\nFinding unique values in a vector\n\nFor ‘character’ variables with repeat information, sometimes it is more helpful to only look at unique values:\n\nunique(data1$site)\n\n[1] \"DBAN\" \"LFAN\" \"NSAN\" \"ORAN\" \"OVAN\" \"TEAN\" \"WEAN\" \"WLAN\"\n\n\n\nCounting unique values in a vector:\n\n\ntable(data1$site)\n\n\nDBAN LFAN NSAN ORAN OVAN TEAN WEAN WLAN \n  36   36   36   36   36   36   36   36 \n\n\nThis also works across multiple vectors:\n\ntable(data1$site, data1$isle)\n\n      \n       Antigua\n  DBAN      36\n  LFAN      36\n  NSAN      36\n  ORAN      36\n  OVAN      36\n  TEAN      36\n  WEAN      36\n  WLAN      36\n\n\n\nVector summaries information\n\nYou can also look at summaries for individual vectors:\n\n# mean\nmean(data1$yield, na.rm = TRUE) # the na.rm tells R to ignore missing data\n\n[1] 4.033275\n\n# minimum\nmin(data1$yield, na.rm = TRUE)\n\n[1] 0.83\n\n# maximum\nmax(data1$yield, na.rm = TRUE)\n\n[1] 7.87\n\n# median\nmedian(data1$yield, na.rm = TRUE)\n\n[1] 3.93\n\n# variance\nvar(data1$yield, na.rm = TRUE)\n\n[1] 3.021442\n\n# standard deviation\nsd(data1$yield, na.rm = TRUE)\n\n[1] 1.73823\n\n# sum all yield data\nsum(data1$yield, na.rm = TRUE)\n\n[1] 1157.55\n\n\n\n\nAccessing Vectors\nYou can access the vector items by referring to its index number inside brackets []. The first item has index 1, the second item has index 2, and so on: Multiple item can also be indexed: x[c(1,5)]. If an index position, it repeated, that item will be returned as often as it is called:\n\n# look at one position\ndata1$yield[5]\n\n[1] 5.36\n\n# look at multiple positions\ndata1$yield[c(2,5)]\n\n[1] 3.94 5.36\n\n\nWe can use this information to replace information in a vector\n\ndata1$yield[5] &lt;- 5 #(original value was 5.36)\n\nIndexing accepts numeric/integer vectors, so you can use a sequence (3:10), or concatenated positions (c(1, 2, 5, 10)), or a combination of both (c(1:10, 13)).\n\n\nAssigning Vectors to Objects\nVectors can be indexed and assigned to a new object.\n\nyield_ &lt;- data1$yield\nsite_ &lt;- data1$site\n\nThe columns called “yield” and “site” are returned as a vector and assigned to new objects.\nThese new objects can be examined and manipulated the same as if they were indexed (e.g. mean(yield, na.rm = TRUE), table(site_))\n\n\nCreating New Vectors\nWe can also create new vectors from the original vectors\n\nlog_yield = log(data1$yield)\nyield_pi = data1$yield*3.14\nyield_sqrt = sqrt(data1$yield)\near_sqr = data1$ears^2\n\nYou can also add/multiply/subtract two columns of same data type and of same length. Let’s create a new vector named ‘var2’ as a product of ‘yield’ and ‘ears’ from data1.\n\nyield_per_ear = data1$yield / data1$ears\nyield_ear &lt;- data1$yield * data1$ears\n\nR is naturally vectorized, which means that when you conduct a math operation on a vector, it will be repeated across the entire vector.\nAny vector whose length matches the number of rows in a data frame can be added to that data frame. When we do this, we assume each is in the correct order. Since ‘yield_ear’ is directly from a vectorized operation done on ‘data1’, that assumption is correctly made.\n\ndata1$yield_x_ear &lt;- yield_ear\n\nWhen adding a new vector to a data frame that is multiple of the number of rows in the dataframe, that vector will be ‘recycled’ or repeated until it is as long as the data frame:\n\ndata1$new_isle = \"Puerto Rico\"\ndata1$sequence = c(1, 2, 3, 4)\ndata1$bad_order = c(1, 2, 3, 4, 5) # throws an error\n\nError in `$&lt;-.data.frame`(`*tmp*`, bad_order, value = c(1, 2, 3, 4, 5)): replacement has 5 rows, data has 288\n\n\nR also has a rich set of math operators available. You can learn more about using math operators here.\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nCreate a sequence of numbers from 1 to 10 twice and assign that to a new vector called ‘k’.\nAssign the value 5.4 to a vector called ‘lambda’\nDo the following operation to your vector from part 1 of this problem and the vector called ‘lamba’ and assign the results to a new vector:\n\n\\[ \\frac{lambda^k2.72^{-lambda}}{k!}\\] You can compute \\(k!\\) using factorial(k).\n\n\n\n\n\n\nThe Data Frame\nA data frame is a collection of the vectors of same length. This is the most widely used and important data structure in R. Each vector is a single data type, but different vectors can be different data types (e.g. character or numeric) in a data frame. This is similar to a typical workbook you might open in Excel or another spreadsheet program.\nIn this example, data1 is a data frame which consists of different vectors (isle, site, block, etc) that are each their own data type (character, integer, numeric, logical).\nA data frame has attributes for:\n\nnrow number of rows\nncol number of columns\ncolnames column names\nrownames row names (if none are provided, R will generate integer row names starting at 1)\n\nCheck the number of rows and columns in a data frame:\n\nnrow(data1)\n\n[1] 288\n\nncol(data1); length(data1)\n\n[1] 11\n\n\n[1] 11\n\ndim(data1) # tells us row and column lengths in one command\n\n[1] 288  11\n\n\n\nrownames(data1)\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\" \"151\" \"152\" \"153\" \"154\" \"155\" \"156\"\n[157] \"157\" \"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\"\n[169] \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\"\n[181] \"181\" \"182\" \"183\" \"184\" \"185\" \"186\" \"187\" \"188\" \"189\" \"190\" \"191\" \"192\"\n[193] \"193\" \"194\" \"195\" \"196\" \"197\" \"198\" \"199\" \"200\" \"201\" \"202\" \"203\" \"204\"\n[205] \"205\" \"206\" \"207\" \"208\" \"209\" \"210\" \"211\" \"212\" \"213\" \"214\" \"215\" \"216\"\n[217] \"217\" \"218\" \"219\" \"220\" \"221\" \"222\" \"223\" \"224\" \"225\" \"226\" \"227\" \"228\"\n[229] \"229\" \"230\" \"231\" \"232\" \"233\" \"234\" \"235\" \"236\" \"237\" \"238\" \"239\" \"240\"\n[241] \"241\" \"242\" \"243\" \"244\" \"245\" \"246\" \"247\" \"248\" \"249\" \"250\" \"251\" \"252\"\n[253] \"253\" \"254\" \"255\" \"256\" \"257\" \"258\" \"259\" \"260\" \"261\" \"262\" \"263\" \"264\"\n[265] \"265\" \"266\" \"267\" \"268\" \"269\" \"270\" \"271\" \"272\" \"273\" \"274\" \"275\" \"276\"\n[277] \"277\" \"278\" \"279\" \"280\" \"281\" \"282\" \"283\" \"284\" \"285\" \"286\" \"287\" \"288\"\n\ncolnames(data1)\n\n [1] \"isle\"        \"site\"        \"block\"       \"plot\"        \"trt\"        \n [6] \"ears\"        \"yield\"       \"disease\"     \"yield_x_ear\" \"new_isle\"   \n[11] \"sequence\"   \n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe rownames attribute can be set, but if it is not, it is automatically created within R from 1 to the total number of rows. Row names are a tricky attribute than many packages in R do not support. A function may toss out your row names without any warning!\nIn general, I do not recommend setting the row names attribute in data frames to anything other than the default values unless a package function specifically requires it.\n\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nImport “Apple.csv” from the data/ folder using the function read.csv() and assign it to an object named “data2”.\nCopy ‘data2’ to a new object. You pick the new name!\nCreate three news vectors using the variables named ‘stock’, ‘gen’, and ‘yield’ from data2 and give each vector a name of your choosing.\n\n\n\n\n\nAccessing items in a data frame\nEarlier, we saw how we can use the $ notation to access any column (or vector) in a data frame. For example, to access the ‘block’ variable in our data1, you can use data1$block\nA data set can also be indexed by numeric position. You can extract individual elements in a data frame by references the row and column position, my_dataframe[row, column], where the indexing begins at 1. So my_dataframe[1, 1] would extract the data point located in the first row and first column.\nMore examples:\n\nExtract the items located in the first 2 rows and 2 columns:\n\nVisual of what we want:\n\n\n\n\n\n\n\n\n\nThis graphic is an overlay of green over blue, creating a dark teal color. The green represents rows indexed, the blue is columns indexed and the teal is the intersection between those two. If a color is not visible, that is because it is under the teal overlay.\n\ndata1[1:2, 2:3]\n\n\nExtract the first two rows and all of the columns:\n\n\n\n\n\n\n\n\n\n\n\ndata1[1:2, ]\n\nWhen the column position is left empty, all columns are returned\n\nExtract the entire first column and all rows:\n\n\n\n\n\n\n\n\n\n\n\ndata1[ ,1]\n\nWhen the row position is left empty, all rows are returned.\n\nExtract the values located in the first 2 rows and first two columns:\n\n\n\n\n\n\n\n\n\n\n\ndata1[1:2, 1:2]\n\n\nReturn everything except the third columns\n\n\n\n\n\n\n\n\n\n\n\ndata1[ ,-3]\n\n\nReturn everything except the first 2 rows:\n\n\n\n\n\n\n\n\n\n\n\ndata1[-(1:2),  ]\n\n\n\nValue replacement\nThere are likely to be moments when you want to replace values in a data frame or vector with something else. You can do that with indexing and variable assignment.\nLet’s image that we want to assign the third value in the sixth column as NA. First, we index the that position, then we assign a value to it (NA in this case):\n\ndata1[1, 8] &lt;- NA\n\nNA is a reserved word in R, hence it does not need to be quoted.\n\n\nCreating a new data frame\nWe can create an example data frame using the new vectors created earlier in this lesson:\n\nnew_df &lt;- data.frame(log_yield, ear_sqr )\nhead(new_df)\n\n  log_yield ear_sqr\n1  1.601406    1764\n2  1.371181    1681\n3  1.848455    2401\n4  1.715598    2304\n5  1.609438    2025\n6  1.821318    2116\n\n\n\n\n\n\n\n\nBrief notes on naming\n\n\n\n\n\nWhile duplicate column names in a data frame are allowed, they are not advised and may throw an error during data import, depending on the import function used.\nAlso, it is not recommended that objects be named after existing functions since it can cause unpredictable behavior with R. Over time, you will learn of these conflicts. Two examples that new users often trip over are data and df, which are existing functions in R.\n\n\n\nVectors and data frames are two major object types in R, but there are other types that provide different functionality. You can learn more about them here.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R"
    ]
  },
  {
    "objectID": "lessons/getting-to-know-data.html#data-types",
    "href": "lessons/getting-to-know-data.html#data-types",
    "title": "Getting to Know Your Data in R",
    "section": "Data Types",
    "text": "Data Types\nRecall that we can look at the overall structure of a data.frame with str():\n\nstr(data1)\n\n'data.frame':   288 obs. of  11 variables:\n $ isle       : chr  \"Antigua\" \"Antigua\" \"Antigua\" \"Antigua\" ...\n $ site       : chr  \"DBAN\" \"DBAN\" \"DBAN\" \"DBAN\" ...\n $ block      : chr  \"B1\" \"B1\" \"B1\" \"B1\" ...\n $ plot       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ trt        : chr  \"T111\" \"T000\" \"T311\" \"T202\" ...\n $ ears       : int  42 41 49 48 45 46 42 44 42 44 ...\n $ yield      : num  4.96 3.94 6.35 5.56 5 6.18 4.71 6.03 2.88 5.68 ...\n $ disease    : logi  NA FALSE FALSE TRUE FALSE TRUE ...\n $ yield_x_ear: num  208 162 311 267 225 ...\n $ new_isle   : chr  \"Puerto Rico\" \"Puerto Rico\" \"Puerto Rico\" \"Puerto Rico\" ...\n $ sequence   : num  1 2 3 4 1 2 3 4 1 2 ...\n\n\n\nCommon Data Types\nBy using the str() command above, we noticed the object types in this data set. The common object types in this data set includes:\n\nYield and ears are shown as ‘numeric’ and ‘integer’ (integer is a subtype of ‘numeric’).\nVariables such as site, and trt are class ‘character’.\nThe variable ‘disease’ is logical, meaning it can only take TRUE or FALSE values (or 1/0 values)\n\nYou can also check the class of each variable separately by using class() function.\n\nclass(data1$block)\n\n[1] \"character\"\n\nclass(data1$yield)\n\n[1] \"numeric\"\n\nclass(data1$disease)\n\n[1] \"logical\"\n\n\n\n\nData Type Conversion\nData type of individual variables can be ‘coerced’ (forced) into different types. For example, plot is a numeric variable, as.character() converts it to a character variable.\n\ndata1$plot &lt;-  as.character(data1$plot)\n\ndata1$plot &lt;- as.numeric(data1$plot) #converting plot back to numeric\n\n\n\nFactors\nA character variable can be converted to the factor variable. Factor is a special type of variable used largely for linear modelling. It look like a character variable and it has pre-defined levels.\n\ndata1$block &lt;- as.factor(data1$block)\nclass(data1$block) # check class of the block\n\n[1] \"factor\"\n\nlevels(data1$block) # existing levels\n\n[1] \"B1\" \"B2\" \"B3\" \"B4\"\n\nnlevels(data1$block) # predefined levels\n\n[1] 4\n\n\nFactors are challenging to work with. They are required for linear modelling and hence that is we teach them. Nevertheless, they are tricky beasts with funny conventions (run typeof(data1$block) to see what we mean). We don’t have any additional lesson to refer to, but if find yourselve working with factors, take some time to read the documentation for the function factor() (run ?factor in the console), and if you must really get serious about factors, see the packge forcats for further resources.\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\nHere is some code from earlier: data1[1, 8] &lt;- NA\n\nWhat happens if we replace NA with \"NA\"?\nHow do we fix this?\n\n\n\n\nMore information on different data types in R and how to convert between them can be found here.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R"
    ]
  },
  {
    "objectID": "lessons/getting-to-know-data.html#base-plotting",
    "href": "lessons/getting-to-know-data.html#base-plotting",
    "title": "Getting to Know Your Data in R",
    "section": "Base Plotting",
    "text": "Base Plotting\nWhile R can make sophisticated and publication quality charts, it can also be used for quick data visualizations. We usually use a set of functions that automatically come with an R installation, ‘base functions’. ‘Base plotting’ refers to functions that are part of base R used for plotting.\nHere we are creating a histogram to look at data distribution of the ‘yield’ variable from data1 using a hist() function.\n\nhist(data1$yield)\n\n\n\n\n\n\n\n\nThe boxplot() function in R is used to create a boxplot for the selected variables. In the code chunk below, a boxplot of yield for each replication is created, the xlab and ylab shows the title of x-axis and y-axis, respectively. The main=, provides the title to the graph.\n\nboxplot(yield ~ trt, data = data1,\n        main = \"Yield Graph\",\n        xlab = \"Rep\",\n        ylab = \"Yield\")\n\n\n\n\n\n\n\n\nPairwise plots are also useful ways to visualize information:\n\nplot(data1$ears, data1$yield)  \n\n\n\n\n\n\n\n\nPoint plots can also be done a single variable:\n\nplot(data1$yield)\n\n\n\n\n\n\n\n\nThe x-axis, “Index”, is the row index, i.e. the indexed position along the vector.\nBarplots are also handy. data1 is suited for a barplot, but we can make a data set better for a barplot:\n\ndata1$yield_categories &lt;- cut(data1$yield, 5) # break yield into 5 groups\ntotes &lt;- as.data.frame(table(data1$yield_categories)) # count how many observations are in each group and convert to a data frame\ntotes # print object\n\n          Var1 Freq\n1 (0.823,2.24]   60\n2  (2.24,3.65]   69\n3  (3.65,5.05]   71\n4  (5.05,6.46]   58\n5  (6.46,7.88]   29\n\n\n\nbarplot(Freq ~ Var1, data = totes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nOften, base plotting is only used for quick visualizations and it is not worth the effort to make them look pretty. However, they can be made publication quality. Search ?par to learn more about how to adjust and improve upon these plots.\nlater in this workshop, we will absolutely be covering how to make publication quality plots with ggplot2 and related extensions.\n\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\n\nCalculate the inverse of yield from data1.\nMake a histogram of inverse yield\nCalculate relative percent yield by dividing all yield values by the mean yield and multipling it by 100. Do the equivalent action for ears.\nMake a pairwise plot (x-y plot) between relative percent ears and relative percent yield.\n\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nCheck the environment pane. These are the object you created during the session. This is where you will see all objects created, unless you have choosen to render the objects invisible by starting their object names with a ., a period.",
    "crumbs": [
      "Lessons",
      "Getting to know data in R"
    ]
  },
  {
    "objectID": "lessons/lesson-zero.html",
    "href": "lessons/lesson-zero.html",
    "title": "Preparing for this Short Course/Workshop",
    "section": "",
    "text": "Welcome & Salutations!\nWe excited to teach this course. We have revamped this curriculum so that we get everyone doing practical coding with data as soon as possible.\nWe have limited time, so order to conserve class time and have us all ready for the first day of class, please read through this “Lesson Zero” and follow the instructions below.\n\nInstall R & RStudio.\nFollow these instructions for installing R and RStudio. R is the actual programmatic engine that you can do cool things with, and RStudio is an “integrated development environment” (IDE) to help us use R effectively. Some of the screenshots are for an older version of R; please install the latest version of R (4.4 as of May 1, 2024).\n\n\nJoin Posit Cloud\nYou will receive a link via email from us to join our online classroom on Posit Cloud, where you will need to sign up for an account using your email, or you can connect it to a Gmail or GitHub account (any of these choices will work fine for the class). If do you not have a Gmail or GitHub account or prefer not to use those, you can use your normal work email instead. Once you receive the invitation and have created an account, follow these instructions for accessing the classroom.\n\n\nClass Structure\nFor all lessons, please follow along in R + RStudio or Posit Cloud session. In most instances, you will type and run the same code that we will demonstrate. Actually typing out the code rather than cut-and-pasting is how you learn.\nAdditionally, all code generated that day will be posted on the Posit Cloud ‘classroom’. It is important that you read through notes and try to run to do the exercises if (1) you had to miss some or all of a class, or (2) there is material you do not understand.\nIt is very important that you use the time between class sessions to ensure you understand the material.\n\n\nClass absences\nIt’s okay to miss class or a lecture - we all have stuff going on. There is no need to tell us in advance. As mentioned above, if you miss class, please be sure to catch up on the course material you missed by reading the course notes, running the content and attempting the exercises. Falling behind in the content can create problems with the following content, so please make every effort to stay current with the class.\n\n\nClass Notes Structure\nAs mentioned, all code run will be captured in class notes that will be posted. While you can read those notes and not attend class, many find it helpful to attend a live course and receive live instruction and feedback from an expert.\n\nAt the beginning of each lesson, this box will be included:\n\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThis will be a list of what each lesson intends to teach.\nIf you do not think you have met those learning goals, please review the notes, and if the material is still unclear, contact us.\n\n\n\n\nAt the end of most lessons, this box will be included:\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nTips designed to weave together information from multiple lessons.\n\n\n\nPractice problems are included in most lessons:\n\n(click to expand)\n\n\n\n\n\n\nPractice Problem\n\n\n\n\n\nTest your R installation by running this in the console:\nx = 1:10\nx\nWhat resulted?\n\n\n\n\n\nHow to Suceed in Learning R\nLearning R is hard. It has a very steep learning curve. You will spend some amount of time lost and confused. At first, your work may look or feel like some of the baking attempts from the TV show “Nailed It”, where amateur bakers attempt to make very intricate baked concoctions:\n\nThat is normal and okay. It means you are trying to active engage with the material. Keep engaging in this process of learning to code. Many of you may have never programmed in any language before, where others do have previous programming experience. After time and regular practice, your R code will look better and most importantly, be easier for you to write. The purpose of this workshop is to reduce the amount of time you spent in the zone of learning pain:\n\nHere are some tips on how to succeed in learning R from this workshop:\n\nAt the end of each class (or when you have a free moment in the class), review the learning goals and decide if you met those goals. These are designed to be the bare minimum of knowledge to competently use R. Later workshop content builds on this knowledge.\n\nReview what we have covered between classes - refresh your knowledge.\nIf there are practice problems, do them (we will give time during class).\nExperiment in the R console using what you learned. Really, nothing can go wrong.\nIf class material is not clear, re-run the code from class and reread the notes; If it’s still not clear, ask up questions. We are here to help.\n\n\n\nYour very first R lesson!\n\nR is case-sensitive! (data is different from Data and DATA). This means when typing commands, exercise great care and attention to detail so your code works.\nThere is no “undo” button in R. Once a command is run, you can’t undo it! (this is not as bad as it sounds)",
    "crumbs": [
      "Lessons",
      "Lesson Zero"
    ]
  },
  {
    "objectID": "lessons/r-documentation.html",
    "href": "lessons/r-documentation.html",
    "title": "R Functions & R Help",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to install R packages\nunderstand how to call functions using named and positional arguments\nbe able to access help files for an R function and know how to use the information provided in a help file",
    "crumbs": [
      "Lessons",
      "R documentation"
    ]
  },
  {
    "objectID": "lessons/r-documentation.html#r-package-installation",
    "href": "lessons/r-documentation.html#r-package-installation",
    "title": "R Functions & R Help",
    "section": "R Package Installation",
    "text": "R Package Installation\nThere are 2 options for installing packages available on CRAN (Comprehensive R Archive Network).\n\nOption 1: the command line\n\n# one package\ninstall.packages(\"package_name\")\n# multiple packages\ninstall.packages(c(\"package_1\", \"package_2\"))\n\nSpelling and case must be exact. Otherwise you get an error:\n\ninstall.packages(\"matrx\")\n\nError: package 'matrx' is not available\n\n\n\n\nOption 2: The RStudio ‘Packages’ window:\nA point-and-click interface.\n\n\n\n\n\n\n\n\n\nClick “Install” and then type your package. Close matches will start to appear in the dropdown:\n\n\n\n\n\n\n\n\n\nThis will automatically resolve spelling and case issues.\n::: {callout-note collapse = FALSE} Note that multiple packages can be listed in the install.packages() command, but not library(). Also, packages only need to be installed once, not repeatedly (unless a package needs to be a updated to the latest version). However, packages must be loaded in every R session or their functionality (including the help files) will not be available. :::",
    "crumbs": [
      "Lessons",
      "R documentation"
    ]
  },
  {
    "objectID": "lessons/r-documentation.html#the-mechanics-of-r-functions",
    "href": "lessons/r-documentation.html#the-mechanics-of-r-functions",
    "title": "R Functions & R Help",
    "section": "The Mechanics of R Functions",
    "text": "The Mechanics of R Functions\nWe have thus far used a few R functions without explicitly stating how to call them properly.\nThe majority of functions in R follow this format:\n\nfunction_name(arg1, arg2, arg3)\n\nWhere “arg” refers to a function argument (that is, a piece of information the function can use).\nA function has a name, and can take several arguments within the parentheses. These argument values can be provided by providing each argument in the expected order:\n\nfunction_name(value1, value2, value3)\n\nNote that each positional argument is not being explicitly referenced. However, we can specify each argument when calling a function:\n\nfunction_name(arg1 = value1, arg2 = value2, arg3 = value3)\n\nWhen specifying the argument explicitly, we don’t have to follow the order of arguments:\n\nfunction_name(arg1 = value1, arg3 = value3, arg2 = value3)\n\nThis approach of using named arguments is very helpful when there is a very long list of potential argument and you only plan to specify a small portion of them.\nWe can also combined positional argument and named arguments:\n\nfunction_name(value1, arg3 = value3)\n\nIn this case, arg2 has been completed omitted. When an argument is not specified, that implies the default arguments for that function will be used instead. In order to find out the default argument values for a function, we need to consult the R help files.\n\nUsing R Help\nYou can search for a function directly using the search windows in the upper right of the “Help” pane.\nYou can also search using this notation: ?function_name.\nLet’s check out the help file for sample(), a function designed to randomly sample items and return that random sample to us.\n\n?sample\n\nHere is a screenshot of the window that hopefully popped up in your RStudio help pane:\n\n\n\n\n\n\n\n\n\nAll help files follow this format\n\nDescription what the function does\nUsage how the function is called; this is where default argument may be listed\nArgument the named arguments available in the function (often the most useful part of the help file)\nDetails an optional section providing various computational details\nValue what is returned after the function is run\nReferences any technical, scientific or peer-reviewed lit references supporting the computational procedures implemented in the function\nSee Also similar functions (sometimes helpful)\nExamples actual examples of the function in the wild! These are hit-or-miss on their overall utility, but when I’m desperate to understand how to properly call a function, this has helped me.\n\nAt the very bottom is the package the function came from and a link to an index of all functions associated with that package. This can come in handy when you want to browse all functions available in a package.\nLooking at the sample() help file, here is what is it telling us:\n\nThe first argument is a vector of choices for the function to sample randomly\nThe next argument is the number to sample. By default, it will return a sample the same length at the input vector of choices\nThe third argument indicates that if a vector should be sampled with replacement (that is, can items be repeatedly sampled). The default is FALSE (meaning no).\nWe can also specify the probability of sampling any item in the input vector. If we don’t provide this information, then all item is assumed to have equal probabilities of being sampled.\nIt will return a vector of the item sampled\n\n\nx &lt;- 1:100\nx\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\nsample(x, 10, replace = TRUE)\n\n [1] 80 39 67 82  8 14 59  7 29 53\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is normal to struggle with R code. Newer users of R struggle more than seasoned users, but we all end up experiencing an apparently intractable problem, one that we cannot solve despite our best efforts. The first response may be to Google that problem (which may yield helpful information), but there are also more efficient search strategies you can employ to solve your R coding problem. Here is a blog post addressing that very topic: how to find help when we are stuck.\n\n\n\n\nBack to functions\nFunctions can return exactly one object (or none at all). If it does return an object, that can be assigned to a new object:\n\nnew &lt;- function_name(value1, arg3 = value3)\n\nIf the output from a function is not assigned, it will be sent to the console instead (we’ve done this plenty during this workshop). Sometimes, this is fine! Maybe it is a small amount of output we are running to check data integrity. Or maybe it’s a giant data frame we deeply regret printing in the console.",
    "crumbs": [
      "Lessons",
      "R documentation"
    ]
  },
  {
    "objectID": "lessons/r-documentation.html#base-r-and-contributed-libraries",
    "href": "lessons/r-documentation.html#base-r-and-contributed-libraries",
    "title": "R Functions & R Help",
    "section": "Base R and Contributed Libraries",
    "text": "Base R and Contributed Libraries\nThis is the only lesson with a major focus on ‘base R’, that is the set of functions that come automatically loaded when you install and open R.\nTake a look at this long-ish cheat sheet (4 pages long!) of the many useful commands in base R. Skim through this and see if there is anything useful for you. It is meant to periodically skimmed, not studied in great detail (you’ll put yourself to sleep if you try to read it beginning to end).\nAdditionally, here is the ultimate guide to working with the R language. This is a long, highly technical document, but it is also incredibly detailed and informative. Reading this is like reading an encyclopedia - only read a a small section at a time and focus on topics that interest you.\n\nLibraries\n\n\n\n\n\n\n\n\n\nBut also, the community keeps R humming and current by writing packages that extend R’s functionality. This is both awesome (the latest greatest tool is now enabled!) and bad (quality of implementation is not guaranteed and these packages are often not maintained over the long haul).\nThese packages are often made available on CRAN, the comprehensive R archive network, as well Bioconductor or via GitHub, GitLab, independent websites.\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen you search for something in the Help pane, several types of help files will result: vignettes and function documentation. Function documentation is what we have just reviewed (detailed information on how to use a function). Vignettes are examples of how to use a collection of function in a package. They provide more context and a programmatic flow for using a package or accomplishing a particular goal. They are package tutorials. Vignettes are not provided for every function or every package; they are an extra feature that package authors choose to create for users.\nThere is an enormous number of R packages available! There are a few options for finding packages relevant to your work: * CRAN Task Views * Bioconductor Workflows",
    "crumbs": [
      "Lessons",
      "R documentation"
    ]
  },
  {
    "objectID": "lessons/repeating-actions.html",
    "href": "lessons/repeating-actions.html",
    "title": "Repeating Actions in R",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nknow how to use apply() to iterate across a data frame\nknow to use lapply() to interate across a list\nknow the structure of purrr functions for iterating across different object types\nknow when and how to construct a for loop\n\n\n\n\n\nRepeating operations across a vector\n\nReminder: a vector is an object with a length attribute composed of items each of the same class. It can have a name attribute (not required)\nifelse(test, action-if-yes, action-if-no)\nThe ‘test’ should be an R function that will return a TRUE or FALSE, e.g. is.na(), is.numeric()\nVector example\n\n\nx &lt;- 1:10\ny &lt;- ifelse(x &lt; 5, NA, x)\n\n\nVector example inside a data.frame\n\n\ndata(storms, package = \"dplyr\")\nstorms$category_simple &lt;- ifelse(storms$wind &lt;= 50, \"small\", \"big\")\n\n\n\nRepeating operations across a data frame\n\napply() a simple handy function to repeat things across a data.frame (or tibble, or matrix)\nThis operation is vectorised, meaning all processes proceed simultaneously\nAcross rows\n\n\nstorm_num &lt;- select_if(storms, is.numeric)\napply(storm_num, 1, median, na.rm = TRUE)\n\n\nAcross columns\n\n\nstorm_num &lt;- select_if(storms, is.numeric)\napply(storm_num, 2, median, na.rm = TRUE)\n\n\nSpecial R functions for rows and columns\n\nThese functions are very, very fast\nThey are not forgiving of non-numeric data\n\n\nrowSums(); colSums()\nrowMeans(); colMeans()\n\n\nlibrary(dplyr); data(\"storms\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    storms\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nstorms %&gt;% select_if(is.numeric) %&gt;% colMeans(na.rm=TRUE)\n\n                        year                        month \n                 2002.754364                     8.705635 \n                         day                         hour \n                   15.732303                     9.100937 \n                         lat                         long \n                   27.005763                   -61.560086 \n                    category                         wind \n                    1.895690                    50.049393 \n                    pressure tropicalstorm_force_diameter \n                  993.484465                   147.869327 \n    hurricane_force_diameter \n                   14.920698 \n\n\n::: {.callout-note} # Comments on NA values\n\nI often get the question “how can I replace”NA” across my entire data object?”\nNA is a reserved word in the R language referring to missing data. Often the best way to handle how missing values from your data are handled is to specify that when the file is read in. Check the documentation for your import function, e.g. read.csv(..., na.string = \"...\").\nTo do a global replacement of NA with another value, use tidyr::replace_na()\nTo do a global replacement of another value with NA, this can be handled in the import, or use dplyr::na_if()\n\n\n\n\nRepeating operatio across a list\n😍😍😍😍😍 lapply() 😍😍😍😍😍\n\nVectorised over lists\nIf you can express one aspect of your operation as a list, this can probably work for you!\nDownside: everything comes back as a list (it takes an effort to convert this into a more exportable form)\nIt uses very simple notation:\n\n\nlapply(list, some_function)\n\n\nExample\n\n\nintegers &lt;- sample(1:100, 200, replace = TRUE)\nthrice_int &lt;- lapply(integers, function(x) x*(c(1,2,3)))\n\nI’m very fond of this for doing complex repeat operations. Perhaps I have a group of experiments, all with identical experimental design, that each need to be analyzed the same. Using a list can accomplish this efficiently.\n\nlapply() flotsam & jetsam\n\nDealing with lists can be challenging: they follow different rules; they typically require lots and lots of indexing to extract content. And you usually can’t write a list straight to file like a data.frame.\n\nsapply() is just like lapply(), except it tries to simplify to common R data objects - a matrix or array. This works if the return data is one row.\ndplyr::bind_rows() can concatenate data.frames better than rbind().\nGetting things out of a list and into the desired format can be one of the most challenging aspects of working with lapply() (bonus: it makes you understand R data types really well!).\npurrr to the rescue!\n\n\n\n\npurrr for repeat operations\npurrr does all of the hard work of iteration plus conversion of output to the object type you want! It works on data structures of all types: vectors, data frames and lists.\n\nlibrary(purrr)\n\nmtcars %&gt;%\n  split(.$cyl) %&gt;%\n  map(~ lm(mpg ~ wt, data = .x)) %&gt;%\n  map_dfr(~ as.data.frame(t(as.matrix(coef(.)))))\n\n  (Intercept)        wt\n1    39.57120 -5.647025\n2    28.40884 -2.780106\n3    23.86803 -2.192438\n\n\n\n\n\n\n\n\nNote\n\n\n\npurrr is complicated! Make use of the cheatsheet].\n\n\n\n\nBase/Tidyverse equivalents\n\n\n\nbase functions\ntidyverse equivalent\n\n\n\n\nlapply() sapply() vapply()\npurrr package\n\n\nmapply()\npurrr::pmap()\n\n\ntapply()\ndplyr::group_by() %&gt;%  dplyr::summarise()\n\n\nreplicate()\npurrr:rerun()\n\n\nifelse()\ndplyr::case_when()\n\n\n\n\n\nThe oft-abused for\nA for loop:\n\nfor (i in thingy) {\n  do_something()\n}\n\nI see things like this frequently:\n\nx &lt;- LETTERS[1:10]\nfor (i in x) print(i)\n# same as sapply(x, print)\n\nOr worse:\n\nfor (i in item1) {\n  for(j in item2) {\n    here_we_go(...)\n  } }\n\n\nOptimal use of for\n\nBetter usage of for is when you require the previous value(s) to proceed through the loop\npre-allocation of your vector/data.frame/list/etc will result in faster code\n\n\n# vector pre-allocation\nf &lt;- c(0, 1, rep(NA, 98)) \nf[1:10]\n\n [1]  0  1 NA NA NA NA NA NA NA NA\n\n# Fibonacci sequence\nfor (i in 3:100){\n  f[i] = f[i-1] + f[i-2]\n}\n\nf[1:10]\n\n [1]  0  1  1  2  3  5  8 13 21 34\n\n\n\n\n\nTraditional control flow\n\nThese are standard control variables that exist across many languages to repeat operations.\nThese are not vectorized; they only work with a single input at time.\n\n\nif\nelse\nfor \nwhile\nnext\nbreak\n\n\nNote that these are reserved words in the R language; you cannot use these words for any other purpose in the R language than what they are designed to do (no function masking is possible).\n\n\n\n\n\n\n\nNote\n\n\n\nTeaching how to use these traditional control flow variables is beyond an introductory course in R. However, you can learn more about it here and Introduction to R manual.\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nUnderstanding how to do repeat operations in R often requires a strong understanding of the underlying data structures we are trying to perform those operations on. This aspect of R, sometimes called “data conditioning” can be one of the most challenging aspects of using R. When writing repeat operations, check back on Lessons 3 and 4 that address basics of data types and data structures if you are having trouble."
  },
  {
    "objectID": "lessons/reshaping.html",
    "href": "lessons/reshaping.html",
    "title": "Reshaping Data Sets",
    "section": "",
    "text": "Learning Goals\n\n\n\n\n\nAt the end of this lesson, you should:\n\nbe able to convert a long data set to wide\nbe able to convert a wide data set to long\nbe aware of function used during pivot_wide() to compress multiple observations for a variable combination being pivoted.\n\n\n\n\n\nWhat is pivoting?\nThere are circumstances when a wide data set are needed and circumstances when a long data set are needed, for analysis, plotting, data wrangling, etc.\nDoing this manually in a spreadsheet program is extremely cumbersome and very susceptible to errors! You are much better off doing this in R (or another programming language).\nThese wide-to-long and long-to-wide conversions are also called ‘pivoting’.\n\n\n\n\n\n\n\n\n\nWhen pivoting from long to wide format, we should consider what will be used as the identifying information, what information will be used for column headers and what information will be used to fill the cells/populate the table.\nWhen pivoting from wide to long, the considerations are similar: what will be the name of the new column header and what information (i.e. what columns) will be used to populate the data in the vertical direction, while which columns will be used for record identification.\nPivoting from wide to long can be done with the tidyr functions pivot_wide() and the reverse function if pivot_longer().\nLet’s run some examples with trial data set.\nLoad the libraries and trial data:\n\nlibrary(dplyr); library(tidyr)\n\nvariety_trials &lt;- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\n\n\nPivot long to wide\nThe first thing we should do is look at the documentation for pivot_wider.\n\n?pivot_wider\n\nThe main arguments to consider (not including the input data) is:\nid_cols what are the identifying columns that we will keep in the data set to identify and separate records. This can be multiple columns.\nnames_from is the variable that will be used to make the new column header. This is the column that we are seeking to change from long to wide. This should be a categorical variable or one that can be coerced to one. Usually it contains repeating values.\nvalues_from is the variable that will be used to fill the cells under the column header.\nThere is long list of other arguments, but these are the most important.\n\nPivot single variable\nThe loaded data set includes many different field trials. Let’s look at the information for one trial and pivot the data across replicates for a single variable, using entry as an ID variable.\nFirst, find out the different levels for “trial”:\n\nunique(variety_trials$trial)\n\n [1] \"SWIdahoCereals_H_S_PAR_2018\" \"SWIdahoCereals_H_S_WEI_2018\"\n [3] \"SWIdahoCereals_H_W_PAR_2017\" \"SWIdahoCereals_H_W_PAR_2018\"\n [5] \"SWIdahoCereals_H_W_WEI_2018\" \"SWIdahoCereals_HRS_PAR_2016\"\n [7] \"SWIdahoCereals_HRS_PAR_2017\" \"SWIdahoCereals_HRS_PAR_2019\"\n [9] \"SWIdahoCereals_HRS_PAR_2020\" \"SWIdahoCereals_HRW_PAR_2019\"\n[11] \"SWIdahoCereals_HRW_PAR_2020\" \"SWIdahoCereals_HWS_PAR_2016\"\n[13] \"SWIdahoCereals_HWS_PAR_2017\" \"SWIdahoCereals_HWS_PAR_2019\"\n[15] \"SWIdahoCereals_HWS_PAR_2020\" \"SWIdahoCereals_HWW_PAR_2019\"\n[17] \"SWIdahoCereals_HWW_PAR_2020\" \"SWIdahoCereals_SWS_PAR_2016\"\n[19] \"SWIdahoCereals_SWS_PAR_2017\" \"SWIdahoCereals_SWS_PAR_2018\"\n[21] \"SWIdahoCereals_SWS_PAR_2019\" \"SWIdahoCereals_SWS_PAR_2020\"\n[23] \"SWIdahoCereals_SWS_WEI_2018\" \"SWIdahoCereals_SWW_PAR_2017\"\n[25] \"SWIdahoCereals_SWW_PAR_2018\" \"SWIdahoCereals_SWW_PAR_2019\"\n[27] \"SWIdahoCereals_SWW_PAR_2020\" \"SWIdahoCereals_SWW_WEI_2018\"\n\n\nThis example will use the last trial listed (SWIdahoCereals_SWW_PAR_2020), but any of these options will work. Let’s filter the data and check that there is one observation per rep and entry.\n\nparma2018 &lt;- variety_trials %&gt;% filter(trial == \"SWIdahoCereals_H_S_PAR_2018\") \ntable(parma2018$variety, parma2018$rep)\n\n             \n              1 2 3 4\n  06PN3017-09 1 1 1 1\n  12SB0197    1 1 1 1\n  12SB0224    1 1 1 1\n  Alum        1 1 1 1\n  Dayn        1 1 1 1\n  Glee        1 1 1 1\n  IDO1602S    1 1 1 1\n  IDO1603S    1 1 1 1\n  IDO1604S    1 1 1 1\n  Jefferson   1 1 1 1\n  LCS Iron    1 1 1 1\n  LCS Luna    1 1 1 1\n  SY Coho     1 1 1 1\n  SY Gunsight 1 1 1 1\n  UI Platinum 1 1 1 1\n  WA828       1 1 1 1\n  WB7328      1 1 1 1\n  WB7589      1 1 1 1\n  WB9411      1 1 1 1\n  WB9433      1 1 1 1\n  WB9578      1 1 1 1\n  WB9668      1 1 1 1\n\n\nThe table produces all “1” indicating 1 observation per variable combination, which is what we want.\n\nparma2018_wide &lt;- parma2018 %&gt;% \n  pivot_wider(id_cols = variety,\n              names_from = rep,\n              values_from = yield)\n\nhead(parma2018_wide)\n\n# A tibble: 6 × 5\n  variety     `1`   `2`   `3`   `4`\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 12SB0197   71.7  109.  81.7 104. \n2 Jefferson  65.3  104.  91.3  84.7\n3 Dayn       70.8  102.  86.2 109. \n4 WA828      77.8  110.  93.3  99.3\n5 Alum       71.1  119.  93.4 109. \n6 Glee       80.8  106.  93.5  94.1\n\n\nIf you try to index that column with parma2018_wide$1, an error is thrown:\n\nparma2018_wide$1\n\nError: &lt;text&gt;:1:16: unexpected numeric constant\n1: parma2018_wide$1\n                   ^\n\n\nWe can give it better column names (not starting with a number) using the names_prefix argument.\n\nparma2018_wide &lt;- parma2018 %&gt;% \n  pivot_wider(id_cols = variety,\n              names_from = rep,\n              values_from = yield,\n              names_prefix = \"rep_\")\n\nhead(parma2018_wide)\n\n# A tibble: 6 × 5\n  variety   rep_1 rep_2 rep_3 rep_4\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 12SB0197   71.7  109.  81.7 104. \n2 Jefferson  65.3  104.  91.3  84.7\n3 Dayn       70.8  102.  86.2 109. \n4 WA828      77.8  110.  93.3  99.3\n5 Alum       71.1  119.  93.4 109. \n6 Glee       80.8  106.  93.5  94.1\n\n\n\n\nPivot multiple variables\nPerhaps we want to pivot 2 variables.\n\nparma2018_wide_2vars &lt;- parma2018 %&gt;%\n  pivot_wider(id_cols = variety,\n              names_from = rep,\n              values_from = c(yield, grain_protein))\n\nhead(parma2018_wide_2vars)\n\n# A tibble: 6 × 9\n  variety   yield_1 yield_2 yield_3 yield_4 grain_protein_1 grain_protein_2\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;\n1 12SB0197     71.7    109.    81.7   104.             9.83            9.60\n2 Jefferson    65.3    104.    91.3    84.7           10.2            11.0 \n3 Dayn         70.8    102.    86.2   109.             9.89           11.7 \n4 WA828        77.8    110.    93.3    99.3           10.9            11.5 \n5 Alum         71.1    119.    93.4   109.             9.95           10.8 \n6 Glee         80.8    106.    93.5    94.1           10.2             9.14\n# ℹ 2 more variables: grain_protein_3 &lt;dbl&gt;, grain_protein_4 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\nImport “weather_data.csv”. Filter to any single year and reshape the data from long to wide so that the levels in “station’ form the new column headers, ‘julian_day’ is the identifying column and the cells are filled with data from ‘tmax_F’.\n\n\n\n\n\nPivot with multiple observations per identifier\nSometimes, there may be multiple observations per identifier and new column header. *tidyr will attempt to resolve this automatically, sometimes by inserting a list inside a data frame to capture the additional information. This is messy and hard to access. Sometimes this is an unintentional; you expected only one observation and learn through tidyr warning messages that there is an more observations than expected.\nHowever, you can also introduce a function in a pivot_wider such as mean or sum to summarise these replicate observations.\nHere is an example using “variety”, which is has replicate values.\n\nparma2018_wide_var &lt;- parma2018 %&gt;%\n  pivot_wider(id_cols = variety,\n              names_from = rep, \n              values_from = yield,\n              values_fn = mean)\n\nhead(parma2018_wide_var)\n\n# A tibble: 6 × 5\n  variety     `1`   `2`   `3`   `4`\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 12SB0197   71.7  109.  81.7 104. \n2 Jefferson  65.3  104.  91.3  84.7\n3 Dayn       70.8  102.  86.2 109. \n4 WA828      77.8  110.  93.3  99.3\n5 Alum       71.1  119.  93.4 109. \n6 Glee       80.8  106.  93.5  94.1\n\n\n\n\n\nWide to Long\nLet’s put all the traits in one column (and filter out the missing data).\nMain arguments in pivot_longer() (besides the data set):\ncols the columns to stack/pivot\nnames_to name of the new categorial variable that is composed of the names of the columns being pivoted\nvalues_to name of new value column (will be named “value” by default if not specified)\n\nparma2020_long &lt;- parma2018 %&gt;% \n  pivot_longer(cols = c(yield, grain_protein, test_weight),\n               names_to = \"trait\")\n\nhead(parma2020_long)\n\n# A tibble: 6 × 5\n  trial                         rep variety  trait          value\n  &lt;chr&gt;                       &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 SWIdahoCereals_H_S_PAR_2018     1 12SB0197 yield          71.7 \n2 SWIdahoCereals_H_S_PAR_2018     1 12SB0197 grain_protein   9.83\n3 SWIdahoCereals_H_S_PAR_2018     1 12SB0197 test_weight    62.1 \n4 SWIdahoCereals_H_S_PAR_2018     2 12SB0197 yield         109.  \n5 SWIdahoCereals_H_S_PAR_2018     2 12SB0197 grain_protein   9.60\n6 SWIdahoCereals_H_S_PAR_2018     2 12SB0197 test_weight    64.2 \n\n\n\n\n\n\n\n\nPractice Problems\n\n\n\n\n\nAs always, consider how these reshaping functions can support your own research and data analysis.\nImport “genotypic_data.txt” and remove columns 2 through 5 (‘CHROM’, ‘POS(cM)’, ‘Major_allele’, ‘Minor_allele’). What is left is genetic marker names and the marker scores for the individual lines (each column is an genetically distinct wheat line). Using pivot_longer(), reshape this object from wide to long so there is one column for the marker name, one column for the wheat name, and the one column for the marker score. How many rows long is this object? Can you image trying to do this by hand??\n\n\n\n\n\n\n\n\n\nExtra Hard Practice Problem\n\n\n\n\n\nHere is a crazy extra exercise that utilizes transpose instead of pivoting. It’s not strictly related to reshaping. Only try this if you are in the mood for a challenge.\nThis problem is indicative of a data wrangling you can experience out in the wild. You are given a data set in one format, but a package requires your data be in another format.\nThe file “genotypic_data.txt” is a transposed version of “genotypic_data_rotated.csv”. Import “genotypic_data.txt” into R and use R commands to recreate “genotypic_data_rotated.csv”.\nThe column “individual” no longer has periods in the listed names, but the original file had periods in those names since they were column headers. Write code to remove those periods from the column “individual” in your transformed column (hint: look at the documentation for gsub()).\n\n\n\n\n\n\n\n\n\nPutting it all together\n\n\n\nWhen to use these function depends on the desired output. If you want to do a multi-year analysis of field trial data, stacking the years in the long format makes sense. If you want to compute correlations across two variables, the wide format makes sense for those variables.\nAs part of the tidyverse, anything pivoting can be preceded by or can be followed by any other data wrangling step such as filtering, data aggregation and so on.\nYou can use any of the tidy select methods for indicating which values to pivot. This is particularly useful when there is a very large number of columns to pivot that share similarities in their name.",
    "crumbs": [
      "Lessons",
      "Reshaping data"
    ]
  },
  {
    "objectID": "posit-instructions.html",
    "href": "posit-instructions.html",
    "title": "Instructions for Accessing the Posit Classroom Project",
    "section": "",
    "text": "Follow the link provided in the mail to join the classroom.\nOnce you have created a login for Posit Cloud, you can join the classroom. Once you follow the link and log in to Posit, you should see something similar to this screen:\n\n\n\n\n\n\n\n\n\nClick “Yes”.\nOnce you join, navigate to the classroom on the left sidebar:\n\n\n\n\n\n\n\n\n\nWhen you open “R Classroom”, you should see this:\n\n\n\n\n\n\n\n\n\nClick on “Intro to R Class”, and the project will load. This may take a few minutes.\n\n\n\n\n\n\n\n\n\nOnce it is finished loading, this is what you should see:\n\n\n\n\n\n\n\n\n\nThis has created a temporary copy of the project (hence the blinking red label that says “TEMPORARY COPY”). Click on “Save a Permanent Copy” to copy the project. This also may take a few minutes to complete. When you’re done, if you return to the R Classroom, you should see something similar to this. It will list your name instead of “Julia Test” and there may be other students with the same project copied.\n\n\n\n\n\n\n\n\n\nOnly the instructors and you can access your project. Course instructors will not access student Posit classroom projects unless a student requests we look at it to help troubleshoot an R coding issue.\nThis project is where you access and download all course data files and live R scripts. You can access this project at anytime, including when the class is not meeting. When the course is done, the classroom will be deleted, so be certain to download your project in case you want to revisit it. We will send a reminder email to do this if you forget."
  },
  {
    "objectID": "practice/practice-B.html",
    "href": "practice/practice-B.html",
    "title": "Practice B",
    "section": "",
    "text": "(for introduction to R types and objects lesson)\n\nYou have this collection of items:\n\n\nx &lt;- c(-2:3, TRUE, FALSE, 1L, 0L, \"zero\"). \n\nWhat data type is this?\n\nConvert this object to these types:\n\n\nlogical\nnumeric\ncharacter Inspect the results. What happened?\n\nSolution"
  },
  {
    "objectID": "practice/practice-D.html",
    "href": "practice/practice-D.html",
    "title": "Practice D",
    "section": "",
    "text": "(for the data import lesson)\n\nImport one of your data sets using two of the functions taught:\n\n(save your data in different format to enable this)\n\nread.csv()\nread_csv()\nread_excel()\nread.delim()\n\n\nExamine the data imported using View(imported_data). Did everything import as expected? Are your variables coded as they should be? Are numeric variables numeric? Are missing data detected as thus?"
  },
  {
    "objectID": "practice/practice-E.html",
    "href": "practice/practice-E.html",
    "title": "Practice E",
    "section": "",
    "text": "(for data export lesson)\n\nRepeat the import practice problems. Export those files under a new file name. Make sure you use a new file name or a different output directory so you do not write over the original files.\nExamine the output files to make sure they look as expected? Where any row names accidentally introduced? Were missing cells converted to “NA”? Did any data become unexpectedly quoted?"
  },
  {
    "objectID": "practice/practice-G.html",
    "href": "practice/practice-G.html",
    "title": "Practice G",
    "section": "",
    "text": "(for the data aggregation lesson)\n\nAs usual, consider how these data aggregation functions can support your own work.\n\nFor some of these exercises, you may need to use other dplyr functions.\n\nImport “weather_data.csv”. Group the data by station and year and count the number of missing data points for ‘tmax’, ‘tmin’ and ‘tavg’.\nImport “weather_data.csv”, group the data by ‘station’ and ‘julian_day’ and calculate the average minimum and maximum temperatures for the groups from ‘tmin’ and ‘tmax’. If you already imported the data set from the previous problem, you don’t need to import it again if you did not change the data set.\nImport “weather_data.csv”, calculate the difference between the ‘tmin’ and ‘tmax’ for each day. Group the data by year and return the smallest and largest differences for each year. Consider how to handle missing data. If you already imported the data set from the previous problem, you don’t need to import it again if you did not change the data set.\n\nSolution"
  },
  {
    "objectID": "practice/practice-I.html",
    "href": "practice/practice-I.html",
    "title": "Practice I",
    "section": "",
    "text": "(for the data merging lesson)\n\nDownload genotypic_data_rotated.csv (see script below), Import that file, along with, “trial_data.csv”, and “trial_metadata.csv”.\n\n\ndownload.file(url = \"https://github.com/IdahoAgStats/r-for-ag-scientists/raw/main/data/genotypic_data_rotated.csv\",\n              destfile = here::here(\"data\", \"genotypic_data_rotated.csv\"))\n\n\nDo an inner join between “genotypic_data_rotated.csv” and “trial_data.csv” using variety names.\nDo a semi-join of “genotypic_data_rotated.csv” with “trial_data.csv” and do the reverse. How does this compare with the inner join from the previous problem?\nDo an anti-join between “genotypic_data_rotated.csv” and “trial_data.csv”.\nJoin together all common observations between the 3 files (your choice on join).\n\nSolution"
  },
  {
    "objectID": "practice/solution-B.html",
    "href": "practice/solution-B.html",
    "title": "Solutions to Practice B",
    "section": "",
    "text": "The variable x is a character variable:\n\n\nx &lt;- c(-2:3, TRUE, FALSE, 1L, 0L, \"zero\")\nclass(x)\n\n[1] \"character\"\n\n\n\nWhen converted:\n\n\nas.logical(x)\n\n [1]    NA    NA    NA    NA    NA    NA  TRUE FALSE    NA    NA    NA\n\nas.character(x)\n\n [1] \"-2\"    \"-1\"    \"0\"     \"1\"     \"2\"     \"3\"     \"TRUE\"  \"FALSE\" \"1\"    \n[10] \"0\"     \"zero\" \n\nas.numeric(x)\n\nWarning: NAs introduced by coercion\n\n\n [1] -2 -1  0  1  2  3 NA NA  1  0 NA\n\n\nItems which did not the expected object type could not be converted (or “coerced”), so they were set to NA."
  },
  {
    "objectID": "practice/solution-F.html",
    "href": "practice/solution-F.html",
    "title": "Solutions to Practice F",
    "section": "",
    "text": "First load the libraries.\n\nThen, import the data and create the new variable.\n\nmydata &lt;- read_csv(here::here(\"data\", \"trial_metadata.csv\"),\n                   show_col_types = FALSE) %&gt;%\n    unite(\"new_var\", location, irrigation, sep = \"_\", remove = FALSE )\n\nAnother option:\n\nmydata$new_var &lt;- paste(mydata$location, mydata$irrigation, sep = \"_\")\n\nAnother option:\n\nmydata &lt;- mydata %&gt;% mutate(new_var = \n                              paste(location, irrigation, sep = \"_\"))\n\n\nFilter and sort:\n\n\nmydata_filtered &lt;- mydata %&gt;% filter(location == \"Parma\") %&gt;%\n  arrange(planting_date)\n\n\nSelect and rename\n\n\nmydata_selected &lt;- mydata %&gt;% select(trial, grower_cooperator, \n                                     location, year) %&gt;%\n    rename(farm = \"grower_cooperator\")\n\nOr in one step:\n\nmydata_selected &lt;- mydata %&gt;% select(trial, farm = \"grower_cooperator\",\n                                     location, year)\n\n\nReduce the identifying information in the weather data set to non-repetitive information. A data set will often several columns that reflect repetitive identifying information. It’s helpful to know how many unique observations are present:\n\n\nweather &lt;- read.csv(here::here(\"data\", \"weather_data.csv\"))\n\nweather %&gt;% select(1:5) %&gt;% distinct()\n\n      station                           name latitude longitude elevation\n1 USC00453546             HATTON 9 SE, WA US 46.72250 -118.6524     458.7\n2 USC00456215           OTHELLO 6 ESE, WA US 46.78861 -119.0461     362.7\n3 USC00457059         RITZVILLE 1 SSE, WA US 47.11750 -118.3715     568.1\n4 USR0000WCNW COLUMBIA NWR WASHINGTON, WA US 46.88140 -119.3242     260.6\n\n\n\nPrep work:\n\n\ntrial_data &lt;- read.csv(here::here(\"data\", \"trial_data.csv\")) \n\ntrial_data$trial &lt;- gsub(pattern = \"_H_\", \n                         replacement = \"_H-\", \n                         x = trial_data$trial)\n\nIt is helpful to know the levels we splitting so we can give the new columns informative names:\n\ndistinct(trial_data, trial)\n\n                         trial\n1  SWIdahoCereals_H-S_PAR_2018\n2  SWIdahoCereals_H-S_WEI_2018\n3  SWIdahoCereals_H-W_PAR_2017\n4  SWIdahoCereals_H-W_PAR_2018\n5  SWIdahoCereals_H-W_WEI_2018\n6  SWIdahoCereals_HRS_PAR_2016\n7  SWIdahoCereals_HRS_PAR_2017\n8  SWIdahoCereals_HRS_PAR_2019\n9  SWIdahoCereals_HRS_PAR_2020\n10 SWIdahoCereals_HRW_PAR_2019\n11 SWIdahoCereals_HRW_PAR_2020\n12 SWIdahoCereals_HWS_PAR_2016\n13 SWIdahoCereals_HWS_PAR_2017\n14 SWIdahoCereals_HWS_PAR_2019\n15 SWIdahoCereals_HWS_PAR_2020\n16 SWIdahoCereals_HWW_PAR_2019\n17 SWIdahoCereals_HWW_PAR_2020\n18 SWIdahoCereals_SWS_PAR_2016\n19 SWIdahoCereals_SWS_PAR_2017\n20 SWIdahoCereals_SWS_PAR_2018\n21 SWIdahoCereals_SWS_PAR_2019\n22 SWIdahoCereals_SWS_PAR_2020\n23 SWIdahoCereals_SWS_WEI_2018\n24 SWIdahoCereals_SWW_PAR_2017\n25 SWIdahoCereals_SWW_PAR_2018\n26 SWIdahoCereals_SWW_PAR_2019\n27 SWIdahoCereals_SWW_PAR_2020\n28 SWIdahoCereals_SWW_WEI_2018\n\n\nI will call the first column “program”, the second “crop” (those are wheat market classes), the third will be called “location” (PAR is an abbreviation for Parma), and the fourth column is year. This separate() command is being done on a character variable and will return all character variables, even though “year” could be coerced to be numeric.\n\ntrial_data_sep &lt;- trial_data %&gt;% \n  separate(trial, into = c(\"program\", \"crop\", \"location\", \"year\"), \n           sep = \"_\",  # specifying the separator between terms, an underscore\n           remove = FALSE) # tells R to keep the original variable \"trial\" in the data set\n\nSince I’m not sure of what are the two most recent years, lets check:\n\ntrial_data_sep %&gt;% distinct(year) %&gt;% arrange(desc(year))\n\n  year\n1 2020\n2 2019\n3 2018\n4 2017\n5 2016\n\n\nThe most recent two years are 2019 and 2020 and they are character variables. We can convert them to numeric with as.numeric(), but why bother in this instance?\n\ntrial_data_sep_filter &lt;- trial_data_sep %&gt;% \n  filter(year %in% c(\"2019\", \"2020\")) %&gt;% \n  filter(variety %in% c(\"WA8268\", \"WB4418\", \"WB4311\", \"WB4623CLP\", \"WB4792\", \"WB7589\"))\n\n\nWrite out a result (any result) to file:\n\n\nwrite.csv(trial_data_sep_filter, \n          here::here(\"outputs\", \"problem_F_output.csv\"),\n          row.names = FALSE)"
  },
  {
    "objectID": "practice/solution-H.html",
    "href": "practice/solution-H.html",
    "title": "Solutions to Practice H",
    "section": "",
    "text": "Import data, remove unneeded columns, and pivot all columns but the first to long.\n\n\ngeno &lt;- read.delim(here::here(\"data\", \"genotypic_data.txt\")) %&gt;% dplyr::select(-(2:5))\ngeno_long &lt;- geno %&gt;% pivot_longer(cols = !1, \n                                   names_to = \"individual\",\n                                   values_to = \"marker_score\")\n\n\nnrow(geno_long)\n\n[1] 1717170\n\nhead(geno_long)\n\n# A tibble: 6 × 3\n  Markers                individual marker_score\n  &lt;chr&gt;                  &lt;chr&gt;             &lt;int&gt;\n1 recBobWhite_c10015_641 H0800080              0\n2 recBobWhite_c10015_641 H0800103L             0\n3 recBobWhite_c10015_641 H0800310              2\n4 recBobWhite_c10015_641 H0800314              2\n5 recBobWhite_c10015_641 H0900009              2\n6 recBobWhite_c10015_641 H0900081              0\n\n\n\nImport weather data and filter to 2000.\n\n\nweather &lt;- read.csv(here::here(\"data\", \"weather_data.csv\")) %&gt;% filter(year == 2000)\nweather_wide &lt;- weather %&gt;% select(station, julian_day, tmax_F) %&gt;% \n  pivot_wider(id_cols = julian_day, \n              names_from = station, \n              values_from = tmax_F)\n\ndim(weather_wide)\n\n[1] 366   4\n\nhead(weather_wide)\n\n# A tibble: 6 × 4\n  julian_day USC00453546 USC00457059 USR0000WCNW\n       &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1          1        39.0        32          35.1\n2          2        39.0        36.0        35.1\n3          3        35.1        33.1        34.0\n4          4        48.9        36.0        48.9\n5          5        43.0        43.0        48.0\n6          6        36.0        39.9        33.1\n\n\n\nExtra problem: transform “genotypic_data.txt” into “genotypic_data_rotated.csv”.\n\n\ngeno &lt;- read.delim(here::here(\"data\", \"genotypic_data.txt\"))\ngeno2 &lt;- dplyr::select(geno, -(1:5))\ngeno3 &lt;- as.data.frame(t(geno2)) %&gt;% mutate(individual = colnames(geno2)) %&gt;% relocate(individual)\n\ncolnames(geno3)[2:ncol(geno3)] &lt;- geno$Markers\ngeno3$individual &lt;- gsub(\"[.]\", \" \", geno3$individual) \n\n# check that things look okay: \ngeno3[sample(1:nrow(geno3), 5), sample(1:ncol(geno3), 5)]\n\ngsub() is relatively straightforward to use, but . without any modifiers is actually for wildcard matching (it matches everything!!) Regular expressions are crazy! So use [.] instead to specify that you in fact are referring to a period and not simply any character (including whitespace).\n\nreadr::write_csv(geno3, here::here(\"data\", \"genotypic_data_rotated.csv\"))"
  },
  {
    "objectID": "r-installation-instructions.html",
    "href": "r-installation-instructions.html",
    "title": "Install R & RStudio",
    "section": "",
    "text": "You may already have R installed on your computer. However, if the installation is one year older or later, you should upgrade it. This the beauty and drawback of R (yay for new functionality, boo to the inconvenience). R is updated frequently, usually several times per year. Not every update is important, but over time, older versions of R will cause you problems because they will work poorly with installed packages. New packages will not work at all with older version of R and older packages will have problems, requiring to also install older package versions. This is a pain to manage; its easiest to keep R updated.",
    "crumbs": [
      "Course Info",
      "how to install R"
    ]
  },
  {
    "objectID": "r-installation-instructions.html#install-r",
    "href": "r-installation-instructions.html#install-r",
    "title": "Install R & RStudio",
    "section": "Install R",
    "text": "Install R\nFirst, navigate to the Cloud mirror of the R Project for Statistical computing, and download R:\n\n\n\n\n\n\n\n\n\n\nWindows\nUse the link circled in red regardless if you have R installed or not. It’s just easier.\n\n\n\n\n\n\n\n\n\n\n\nMac\nDownload the installation bundle. Check that your operating system version is compatible (the text to the right of the download link will indicate this).\n\n\n\n\n\n\n\n\n\nOnce the installation file is downloaded, open it and follow the installation instructions, accepting the default installation settings.",
    "crumbs": [
      "Course Info",
      "how to install R"
    ]
  },
  {
    "objectID": "r-installation-instructions.html#install-rstudio",
    "href": "r-installation-instructions.html#install-rstudio",
    "title": "Install R & RStudio",
    "section": "Install RStudio",
    "text": "Install RStudio\nYou can download RStudio from the Posit website. Pick the version appropriate for your operation system and follow the installation instructions.\nYou do not need to follow “Step 1: install R” indicated on the Posit site if you already installed R following the directions above.",
    "crumbs": [
      "Course Info",
      "how to install R"
    ]
  },
  {
    "objectID": "r-installation-instructions.html#test-your-installation",
    "href": "r-installation-instructions.html#test-your-installation",
    "title": "Install R & RStudio",
    "section": "Test your Installation",
    "text": "Test your Installation\n\nOpen RStudio on your personal or work computer. It should look very similar to Posit Cloud.\nRun a command in the console to make sure all installed properly.\nInstall the Tidyverse packages: install.packages(\"tidyverse\") (this will take a few minutes)",
    "crumbs": [
      "Course Info",
      "how to install R"
    ]
  }
]